{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> INTRODUCTION TO AUTOKERAS </center></h1>\n",
    "<h2><center> THE MOST ACCESSIBLE DEEP EVOLUTION API </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SOURCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Haifeng Jin, Qingquan Song and Xia Hu (2019), `Auto-Keras: An Efficient Neural Architecture Search System`** to be found at:\n",
    "https://www.kdd.org/kdd2019/accepted-papers/view/auto-keras-an-efficient-neural-architecture-search-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural architecture search (NAS) has been proposed to automatically tune deep neural networks, but existing search algorithms, e.g., NASNet, PNAS, usually suffer from expensive computational cost. Network morphism, which keeps the functionality of a neural network while changing its neural architecture, could be helpful for NAS by enabling more efficient training during the search. In this paper, we propose a novel framework enabling Bayesian optimization to guide the network morphism for efficient neural architecture search. The framework develops a neural network kernel and a tree-structured acquisition function optimization algorithm to efficiently explores the search space. Extensive experiments on real-world benchmark datasets have been done to demonstrate the superior performance of the developed framework over the state-of-the-art methods. Moreover, we build an open-source AutoML system based on our method, namely Auto-Keras. The code and documentation are available at https://autokeras.com. The system runs in parallel on CPU and GPU, with an adaptive search strategy for different GPU memory limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A NOTE ON SAVING KERAS OUTCOME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See **Brownlee, J. (2019) `Your First Deep Learning Project in Python with Keras Step-By-Step`** , to be found at:\n",
    "\n",
    "https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRAMEWORK\n",
    "\n",
    "Keras separates the concerns of saving your model architecture and saving your model weights.\n",
    "\n",
    "Model weights are saved to HDF5 format. This is a grid format that is ideal for storing multi-dimensional arrays of numbers.\n",
    "\n",
    "The model structure can be described and saved using two different formats: JSON and YAML.\n",
    "\n",
    "In this post we are going to look at two examples of saving and loading your model to file:\n",
    "\n",
    "> - Save Model to JSON.\n",
    "> - Save Model to YAML.\n",
    "Each example will also demonstrate saving and loading your model weights to HDF5 formatted files.\n",
    "\n",
    "The examples will use the same simple network trained on the Pima Indians onset of diabetes binary classification dataset. This is a small dataset that contains all numerical data and is easy to work with. You can download this dataset and place it in your working directory with the filename “pima-indians-diabetes.csv” (update: download from here).\n",
    "\n",
    "Confirm that you have the latest version of Keras installed (e.g. v2.2.4 as of May 2019).\n",
    "\n",
    "Note: Saving models requires that you have the h5py library installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.21%\n"
     ]
    }
   ],
   "source": [
    "#MLP for Pima Indians Dataset saved to single file\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# load pima indians dataset\n",
    "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING THE MODEL\n",
    "\n",
    "Your saved model can then be loaded later by calling the load_model() function and passing the filename. The function returns the model with the same architecture and weights.\n",
    "\n",
    "In this case, we load the model, summarize the architecture and evaluate it on the same dataset to confirm the weights and architecture are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZING THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x288daa00dd8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m=new_model.predict(X)\n",
    "o=(Y)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.scatter(Y,m)\n",
    "plt.grid()\n",
    "plt.title(\"MODEL PREDICTION:Scatter Plot\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Observed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GETTING STARTED WITH AUTOKERAS\n",
    "\n",
    "**Rowan, I (2017). `Harness the power of Neural Architecture Search with a few lines of code`** to be found at : https://towardsdatascience.com/getting-started-with-autokeras-8c5332b829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most powerful upcoming concepts which I wrote about in The State of AI in 2020 is Neural Architecture Search(NAS). There is plenty to know about NAS, but to understand this tutorial I will only summarize. In short, NAS is essentially a method to take the limitations of human design out of Neural Network architectures. To accomplish this, many different architectures are considered in parallel, trained, and evaluated. Following this each may be adjusted based on a selected algorithm to try another architecture. The end result is a sort of gradient descent of the model loss across each model attempted(Can be thousands!), instead of each step. The model that performed best is the winner and the Data Scientist can sleep well at night knowing they likely aren’t using an inferior algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to **`Efficient Neural Architecture Search (ENAS) in PyTorch`** .See animation at: https://github.com/carpedm20/ENAS-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pull off a successful NAS in the past, very complicated implementations of Tensorflow, PyTorch or Keras scripts were required. Aside from this, compute hardware requirements where enterprise level. Enter AutoKeras. The Data Analytics at Texas A&M Lab developed an open source framework built with Keras to bring NAS to any avid Keras + python user. Version 1.0 was just released in January 2019 following a year of pre-release versions as well, making it ready to go out to the wild. This is a great tool for young data scientists and small companies especially, as it allows for them to keep up with this technique which large competitors swear to.\n",
    "\n",
    "The library uses state-of-the-art NAS algorithms, along with existing preprocessing blocks to insure smooth NAS trainings sessions. This is laid out extensively in the AutoKeras Paper. Part of what makes this very exciting for small research operations is the fact that they have optimized the algorithms for dynamic GPU memories to avoid the evil OOM Exceptions we are all used to. Given all of this, AutoKeras comes pre-packaged with the following capabilities:\n",
    "\n",
    "> - Image Classification/Regression\n",
    "> - Text Classification/Regression\n",
    "> - Structured DataClassification/Regression(Typical row x column datatypes)\n",
    "> - Multi-Task Learning\n",
    "\n",
    "We could start with a brief walkthrough of setup and easy implementations and then go further into depth on custom implementations and the concept of “Blocks”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "    \n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your only goal is to train the best architecture for a classification task the code is rather minimal. Using the built-in mnist dataset you could load as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data we want to fit we can create the ImageClassifier object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ak.ImageClassifier(max_trials =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the structure for our training session. The max_trials refer to how many different models will be attempted. AutoKeras has implemented models like ResNet, Xception, and separable CNNs, which are bound to be powerful.\n",
    "Following this, we will need to fit the model. \n",
    "\n",
    "The incredibly complex and long process, depending on your hardware, can be triggered with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 375 steps, validate for 1500 steps\n",
      "233/375 [=================>............] - ETA: 7:22 - loss: 2.3750 - accuracy: 0.15 - ETA: 3:50 - loss: 2.3627 - accuracy: 0.15 - ETA: 2:39 - loss: 2.2987 - accuracy: 0.20 - ETA: 1:42 - loss: 2.1856 - accuracy: 0.26 - ETA: 1:28 - loss: 2.1619 - accuracy: 0.29 - ETA: 1:18 - loss: 2.0754 - accuracy: 0.35 - ETA: 1:10 - loss: 2.0260 - accuracy: 0.36 - ETA: 1:04 - loss: 2.0019 - accuracy: 0.38 - ETA: 55s - loss: 1.8731 - accuracy: 0.4574 - ETA: 52s - loss: 1.8174 - accuracy: 0.484 - ETA: 49s - loss: 1.7579 - accuracy: 0.509 - ETA: 47s - loss: 1.7037 - accuracy: 0.526 - ETA: 45s - loss: 1.6486 - accuracy: 0.539 - ETA: 43s - loss: 1.6342 - accuracy: 0.539 - ETA: 40s - loss: 1.5573 - accuracy: 0.555 - ETA: 39s - loss: 1.5294 - accuracy: 0.557 - ETA: 36s - loss: 1.4945 - accuracy: 0.559 - ETA: 35s - loss: 1.4573 - accuracy: 0.571 - ETA: 35s - loss: 1.4341 - accuracy: 0.577 - ETA: 34s - loss: 1.4033 - accuracy: 0.583 - ETA: 32s - loss: 1.3386 - accuracy: 0.598 - ETA: 32s - loss: 1.3198 - accuracy: 0.605 - ETA: 30s - loss: 1.2861 - accuracy: 0.615 - ETA: 30s - loss: 1.2704 - accuracy: 0.617 - ETA: 29s - loss: 1.2485 - accuracy: 0.624 - ETA: 29s - loss: 1.2401 - accuracy: 0.627 - ETA: 28s - loss: 1.2184 - accuracy: 0.636 - ETA: 27s - loss: 1.1921 - accuracy: 0.643 - ETA: 26s - loss: 1.1546 - accuracy: 0.651 - ETA: 26s - loss: 1.1568 - accuracy: 0.652 - ETA: 25s - loss: 1.1265 - accuracy: 0.660 - ETA: 25s - loss: 1.1069 - accuracy: 0.668 - ETA: 24s - loss: 1.0791 - accuracy: 0.677 - ETA: 24s - loss: 1.0628 - accuracy: 0.683 - ETA: 24s - loss: 1.0457 - accuracy: 0.689 - ETA: 24s - loss: 1.0375 - accuracy: 0.692 - ETA: 23s - loss: 1.0262 - accuracy: 0.694 - ETA: 23s - loss: 1.0072 - accuracy: 0.699 - ETA: 23s - loss: 0.9869 - accuracy: 0.705 - ETA: 22s - loss: 0.9719 - accuracy: 0.710 - ETA: 22s - loss: 0.9600 - accuracy: 0.713 - ETA: 22s - loss: 0.9521 - accuracy: 0.716 - ETA: 22s - loss: 0.9347 - accuracy: 0.720 - ETA: 21s - loss: 0.9270 - accuracy: 0.721 - ETA: 21s - loss: 0.9170 - accuracy: 0.724 - ETA: 21s - loss: 0.9011 - accuracy: 0.728 - ETA: 21s - loss: 0.8938 - accuracy: 0.731 - ETA: 21s - loss: 0.8901 - accuracy: 0.732 - ETA: 20s - loss: 0.8759 - accuracy: 0.738 - ETA: 20s - loss: 0.8674 - accuracy: 0.740 - ETA: 20s - loss: 0.8561 - accuracy: 0.744 - ETA: 20s - loss: 0.8484 - accuracy: 0.746 - ETA: 20s - loss: 0.8320 - accuracy: 0.752 - ETA: 19s - loss: 0.8245 - accuracy: 0.753 - ETA: 19s - loss: 0.8085 - accuracy: 0.759 - ETA: 19s - loss: 0.8023 - accuracy: 0.761 - ETA: 19s - loss: 0.7990 - accuracy: 0.762 - ETA: 19s - loss: 0.7925 - accuracy: 0.764 - ETA: 19s - loss: 0.7860 - accuracy: 0.766 - ETA: 19s - loss: 0.7717 - accuracy: 0.771 - ETA: 18s - loss: 0.7647 - accuracy: 0.773 - ETA: 18s - loss: 0.7608 - accuracy: 0.774 - ETA: 18s - loss: 0.7560 - accuracy: 0.775 - ETA: 18s - loss: 0.7555 - accuracy: 0.776 - ETA: 18s - loss: 0.7456 - accuracy: 0.779 - ETA: 18s - loss: 0.7413 - accuracy: 0.780 - ETA: 18s - loss: 0.7389 - accuracy: 0.780 - ETA: 18s - loss: 0.7349 - accuracy: 0.782 - ETA: 18s - loss: 0.7283 - accuracy: 0.784 - ETA: 17s - loss: 0.7248 - accuracy: 0.784 - ETA: 17s - loss: 0.7201 - accuracy: 0.785 - ETA: 17s - loss: 0.7143 - accuracy: 0.786 - ETA: 17s - loss: 0.7087 - accuracy: 0.788 - ETA: 17s - loss: 0.7068 - accuracy: 0.788 - ETA: 17s - loss: 0.7047 - accuracy: 0.789 - ETA: 17s - loss: 0.7004 - accuracy: 0.789 - ETA: 17s - loss: 0.6973 - accuracy: 0.790 - ETA: 17s - loss: 0.6924 - accuracy: 0.792 - ETA: 17s - loss: 0.6835 - accuracy: 0.793 - ETA: 16s - loss: 0.6783 - accuracy: 0.795 - ETA: 16s - loss: 0.6772 - accuracy: 0.796 - ETA: 16s - loss: 0.6681 - accuracy: 0.798 - ETA: 16s - loss: 0.6660 - accuracy: 0.799 - ETA: 16s - loss: 0.6589 - accuracy: 0.802 - ETA: 16s - loss: 0.6526 - accuracy: 0.804 - ETA: 16s - loss: 0.6510 - accuracy: 0.804 - ETA: 16s - loss: 0.6466 - accuracy: 0.806 - ETA: 16s - loss: 0.6418 - accuracy: 0.807 - ETA: 15s - loss: 0.6381 - accuracy: 0.808 - ETA: 15s - loss: 0.6327 - accuracy: 0.809 - ETA: 15s - loss: 0.6315 - accuracy: 0.809 - ETA: 15s - loss: 0.6291 - accuracy: 0.810 - ETA: 15s - loss: 0.6273 - accuracy: 0.811 - ETA: 15s - loss: 0.6217 - accuracy: 0.812 - ETA: 15s - loss: 0.6178 - accuracy: 0.814 - ETA: 15s - loss: 0.6150 - accuracy: 0.814 - ETA: 15s - loss: 0.6118 - accuracy: 0.815 - ETA: 15s - loss: 0.6086 - accuracy: 0.816 - ETA: 15s - loss: 0.6062 - accuracy: 0.817 - ETA: 14s - loss: 0.6047 - accuracy: 0.817 - ETA: 14s - loss: 0.6040 - accuracy: 0.818 - ETA: 14s - loss: 0.6008 - accuracy: 0.819 - ETA: 14s - loss: 0.5984 - accuracy: 0.820 - ETA: 14s - loss: 0.5922 - accuracy: 0.822 - ETA: 14s - loss: 0.5905 - accuracy: 0.823 - ETA: 14s - loss: 0.5868 - accuracy: 0.824 - ETA: 14s - loss: 0.5849 - accuracy: 0.824 - ETA: 14s - loss: 0.5827 - accuracy: 0.825 - ETA: 14s - loss: 0.5801 - accuracy: 0.826 - ETA: 13s - loss: 0.5761 - accuracy: 0.827 - ETA: 13s - loss: 0.5747 - accuracy: 0.828 - ETA: 13s - loss: 0.5713 - accuracy: 0.829 - ETA: 13s - loss: 0.5686 - accuracy: 0.830 - ETA: 13s - loss: 0.5661 - accuracy: 0.830 - ETA: 13s - loss: 0.5646 - accuracy: 0.831 - ETA: 13s - loss: 0.5630 - accuracy: 0.832 - ETA: 13s - loss: 0.5610 - accuracy: 0.832 - ETA: 13s - loss: 0.5580 - accuracy: 0.833 - ETA: 13s - loss: 0.5565 - accuracy: 0.834 - ETA: 13s - loss: 0.5539 - accuracy: 0.835 - ETA: 13s - loss: 0.5515 - accuracy: 0.835 - ETA: 13s - loss: 0.5463 - accuracy: 0.837 - ETA: 13s - loss: 0.5438 - accuracy: 0.837 - ETA: 12s - loss: 0.5439 - accuracy: 0.837 - ETA: 12s - loss: 0.5414 - accuracy: 0.839 - ETA: 12s - loss: 0.5385 - accuracy: 0.840 - ETA: 12s - loss: 0.5368 - accuracy: 0.840 - ETA: 12s - loss: 0.5353 - accuracy: 0.840 - ETA: 12s - loss: 0.5346 - accuracy: 0.841 - ETA: 12s - loss: 0.5337 - accuracy: 0.841 - ETA: 12s - loss: 0.5315 - accuracy: 0.841 - ETA: 12s - loss: 0.5289 - accuracy: 0.842 - ETA: 12s - loss: 0.5261 - accuracy: 0.843 - ETA: 12s - loss: 0.5239 - accuracy: 0.844 - ETA: 12s - loss: 0.5224 - accuracy: 0.844 - ETA: 12s - loss: 0.5204 - accuracy: 0.845 - ETA: 11s - loss: 0.5158 - accuracy: 0.846 - ETA: 11s - loss: 0.5133 - accuracy: 0.847 - ETA: 11s - loss: 0.5113 - accuracy: 0.848 - ETA: 11s - loss: 0.5130 - accuracy: 0.847 - ETA: 11s - loss: 0.5108 - accuracy: 0.848 - ETA: 11s - loss: 0.5085 - accuracy: 0.849 - ETA: 11s - loss: 0.5065 - accuracy: 0.849 - ETA: 11s - loss: 0.5057 - accuracy: 0.849 - ETA: 11s - loss: 0.5043 - accuracy: 0.850 - ETA: 11s - loss: 0.5027 - accuracy: 0.850 - ETA: 11s - loss: 0.5008 - accuracy: 0.851 - ETA: 11s - loss: 0.4989 - accuracy: 0.851 - ETA: 10s - loss: 0.4977 - accuracy: 0.852 - ETA: 10s - loss: 0.4961 - accuracy: 0.852 - ETA: 10s - loss: 0.4924 - accuracy: 0.853 - ETA: 10s - loss: 0.4906 - accuracy: 0.854 - ETA: 10s - loss: 0.4878 - accuracy: 0.854 - ETA: 10s - loss: 0.4842 - accuracy: 0.856 - ETA: 10s - loss: 0.4819 - accuracy: 0.857 - ETA: 10s - loss: 0.4802 - accuracy: 0.857 - ETA: 10s - loss: 0.4791 - accuracy: 0.857 - ETA: 10s - loss: 0.4762 - accuracy: 0.858 - ETA: 10s - loss: 0.4748 - accuracy: 0.858 - ETA: 10s - loss: 0.4727 - accuracy: 0.859 - ETA: 9s - loss: 0.4717 - accuracy: 0.859 - ETA: 9s - loss: 0.4708 - accuracy: 0.85 - ETA: 9s - loss: 0.4703 - accuracy: 0.86 - ETA: 9s - loss: 0.4687 - accuracy: 0.86 - ETA: 9s - loss: 0.4655 - accuracy: 0.86 - ETA: 9s - loss: 0.4640 - accuracy: 0.86 - ETA: 9s - loss: 0.4626 - accuracy: 0.86 - ETA: 9s - loss: 0.4600 - accuracy: 0.86 - ETA: 9s - loss: 0.4585 - accuracy: 0.86 - ETA: 9s - loss: 0.4567 - accuracy: 0.86 - ETA: 9s - loss: 0.4549 - accuracy: 0.86 - ETA: 9s - loss: 0.4552 - accuracy: 0.86 - ETA: 9s - loss: 0.4542 - accuracy: 0.86 - ETA: 8s - loss: 0.4539 - accuracy: 0.86 - ETA: 8s - loss: 0.4524 - accuracy: 0.86 - ETA: 8s - loss: 0.4522 - accuracy: 0.86 - ETA: 8s - loss: 0.4508 - accuracy: 0.86 - ETA: 8s - loss: 0.4495 - accuracy: 0.86 - ETA: 8s - loss: 0.4471 - accuracy: 0.86 - ETA: 8s - loss: 0.4460 - accuracy: 0.86 - ETA: 8s - loss: 0.4456 - accuracy: 0.86 - ETA: 8s - loss: 0.4453 - accuracy: 0.86 - ETA: 8s - loss: 0.4443 - accuracy: 0.86 - ETA: 8s - loss: 0.4438 - accuracy: 0.86 - ETA: 8s - loss: 0.4425 - accuracy: 0.86 - ETA: 8s - loss: 0.4399 - accuracy: 0.86375/375 [==============================] - ETA: 7s - loss: 0.4371 - accuracy: 0.86 - ETA: 7s - loss: 0.4364 - accuracy: 0.86 - ETA: 7s - loss: 0.4347 - accuracy: 0.87 - ETA: 7s - loss: 0.4342 - accuracy: 0.87 - ETA: 7s - loss: 0.4330 - accuracy: 0.87 - ETA: 7s - loss: 0.4317 - accuracy: 0.87 - ETA: 7s - loss: 0.4304 - accuracy: 0.87 - ETA: 7s - loss: 0.4297 - accuracy: 0.87 - ETA: 7s - loss: 0.4292 - accuracy: 0.87 - ETA: 7s - loss: 0.4271 - accuracy: 0.87 - ETA: 7s - loss: 0.4263 - accuracy: 0.87 - ETA: 7s - loss: 0.4239 - accuracy: 0.87 - ETA: 7s - loss: 0.4229 - accuracy: 0.87 - ETA: 6s - loss: 0.4224 - accuracy: 0.87 - ETA: 6s - loss: 0.4209 - accuracy: 0.87 - ETA: 6s - loss: 0.4204 - accuracy: 0.87 - ETA: 6s - loss: 0.4192 - accuracy: 0.87 - ETA: 6s - loss: 0.4180 - accuracy: 0.87 - ETA: 6s - loss: 0.4186 - accuracy: 0.87 - ETA: 6s - loss: 0.4185 - accuracy: 0.87 - ETA: 6s - loss: 0.4172 - accuracy: 0.87 - ETA: 6s - loss: 0.4155 - accuracy: 0.87 - ETA: 6s - loss: 0.4141 - accuracy: 0.87 - ETA: 6s - loss: 0.4129 - accuracy: 0.87 - ETA: 6s - loss: 0.4127 - accuracy: 0.87 - ETA: 6s - loss: 0.4127 - accuracy: 0.87 - ETA: 6s - loss: 0.4115 - accuracy: 0.87 - ETA: 5s - loss: 0.4094 - accuracy: 0.87 - ETA: 5s - loss: 0.4084 - accuracy: 0.87 - ETA: 5s - loss: 0.4090 - accuracy: 0.87 - ETA: 5s - loss: 0.4115 - accuracy: 0.87 - ETA: 5s - loss: 0.4104 - accuracy: 0.87 - ETA: 5s - loss: 0.4096 - accuracy: 0.87 - ETA: 5s - loss: 0.4092 - accuracy: 0.87 - ETA: 5s - loss: 0.4094 - accuracy: 0.87 - ETA: 5s - loss: 0.4084 - accuracy: 0.87 - ETA: 5s - loss: 0.4079 - accuracy: 0.87 - ETA: 5s - loss: 0.4071 - accuracy: 0.87 - ETA: 5s - loss: 0.4059 - accuracy: 0.87 - ETA: 5s - loss: 0.4050 - accuracy: 0.87 - ETA: 5s - loss: 0.4059 - accuracy: 0.87 - ETA: 4s - loss: 0.4051 - accuracy: 0.87 - ETA: 4s - loss: 0.4041 - accuracy: 0.87 - ETA: 4s - loss: 0.4030 - accuracy: 0.87 - ETA: 4s - loss: 0.4027 - accuracy: 0.87 - ETA: 4s - loss: 0.4017 - accuracy: 0.88 - ETA: 4s - loss: 0.4013 - accuracy: 0.88 - ETA: 4s - loss: 0.4005 - accuracy: 0.88 - ETA: 4s - loss: 0.3999 - accuracy: 0.88 - ETA: 4s - loss: 0.4006 - accuracy: 0.88 - ETA: 4s - loss: 0.4003 - accuracy: 0.88 - ETA: 4s - loss: 0.3996 - accuracy: 0.88 - ETA: 4s - loss: 0.3984 - accuracy: 0.88 - ETA: 4s - loss: 0.3978 - accuracy: 0.88 - ETA: 4s - loss: 0.3972 - accuracy: 0.88 - ETA: 3s - loss: 0.3962 - accuracy: 0.88 - ETA: 3s - loss: 0.3945 - accuracy: 0.88 - ETA: 3s - loss: 0.3935 - accuracy: 0.88 - ETA: 3s - loss: 0.3923 - accuracy: 0.88 - ETA: 3s - loss: 0.3917 - accuracy: 0.88 - ETA: 3s - loss: 0.3905 - accuracy: 0.88 - ETA: 3s - loss: 0.3895 - accuracy: 0.88 - ETA: 3s - loss: 0.3888 - accuracy: 0.88 - ETA: 3s - loss: 0.3877 - accuracy: 0.88 - ETA: 3s - loss: 0.3876 - accuracy: 0.88 - ETA: 3s - loss: 0.3868 - accuracy: 0.88 - ETA: 3s - loss: 0.3860 - accuracy: 0.88 - ETA: 3s - loss: 0.3855 - accuracy: 0.88 - ETA: 3s - loss: 0.3849 - accuracy: 0.88 - ETA: 3s - loss: 0.3852 - accuracy: 0.88 - ETA: 3s - loss: 0.3851 - accuracy: 0.88 - ETA: 2s - loss: 0.3844 - accuracy: 0.88 - ETA: 2s - loss: 0.3840 - accuracy: 0.88 - ETA: 2s - loss: 0.3830 - accuracy: 0.88 - ETA: 2s - loss: 0.3822 - accuracy: 0.88 - ETA: 2s - loss: 0.3811 - accuracy: 0.88 - ETA: 2s - loss: 0.3801 - accuracy: 0.88 - ETA: 2s - loss: 0.3798 - accuracy: 0.88 - ETA: 2s - loss: 0.3792 - accuracy: 0.88 - ETA: 2s - loss: 0.3775 - accuracy: 0.88 - ETA: 2s - loss: 0.3767 - accuracy: 0.88 - ETA: 2s - loss: 0.3752 - accuracy: 0.88 - ETA: 2s - loss: 0.3742 - accuracy: 0.88 - ETA: 2s - loss: 0.3735 - accuracy: 0.88 - ETA: 2s - loss: 0.3736 - accuracy: 0.88 - ETA: 2s - loss: 0.3728 - accuracy: 0.88 - ETA: 2s - loss: 0.3725 - accuracy: 0.88 - ETA: 1s - loss: 0.3717 - accuracy: 0.88 - ETA: 1s - loss: 0.3715 - accuracy: 0.88 - ETA: 1s - loss: 0.3710 - accuracy: 0.88 - ETA: 1s - loss: 0.3703 - accuracy: 0.88 - ETA: 1s - loss: 0.3694 - accuracy: 0.88 - ETA: 1s - loss: 0.3703 - accuracy: 0.88 - ETA: 1s - loss: 0.3697 - accuracy: 0.88 - ETA: 1s - loss: 0.3691 - accuracy: 0.88 - ETA: 1s - loss: 0.3685 - accuracy: 0.88 - ETA: 1s - loss: 0.3677 - accuracy: 0.89 - ETA: 1s - loss: 0.3669 - accuracy: 0.89 - ETA: 1s - loss: 0.3661 - accuracy: 0.89 - ETA: 1s - loss: 0.3657 - accuracy: 0.89 - ETA: 1s - loss: 0.3641 - accuracy: 0.89 - ETA: 1s - loss: 0.3632 - accuracy: 0.89 - ETA: 1s - loss: 0.3622 - accuracy: 0.89 - ETA: 1s - loss: 0.3619 - accuracy: 0.89 - ETA: 0s - loss: 0.3611 - accuracy: 0.89 - ETA: 0s - loss: 0.3605 - accuracy: 0.89 - ETA: 0s - loss: 0.3602 - accuracy: 0.89 - ETA: 0s - loss: 0.3594 - accuracy: 0.89 - ETA: 0s - loss: 0.3591 - accuracy: 0.89 - ETA: 0s - loss: 0.3592 - accuracy: 0.89 - ETA: 0s - loss: 0.3592 - accuracy: 0.89 - ETA: 0s - loss: 0.3592 - accuracy: 0.89 - ETA: 0s - loss: 0.3586 - accuracy: 0.89 - ETA: 0s - loss: 0.3583 - accuracy: 0.89 - ETA: 0s - loss: 0.3580 - accuracy: 0.89 - ETA: 0s - loss: 0.3573 - accuracy: 0.89 - ETA: 0s - loss: 0.3570 - accuracy: 0.89 - ETA: 0s - loss: 0.3565 - accuracy: 0.89 - ETA: 0s - loss: 0.3557 - accuracy: 0.89 - ETA: 0s - loss: 0.3552 - accuracy: 0.89 - 40s 105ms/step - loss: 0.3545 - accuracy: 0.8944 - val_loss: 0.1505 - val_accuracy: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 8ff5ddbcf0cdf4ce3723ababc5b55f61</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.15054753290923933</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-classification_head_1/spatial_reduction_1/reduction_type: flatten</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_block_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_block_1/units_0: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-image_block_1/augment: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-image_block_1/block_type: vanilla</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-image_block_1/conv_block_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-image_block_1/conv_block_1/filters_0_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-image_block_1/conv_block_1/filters_0_1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-image_block_1/conv_block_1/kernel_size: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-image_block_1/conv_block_1/max_pooling: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-image_block_1/conv_block_1/num_blocks: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-image_block_1/conv_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-image_block_1/conv_block_1/separable: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-image_block_1/normalize: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Train for 1875 steps, validate for 1500 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 228/1875 [==>...........................] - ETA: 38:11 - loss: 2.4305 - accuracy: 0.062 - ETA: 19:52 - loss: 2.3743 - accuracy: 0.093 - ETA: 10:43 - loss: 2.2354 - accuracy: 0.179 - ETA: 8:55 - loss: 2.2009 - accuracy: 0.218 - ETA: 7:41 - loss: 2.1868 - accuracy: 0.22 - ETA: 6:50 - loss: 2.1122 - accuracy: 0.27 - ETA: 6:11 - loss: 2.0857 - accuracy: 0.29 - ETA: 5:41 - loss: 2.0577 - accuracy: 0.30 - ETA: 4:55 - loss: 1.9433 - accuracy: 0.37 - ETA: 4:38 - loss: 1.8826 - accuracy: 0.41 - ETA: 4:24 - loss: 1.8303 - accuracy: 0.43 - ETA: 4:02 - loss: 1.7113 - accuracy: 0.48 - ETA: 3:52 - loss: 1.6909 - accuracy: 0.49 - ETA: 3:36 - loss: 1.6024 - accuracy: 0.52 - ETA: 3:24 - loss: 1.5535 - accuracy: 0.52 - ETA: 3:19 - loss: 1.5354 - accuracy: 0.52 - ETA: 3:09 - loss: 1.4837 - accuracy: 0.54 - ETA: 3:04 - loss: 1.4579 - accuracy: 0.55 - ETA: 3:01 - loss: 1.4340 - accuracy: 0.55 - ETA: 2:54 - loss: 1.3715 - accuracy: 0.57 - ETA: 2:51 - loss: 1.3523 - accuracy: 0.58 - ETA: 2:48 - loss: 1.3345 - accuracy: 0.59 - ETA: 2:46 - loss: 1.3185 - accuracy: 0.59 - ETA: 2:41 - loss: 1.2848 - accuracy: 0.60 - ETA: 2:39 - loss: 1.2706 - accuracy: 0.60 - ETA: 2:37 - loss: 1.2586 - accuracy: 0.61 - ETA: 2:35 - loss: 1.2400 - accuracy: 0.61 - ETA: 2:34 - loss: 1.2335 - accuracy: 0.61 - ETA: 2:30 - loss: 1.1913 - accuracy: 0.62 - ETA: 2:29 - loss: 1.1946 - accuracy: 0.63 - ETA: 2:27 - loss: 1.1813 - accuracy: 0.63 - ETA: 2:26 - loss: 1.1713 - accuracy: 0.63 - ETA: 2:23 - loss: 1.1555 - accuracy: 0.64 - ETA: 2:21 - loss: 1.1342 - accuracy: 0.65 - ETA: 2:20 - loss: 1.1220 - accuracy: 0.65 - ETA: 2:19 - loss: 1.1070 - accuracy: 0.66 - ETA: 2:18 - loss: 1.0968 - accuracy: 0.66 - ETA: 2:17 - loss: 1.0837 - accuracy: 0.66 - ETA: 2:16 - loss: 1.0718 - accuracy: 0.66 - ETA: 2:15 - loss: 1.0627 - accuracy: 0.66 - ETA: 2:13 - loss: 1.0406 - accuracy: 0.67 - ETA: 2:12 - loss: 1.0258 - accuracy: 0.68 - ETA: 2:12 - loss: 1.0134 - accuracy: 0.68 - ETA: 2:11 - loss: 1.0040 - accuracy: 0.68 - ETA: 2:10 - loss: 0.9943 - accuracy: 0.69 - ETA: 2:09 - loss: 0.9790 - accuracy: 0.69 - ETA: 2:07 - loss: 0.9631 - accuracy: 0.69 - ETA: 2:06 - loss: 0.9460 - accuracy: 0.70 - ETA: 2:05 - loss: 0.9409 - accuracy: 0.70 - ETA: 2:05 - loss: 0.9332 - accuracy: 0.70 - ETA: 2:04 - loss: 0.9250 - accuracy: 0.70 - ETA: 2:04 - loss: 0.9165 - accuracy: 0.71 - ETA: 2:03 - loss: 0.9051 - accuracy: 0.71 - ETA: 2:03 - loss: 0.8983 - accuracy: 0.71 - ETA: 2:03 - loss: 0.8910 - accuracy: 0.72 - ETA: 2:02 - loss: 0.8801 - accuracy: 0.72 - ETA: 2:01 - loss: 0.8643 - accuracy: 0.72 - ETA: 2:00 - loss: 0.8506 - accuracy: 0.73 - ETA: 2:00 - loss: 0.8491 - accuracy: 0.73 - ETA: 1:59 - loss: 0.8360 - accuracy: 0.73 - ETA: 1:58 - loss: 0.8272 - accuracy: 0.74 - ETA: 1:58 - loss: 0.8222 - accuracy: 0.74 - ETA: 1:58 - loss: 0.8152 - accuracy: 0.74 - ETA: 1:57 - loss: 0.8104 - accuracy: 0.74 - ETA: 1:57 - loss: 0.8070 - accuracy: 0.74 - ETA: 1:56 - loss: 0.8010 - accuracy: 0.74 - ETA: 1:56 - loss: 0.7962 - accuracy: 0.74 - ETA: 1:56 - loss: 0.7902 - accuracy: 0.75 - ETA: 1:55 - loss: 0.7837 - accuracy: 0.75 - ETA: 1:55 - loss: 0.7773 - accuracy: 0.75 - ETA: 1:54 - loss: 0.7734 - accuracy: 0.75 - ETA: 1:54 - loss: 0.7681 - accuracy: 0.75 - ETA: 1:54 - loss: 0.7622 - accuracy: 0.76 - ETA: 1:53 - loss: 0.7572 - accuracy: 0.76 - ETA: 1:53 - loss: 0.7531 - accuracy: 0.76 - ETA: 1:53 - loss: 0.7459 - accuracy: 0.76 - ETA: 1:52 - loss: 0.7414 - accuracy: 0.76 - ETA: 1:52 - loss: 0.7366 - accuracy: 0.76 - ETA: 1:51 - loss: 0.7286 - accuracy: 0.77 - ETA: 1:51 - loss: 0.7232 - accuracy: 0.77 - ETA: 1:51 - loss: 0.7221 - accuracy: 0.77 - ETA: 1:50 - loss: 0.7140 - accuracy: 0.77 - ETA: 1:50 - loss: 0.7094 - accuracy: 0.77 - ETA: 1:50 - loss: 0.7052 - accuracy: 0.78 - ETA: 1:50 - loss: 0.7016 - accuracy: 0.78 - ETA: 1:49 - loss: 0.6987 - accuracy: 0.78 - ETA: 1:49 - loss: 0.6970 - accuracy: 0.78 - ETA: 1:49 - loss: 0.6927 - accuracy: 0.78 - ETA: 1:49 - loss: 0.6876 - accuracy: 0.78 - ETA: 1:49 - loss: 0.6836 - accuracy: 0.78 - ETA: 1:48 - loss: 0.6773 - accuracy: 0.78 - ETA: 1:48 - loss: 0.6760 - accuracy: 0.78 - ETA: 1:48 - loss: 0.6735 - accuracy: 0.79 - ETA: 1:48 - loss: 0.6706 - accuracy: 0.79 - ETA: 1:47 - loss: 0.6680 - accuracy: 0.79 - ETA: 1:47 - loss: 0.6614 - accuracy: 0.79 - ETA: 1:47 - loss: 0.6574 - accuracy: 0.79 - ETA: 1:47 - loss: 0.6538 - accuracy: 0.79 - ETA: 1:46 - loss: 0.6477 - accuracy: 0.79 - ETA: 1:46 - loss: 0.6446 - accuracy: 0.80 - ETA: 1:46 - loss: 0.6411 - accuracy: 0.80 - ETA: 1:45 - loss: 0.6402 - accuracy: 0.80 - ETA: 1:45 - loss: 0.6387 - accuracy: 0.80 - ETA: 1:45 - loss: 0.6352 - accuracy: 0.80 - ETA: 1:45 - loss: 0.6320 - accuracy: 0.80 - ETA: 1:45 - loss: 0.6311 - accuracy: 0.80 - ETA: 1:44 - loss: 0.6255 - accuracy: 0.80 - ETA: 1:44 - loss: 0.6222 - accuracy: 0.80 - ETA: 1:44 - loss: 0.6198 - accuracy: 0.80 - ETA: 1:44 - loss: 0.6162 - accuracy: 0.81 - ETA: 1:44 - loss: 0.6145 - accuracy: 0.81 - ETA: 1:44 - loss: 0.6123 - accuracy: 0.81 - ETA: 1:43 - loss: 0.6086 - accuracy: 0.81 - ETA: 1:43 - loss: 0.6020 - accuracy: 0.81 - ETA: 1:43 - loss: 0.5995 - accuracy: 0.81 - ETA: 1:43 - loss: 0.5975 - accuracy: 0.81 - ETA: 1:43 - loss: 0.5952 - accuracy: 0.81 - ETA: 1:43 - loss: 0.5921 - accuracy: 0.81 - ETA: 1:42 - loss: 0.5878 - accuracy: 0.81 - ETA: 1:42 - loss: 0.5855 - accuracy: 0.82 - ETA: 1:42 - loss: 0.5831 - accuracy: 0.82 - ETA: 1:42 - loss: 0.5802 - accuracy: 0.82 - ETA: 1:42 - loss: 0.5768 - accuracy: 0.82 - ETA: 1:42 - loss: 0.5758 - accuracy: 0.82 - ETA: 1:41 - loss: 0.5734 - accuracy: 0.82 - ETA: 1:41 - loss: 0.5707 - accuracy: 0.82 - ETA: 1:41 - loss: 0.5687 - accuracy: 0.82 - ETA: 1:41 - loss: 0.5662 - accuracy: 0.82 - ETA: 1:41 - loss: 0.5657 - accuracy: 0.82 - ETA: 1:40 - loss: 0.5604 - accuracy: 0.82 - ETA: 1:40 - loss: 0.5561 - accuracy: 0.82 - ETA: 1:40 - loss: 0.5547 - accuracy: 0.82 - ETA: 1:40 - loss: 0.5534 - accuracy: 0.83 - ETA: 1:40 - loss: 0.5489 - accuracy: 0.83 - ETA: 1:39 - loss: 0.5463 - accuracy: 0.83 - ETA: 1:39 - loss: 0.5443 - accuracy: 0.83 - ETA: 1:39 - loss: 0.5418 - accuracy: 0.83 - ETA: 1:39 - loss: 0.5425 - accuracy: 0.83 - ETA: 1:39 - loss: 0.5402 - accuracy: 0.83 - ETA: 1:39 - loss: 0.5383 - accuracy: 0.83 - ETA: 1:39 - loss: 0.5369 - accuracy: 0.83 - ETA: 1:39 - loss: 0.5345 - accuracy: 0.83 - ETA: 1:38 - loss: 0.5312 - accuracy: 0.83 - ETA: 1:38 - loss: 0.5291 - accuracy: 0.83 - ETA: 1:38 - loss: 0.5258 - accuracy: 0.83 - ETA: 1:38 - loss: 0.5232 - accuracy: 0.84 - ETA: 1:38 - loss: 0.5213 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5172 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5150 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5134 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5123 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5109 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5065 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5048 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5036 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5023 - accuracy: 0.84 - ETA: 1:36 - loss: 0.5004 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4988 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4967 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4954 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4935 - accuracy: 0.85 - ETA: 1:36 - loss: 0.4916 - accuracy: 0.85 - ETA: 1:36 - loss: 0.4895 - accuracy: 0.85 - ETA: 1:36 - loss: 0.4878 - accuracy: 0.85 - ETA: 1:36 - loss: 0.4861 - accuracy: 0.85 - ETA: 1:36 - loss: 0.4842 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4831 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4814 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4800 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4782 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4775 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4770 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4763 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4768 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4758 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4747 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4746 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4719 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4701 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4694 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4683 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4681 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4681 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4677 - accuracy: 0.85 439/1875 [======>.......................] - ETA: 1:34 - loss: 0.4668 - accuracy: 0.85 - ETA: 1:33 - loss: 0.4657 - accuracy: 0.85 - ETA: 1:33 - loss: 0.4643 - accuracy: 0.85 - ETA: 1:33 - loss: 0.4613 - accuracy: 0.85 - ETA: 1:33 - loss: 0.4597 - accuracy: 0.85 - ETA: 1:33 - loss: 0.4582 - accuracy: 0.86 - ETA: 1:33 - loss: 0.4579 - accuracy: 0.86 - ETA: 1:33 - loss: 0.4551 - accuracy: 0.86 - ETA: 1:33 - loss: 0.4541 - accuracy: 0.86 - ETA: 1:33 - loss: 0.4528 - accuracy: 0.86 - ETA: 1:32 - loss: 0.4502 - accuracy: 0.86 - ETA: 1:32 - loss: 0.4489 - accuracy: 0.86 - ETA: 1:32 - loss: 0.4479 - accuracy: 0.86 - ETA: 1:32 - loss: 0.4468 - accuracy: 0.86 - ETA: 1:32 - loss: 0.4458 - accuracy: 0.86 - ETA: 1:32 - loss: 0.4443 - accuracy: 0.86 - ETA: 1:32 - loss: 0.4432 - accuracy: 0.86 - ETA: 1:32 - loss: 0.4421 - accuracy: 0.86 - ETA: 1:32 - loss: 0.4418 - accuracy: 0.86 - ETA: 1:31 - loss: 0.4404 - accuracy: 0.86 - ETA: 1:31 - loss: 0.4389 - accuracy: 0.86 - ETA: 1:31 - loss: 0.4376 - accuracy: 0.86 - ETA: 1:31 - loss: 0.4368 - accuracy: 0.86 - ETA: 1:31 - loss: 0.4363 - accuracy: 0.86 - ETA: 1:31 - loss: 0.4352 - accuracy: 0.86 - ETA: 1:31 - loss: 0.4339 - accuracy: 0.86 - ETA: 1:31 - loss: 0.4326 - accuracy: 0.86 - ETA: 1:30 - loss: 0.4307 - accuracy: 0.86 - ETA: 1:30 - loss: 0.4306 - accuracy: 0.86 - ETA: 1:30 - loss: 0.4310 - accuracy: 0.86 - ETA: 1:30 - loss: 0.4296 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4285 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4272 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4264 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4260 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4269 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4290 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4284 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4279 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4272 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4265 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4260 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4260 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4250 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4243 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4238 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4224 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4213 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4216 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4209 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4198 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4185 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4180 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4176 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4170 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4164 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4155 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4151 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4154 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4148 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4140 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4130 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4123 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4108 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4093 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4071 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4073 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4062 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4049 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4040 - accuracy: 0.87 - ETA: 1:28 - loss: 0.4028 - accuracy: 0.87 - ETA: 1:28 - loss: 0.4019 - accuracy: 0.87 - ETA: 1:28 - loss: 0.3998 - accuracy: 0.87 - ETA: 1:28 - loss: 0.3995 - accuracy: 0.87 - ETA: 1:28 - loss: 0.3987 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3979 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3966 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3965 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3964 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3960 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3954 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3944 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3934 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3924 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3912 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3904 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3896 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3885 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3876 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3865 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3864 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3854 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3846 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3843 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3838 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3829 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3821 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3819 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3814 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3807 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3797 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3802 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3797 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3788 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3773 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3764 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3749 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3742 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3734 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3725 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3716 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3701 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3692 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3684 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3676 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3673 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3673 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3667 - accuracy: 0.88 - ETA: 1:24 - loss: 0.3657 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3660 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3648 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3640 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3632 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3631 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3628 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3619 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3613 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3607 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3600 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3596 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3593 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3586 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3578 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3571 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3567 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3559 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3562 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3561 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3552 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3548 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3543 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3537 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3529 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3523 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3525 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3528 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3523 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3521 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3521 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3513 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3505 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3494 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3489 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3478 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3468 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3465 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3464 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3456 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3454 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3447 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3448 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3440 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3435 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3429 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3424 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3418 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3416 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3412 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3408 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3401 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3393 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3386 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3379 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3375 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3371 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3370 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3370 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3363 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3356 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3354 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3349 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3347 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3343 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3348 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3345 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3340 - accuracy: 0.8997 643/1875 [=========>....................] - ETA: 1:20 - loss: 0.3334 - accuracy: 0.89 - ETA: 1:20 - loss: 0.3323 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3320 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3318 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3309 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3304 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3300 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3299 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3294 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3288 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3277 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3273 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3265 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3262 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3258 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3253 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3253 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3252 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3250 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3246 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3244 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3238 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3231 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3224 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3221 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3215 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3215 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3212 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3211 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3204 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3200 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3190 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3187 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3182 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3177 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3170 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3166 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3161 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3156 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3151 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3146 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3140 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3135 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3133 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3131 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3128 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3126 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3125 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3120 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3128 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3123 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3121 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3115 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3112 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3108 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3102 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3100 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3094 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3091 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3087 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3082 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3081 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3075 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3070 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3065 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3062 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3057 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3060 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3056 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3051 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3047 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3044 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3041 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3039 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3035 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3030 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3025 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3023 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3020 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3017 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3014 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3009 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3004 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3004 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3000 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2994 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2994 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2993 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2989 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2984 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2979 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2975 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2973 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2970 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2966 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2967 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2963 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2962 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2957 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2953 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2948 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2945 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2942 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2942 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2941 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2938 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2934 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2933 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2929 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2927 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2925 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2921 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2918 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2914 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2909 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2904 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2900 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2898 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2894 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2889 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2887 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2883 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2879 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2876 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2875 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2872 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2867 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2864 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2861 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2857 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2853 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2851 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2847 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2842 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2839 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2838 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2833 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2829 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2825 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2820 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2818 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2814 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2811 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2810 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2810 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2803 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2800 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2800 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2792 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2788 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2787 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2784 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2780 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2777 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2776 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2772 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2770 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2767 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2763 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2759 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2755 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2751 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2747 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2746 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2744 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2744 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2736 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2733 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2731 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2732 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2730 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2731 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2728 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2725 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2724 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2721 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2718 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2714 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2711 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2710 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2706 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2702 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2699 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2697 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2693 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2687 - accuracy: 0.9187 842/1875 [============>.................] - ETA: 1:08 - loss: 0.2684 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2680 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2679 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2677 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2678 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2676 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2677 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2674 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2668 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2669 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2666 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2662 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2661 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2662 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2659 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2658 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2655 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2652 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2649 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2646 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2646 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2642 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2640 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2638 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2635 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2633 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2629 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2626 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2623 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2624 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2625 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2623 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2621 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2621 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2617 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2614 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2610 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2608 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2605 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2606 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2605 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2604 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2600 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2597 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2594 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2592 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2591 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2588 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2588 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2589 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2586 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2584 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2582 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2579 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2573 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2571 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2569 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2568 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2570 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2571 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2569 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2567 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2567 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2564 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2562 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2560 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2557 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2554 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2551 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2548 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2545 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2542 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2540 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2537 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2540 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2537 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2535 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2533 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2531 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2528 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2525 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2519 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2517 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2514 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2511 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2510 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2507 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2504 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2501 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2501 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2501 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2498 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2496 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2495 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2490 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2488 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2486 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2483 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2483 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2484 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2481 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2478 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2477 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2474 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2472 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2470 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2467 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2465 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2462 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2460 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2457 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2455 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2451 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2448 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2446 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2444 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2442 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2443 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2443 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2443 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2441 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2439 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2438 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2442 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2440 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2439 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2438 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2436 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2434 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2431 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2429 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2427 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2426 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2423 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2423 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2421 - accuracy: 0.92 - ETA: 59s - loss: 0.2419 - accuracy: 0.9266 - ETA: 59s - loss: 0.2416 - accuracy: 0.926 - ETA: 59s - loss: 0.2413 - accuracy: 0.926 - ETA: 59s - loss: 0.2410 - accuracy: 0.926 - ETA: 59s - loss: 0.2407 - accuracy: 0.927 - ETA: 59s - loss: 0.2404 - accuracy: 0.927 - ETA: 59s - loss: 0.2402 - accuracy: 0.927 - ETA: 59s - loss: 0.2403 - accuracy: 0.927 - ETA: 59s - loss: 0.2401 - accuracy: 0.927 - ETA: 59s - loss: 0.2402 - accuracy: 0.927 - ETA: 59s - loss: 0.2399 - accuracy: 0.927 - ETA: 59s - loss: 0.2398 - accuracy: 0.927 - ETA: 59s - loss: 0.2396 - accuracy: 0.927 - ETA: 59s - loss: 0.2395 - accuracy: 0.927 - ETA: 59s - loss: 0.2393 - accuracy: 0.927 - ETA: 59s - loss: 0.2391 - accuracy: 0.927 - ETA: 59s - loss: 0.2388 - accuracy: 0.927 - ETA: 58s - loss: 0.2388 - accuracy: 0.927 - ETA: 58s - loss: 0.2388 - accuracy: 0.927 - ETA: 58s - loss: 0.2385 - accuracy: 0.927 - ETA: 58s - loss: 0.2382 - accuracy: 0.927 - ETA: 58s - loss: 0.2379 - accuracy: 0.927 - ETA: 58s - loss: 0.2377 - accuracy: 0.927 - ETA: 58s - loss: 0.2375 - accuracy: 0.928 - ETA: 58s - loss: 0.2375 - accuracy: 0.928 - ETA: 58s - loss: 0.2372 - accuracy: 0.928 - ETA: 58s - loss: 0.2370 - accuracy: 0.928 - ETA: 58s - loss: 0.2365 - accuracy: 0.928 - ETA: 58s - loss: 0.2362 - accuracy: 0.928 - ETA: 58s - loss: 0.2361 - accuracy: 0.928 - ETA: 58s - loss: 0.2358 - accuracy: 0.928 - ETA: 58s - loss: 0.2355 - accuracy: 0.928 - ETA: 58s - loss: 0.2354 - accuracy: 0.928 - ETA: 57s - loss: 0.2356 - accuracy: 0.928 - ETA: 57s - loss: 0.2355 - accuracy: 0.928 - ETA: 57s - loss: 0.2354 - accuracy: 0.928 - ETA: 57s - loss: 0.2352 - accuracy: 0.928 - ETA: 57s - loss: 0.2352 - accuracy: 0.928 - ETA: 57s - loss: 0.2353 - accuracy: 0.928 - ETA: 57s - loss: 0.2351 - accuracy: 0.928 - ETA: 57s - loss: 0.2356 - accuracy: 0.928 - ETA: 57s - loss: 0.2353 - accuracy: 0.929 - ETA: 57s - loss: 0.2351 - accuracy: 0.929 - ETA: 57s - loss: 0.2353 - accuracy: 0.929 - ETA: 57s - loss: 0.2352 - accuracy: 0.929 - ETA: 57s - loss: 0.2349 - accuracy: 0.929 - ETA: 57s - loss: 0.2348 - accuracy: 0.929 - ETA: 57s - loss: 0.2348 - accuracy: 0.929 - ETA: 57s - loss: 0.2348 - accuracy: 0.929 - ETA: 56s - loss: 0.2347 - accuracy: 0.9293"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1875 [===============>..............] - ETA: 56s - loss: 0.2345 - accuracy: 0.929 - ETA: 56s - loss: 0.2342 - accuracy: 0.929 - ETA: 56s - loss: 0.2340 - accuracy: 0.929 - ETA: 56s - loss: 0.2337 - accuracy: 0.929 - ETA: 56s - loss: 0.2335 - accuracy: 0.929 - ETA: 56s - loss: 0.2333 - accuracy: 0.929 - ETA: 56s - loss: 0.2331 - accuracy: 0.929 - ETA: 56s - loss: 0.2330 - accuracy: 0.929 - ETA: 56s - loss: 0.2328 - accuracy: 0.930 - ETA: 56s - loss: 0.2326 - accuracy: 0.930 - ETA: 56s - loss: 0.2324 - accuracy: 0.930 - ETA: 56s - loss: 0.2322 - accuracy: 0.930 - ETA: 56s - loss: 0.2318 - accuracy: 0.930 - ETA: 55s - loss: 0.2317 - accuracy: 0.930 - ETA: 55s - loss: 0.2316 - accuracy: 0.930 - ETA: 55s - loss: 0.2315 - accuracy: 0.930 - ETA: 55s - loss: 0.2313 - accuracy: 0.930 - ETA: 55s - loss: 0.2313 - accuracy: 0.930 - ETA: 55s - loss: 0.2311 - accuracy: 0.930 - ETA: 55s - loss: 0.2310 - accuracy: 0.930 - ETA: 55s - loss: 0.2308 - accuracy: 0.930 - ETA: 55s - loss: 0.2306 - accuracy: 0.930 - ETA: 55s - loss: 0.2304 - accuracy: 0.930 - ETA: 55s - loss: 0.2303 - accuracy: 0.930 - ETA: 55s - loss: 0.2301 - accuracy: 0.930 - ETA: 55s - loss: 0.2299 - accuracy: 0.930 - ETA: 55s - loss: 0.2295 - accuracy: 0.930 - ETA: 55s - loss: 0.2293 - accuracy: 0.930 - ETA: 54s - loss: 0.2292 - accuracy: 0.931 - ETA: 54s - loss: 0.2290 - accuracy: 0.931 - ETA: 54s - loss: 0.2288 - accuracy: 0.931 - ETA: 54s - loss: 0.2286 - accuracy: 0.931 - ETA: 54s - loss: 0.2286 - accuracy: 0.931 - ETA: 54s - loss: 0.2284 - accuracy: 0.931 - ETA: 54s - loss: 0.2282 - accuracy: 0.931 - ETA: 54s - loss: 0.2280 - accuracy: 0.931 - ETA: 54s - loss: 0.2278 - accuracy: 0.931 - ETA: 54s - loss: 0.2276 - accuracy: 0.931 - ETA: 54s - loss: 0.2276 - accuracy: 0.931 - ETA: 54s - loss: 0.2274 - accuracy: 0.931 - ETA: 54s - loss: 0.2272 - accuracy: 0.931 - ETA: 54s - loss: 0.2270 - accuracy: 0.931 - ETA: 54s - loss: 0.2268 - accuracy: 0.931 - ETA: 54s - loss: 0.2268 - accuracy: 0.931 - ETA: 53s - loss: 0.2266 - accuracy: 0.931 - ETA: 53s - loss: 0.2270 - accuracy: 0.931 - ETA: 53s - loss: 0.2268 - accuracy: 0.931 - ETA: 53s - loss: 0.2268 - accuracy: 0.931 - ETA: 53s - loss: 0.2266 - accuracy: 0.931 - ETA: 53s - loss: 0.2264 - accuracy: 0.931 - ETA: 53s - loss: 0.2262 - accuracy: 0.931 - ETA: 53s - loss: 0.2261 - accuracy: 0.931 - ETA: 53s - loss: 0.2259 - accuracy: 0.931 - ETA: 53s - loss: 0.2257 - accuracy: 0.932 - ETA: 53s - loss: 0.2255 - accuracy: 0.932 - ETA: 53s - loss: 0.2255 - accuracy: 0.932 - ETA: 53s - loss: 0.2252 - accuracy: 0.932 - ETA: 53s - loss: 0.2251 - accuracy: 0.932 - ETA: 53s - loss: 0.2250 - accuracy: 0.932 - ETA: 53s - loss: 0.2248 - accuracy: 0.932 - ETA: 53s - loss: 0.2246 - accuracy: 0.932 - ETA: 52s - loss: 0.2245 - accuracy: 0.932 - ETA: 52s - loss: 0.2243 - accuracy: 0.932 - ETA: 52s - loss: 0.2243 - accuracy: 0.932 - ETA: 52s - loss: 0.2240 - accuracy: 0.932 - ETA: 52s - loss: 0.2239 - accuracy: 0.932 - ETA: 52s - loss: 0.2238 - accuracy: 0.932 - ETA: 52s - loss: 0.2237 - accuracy: 0.932 - ETA: 52s - loss: 0.2235 - accuracy: 0.932 - ETA: 52s - loss: 0.2236 - accuracy: 0.932 - ETA: 52s - loss: 0.2234 - accuracy: 0.932 - ETA: 52s - loss: 0.2232 - accuracy: 0.932 - ETA: 52s - loss: 0.2232 - accuracy: 0.932 - ETA: 52s - loss: 0.2229 - accuracy: 0.932 - ETA: 52s - loss: 0.2229 - accuracy: 0.932 - ETA: 52s - loss: 0.2227 - accuracy: 0.932 - ETA: 52s - loss: 0.2224 - accuracy: 0.932 - ETA: 52s - loss: 0.2225 - accuracy: 0.932 - ETA: 52s - loss: 0.2223 - accuracy: 0.933 - ETA: 52s - loss: 0.2223 - accuracy: 0.933 - ETA: 51s - loss: 0.2221 - accuracy: 0.933 - ETA: 51s - loss: 0.2219 - accuracy: 0.933 - ETA: 51s - loss: 0.2217 - accuracy: 0.933 - ETA: 51s - loss: 0.2216 - accuracy: 0.933 - ETA: 51s - loss: 0.2214 - accuracy: 0.933 - ETA: 51s - loss: 0.2213 - accuracy: 0.933 - ETA: 51s - loss: 0.2212 - accuracy: 0.933 - ETA: 51s - loss: 0.2210 - accuracy: 0.933 - ETA: 51s - loss: 0.2208 - accuracy: 0.933 - ETA: 51s - loss: 0.2209 - accuracy: 0.933 - ETA: 51s - loss: 0.2207 - accuracy: 0.933 - ETA: 51s - loss: 0.2206 - accuracy: 0.933 - ETA: 51s - loss: 0.2205 - accuracy: 0.933 - ETA: 51s - loss: 0.2203 - accuracy: 0.933 - ETA: 51s - loss: 0.2201 - accuracy: 0.933 - ETA: 51s - loss: 0.2200 - accuracy: 0.933 - ETA: 51s - loss: 0.2198 - accuracy: 0.933 - ETA: 51s - loss: 0.2196 - accuracy: 0.933 - ETA: 50s - loss: 0.2194 - accuracy: 0.933 - ETA: 50s - loss: 0.2192 - accuracy: 0.933 - ETA: 50s - loss: 0.2190 - accuracy: 0.934 - ETA: 50s - loss: 0.2189 - accuracy: 0.934 - ETA: 50s - loss: 0.2188 - accuracy: 0.934 - ETA: 50s - loss: 0.2185 - accuracy: 0.934 - ETA: 50s - loss: 0.2183 - accuracy: 0.934 - ETA: 50s - loss: 0.2182 - accuracy: 0.934 - ETA: 50s - loss: 0.2181 - accuracy: 0.934 - ETA: 50s - loss: 0.2179 - accuracy: 0.934 - ETA: 50s - loss: 0.2178 - accuracy: 0.934 - ETA: 50s - loss: 0.2177 - accuracy: 0.934 - ETA: 50s - loss: 0.2175 - accuracy: 0.934 - ETA: 50s - loss: 0.2174 - accuracy: 0.934 - ETA: 50s - loss: 0.2171 - accuracy: 0.934 - ETA: 49s - loss: 0.2169 - accuracy: 0.934 - ETA: 49s - loss: 0.2168 - accuracy: 0.934 - ETA: 49s - loss: 0.2166 - accuracy: 0.934 - ETA: 49s - loss: 0.2164 - accuracy: 0.934 - ETA: 49s - loss: 0.2163 - accuracy: 0.934 - ETA: 49s - loss: 0.2162 - accuracy: 0.934 - ETA: 49s - loss: 0.2163 - accuracy: 0.934 - ETA: 49s - loss: 0.2160 - accuracy: 0.935 - ETA: 49s - loss: 0.2161 - accuracy: 0.934 - ETA: 49s - loss: 0.2159 - accuracy: 0.935 - ETA: 49s - loss: 0.2158 - accuracy: 0.935 - ETA: 49s - loss: 0.2158 - accuracy: 0.935 - ETA: 49s - loss: 0.2157 - accuracy: 0.935 - ETA: 49s - loss: 0.2155 - accuracy: 0.935 - ETA: 49s - loss: 0.2154 - accuracy: 0.935 - ETA: 48s - loss: 0.2152 - accuracy: 0.935 - ETA: 48s - loss: 0.2151 - accuracy: 0.935 - ETA: 48s - loss: 0.2149 - accuracy: 0.935 - ETA: 48s - loss: 0.2147 - accuracy: 0.935 - ETA: 48s - loss: 0.2147 - accuracy: 0.935 - ETA: 48s - loss: 0.2145 - accuracy: 0.935 - ETA: 48s - loss: 0.2147 - accuracy: 0.935 - ETA: 48s - loss: 0.2148 - accuracy: 0.935 - ETA: 48s - loss: 0.2148 - accuracy: 0.935 - ETA: 48s - loss: 0.2147 - accuracy: 0.935 - ETA: 48s - loss: 0.2145 - accuracy: 0.935 - ETA: 48s - loss: 0.2146 - accuracy: 0.935 - ETA: 48s - loss: 0.2144 - accuracy: 0.935 - ETA: 48s - loss: 0.2142 - accuracy: 0.935 - ETA: 48s - loss: 0.2145 - accuracy: 0.935 - ETA: 48s - loss: 0.2144 - accuracy: 0.935 - ETA: 48s - loss: 0.2144 - accuracy: 0.935 - ETA: 47s - loss: 0.2141 - accuracy: 0.935 - ETA: 47s - loss: 0.2141 - accuracy: 0.935 - ETA: 47s - loss: 0.2139 - accuracy: 0.935 - ETA: 47s - loss: 0.2138 - accuracy: 0.935 - ETA: 47s - loss: 0.2137 - accuracy: 0.935 - ETA: 47s - loss: 0.2135 - accuracy: 0.935 - ETA: 47s - loss: 0.2137 - accuracy: 0.935 - ETA: 47s - loss: 0.2135 - accuracy: 0.935 - ETA: 47s - loss: 0.2134 - accuracy: 0.935 - ETA: 47s - loss: 0.2137 - accuracy: 0.935 - ETA: 47s - loss: 0.2138 - accuracy: 0.935 - ETA: 47s - loss: 0.2138 - accuracy: 0.935 - ETA: 47s - loss: 0.2136 - accuracy: 0.935 - ETA: 47s - loss: 0.2135 - accuracy: 0.935 - ETA: 46s - loss: 0.2133 - accuracy: 0.935 - ETA: 46s - loss: 0.2131 - accuracy: 0.935 - ETA: 46s - loss: 0.2130 - accuracy: 0.935 - ETA: 46s - loss: 0.2127 - accuracy: 0.935 - ETA: 46s - loss: 0.2127 - accuracy: 0.935 - ETA: 46s - loss: 0.2126 - accuracy: 0.935 - ETA: 46s - loss: 0.2125 - accuracy: 0.935 - ETA: 46s - loss: 0.2126 - accuracy: 0.935 - ETA: 46s - loss: 0.2124 - accuracy: 0.935 - ETA: 46s - loss: 0.2122 - accuracy: 0.935 - ETA: 46s - loss: 0.2121 - accuracy: 0.935 - ETA: 46s - loss: 0.2119 - accuracy: 0.936 - ETA: 46s - loss: 0.2117 - accuracy: 0.936 - ETA: 46s - loss: 0.2116 - accuracy: 0.936 - ETA: 46s - loss: 0.2114 - accuracy: 0.936 - ETA: 46s - loss: 0.2113 - accuracy: 0.936 - ETA: 45s - loss: 0.2111 - accuracy: 0.936 - ETA: 45s - loss: 0.2110 - accuracy: 0.936 - ETA: 45s - loss: 0.2110 - accuracy: 0.936 - ETA: 45s - loss: 0.2109 - accuracy: 0.936 - ETA: 45s - loss: 0.2107 - accuracy: 0.936 - ETA: 45s - loss: 0.2106 - accuracy: 0.936 - ETA: 45s - loss: 0.2105 - accuracy: 0.936 - ETA: 45s - loss: 0.2103 - accuracy: 0.936 - ETA: 45s - loss: 0.2101 - accuracy: 0.936 - ETA: 45s - loss: 0.2100 - accuracy: 0.936 - ETA: 45s - loss: 0.2100 - accuracy: 0.9366"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1262/1875 [===================>..........] - ETA: 45s - loss: 0.2099 - accuracy: 0.936 - ETA: 45s - loss: 0.2097 - accuracy: 0.936 - ETA: 45s - loss: 0.2095 - accuracy: 0.936 - ETA: 45s - loss: 0.2094 - accuracy: 0.936 - ETA: 44s - loss: 0.2092 - accuracy: 0.936 - ETA: 44s - loss: 0.2091 - accuracy: 0.936 - ETA: 44s - loss: 0.2091 - accuracy: 0.936 - ETA: 44s - loss: 0.2090 - accuracy: 0.936 - ETA: 44s - loss: 0.2088 - accuracy: 0.937 - ETA: 44s - loss: 0.2086 - accuracy: 0.937 - ETA: 44s - loss: 0.2085 - accuracy: 0.937 - ETA: 44s - loss: 0.2083 - accuracy: 0.937 - ETA: 44s - loss: 0.2082 - accuracy: 0.937 - ETA: 44s - loss: 0.2081 - accuracy: 0.937 - ETA: 44s - loss: 0.2080 - accuracy: 0.937 - ETA: 44s - loss: 0.2076 - accuracy: 0.937 - ETA: 44s - loss: 0.2075 - accuracy: 0.937 - ETA: 44s - loss: 0.2073 - accuracy: 0.937 - ETA: 44s - loss: 0.2072 - accuracy: 0.937 - ETA: 44s - loss: 0.2070 - accuracy: 0.937 - ETA: 43s - loss: 0.2068 - accuracy: 0.937 - ETA: 43s - loss: 0.2067 - accuracy: 0.937 - ETA: 43s - loss: 0.2067 - accuracy: 0.937 - ETA: 43s - loss: 0.2066 - accuracy: 0.937 - ETA: 43s - loss: 0.2065 - accuracy: 0.937 - ETA: 43s - loss: 0.2066 - accuracy: 0.937 - ETA: 43s - loss: 0.2062 - accuracy: 0.937 - ETA: 43s - loss: 0.2061 - accuracy: 0.937 - ETA: 43s - loss: 0.2059 - accuracy: 0.937 - ETA: 43s - loss: 0.2061 - accuracy: 0.937 - ETA: 43s - loss: 0.2059 - accuracy: 0.938 - ETA: 43s - loss: 0.2058 - accuracy: 0.938 - ETA: 43s - loss: 0.2058 - accuracy: 0.938 - ETA: 43s - loss: 0.2059 - accuracy: 0.938 - ETA: 42s - loss: 0.2059 - accuracy: 0.938 - ETA: 42s - loss: 0.2058 - accuracy: 0.938 - ETA: 42s - loss: 0.2057 - accuracy: 0.938 - ETA: 42s - loss: 0.2056 - accuracy: 0.938 - ETA: 42s - loss: 0.2054 - accuracy: 0.938 - ETA: 42s - loss: 0.2052 - accuracy: 0.938 - ETA: 42s - loss: 0.2052 - accuracy: 0.938 - ETA: 42s - loss: 0.2051 - accuracy: 0.938 - ETA: 42s - loss: 0.2049 - accuracy: 0.938 - ETA: 42s - loss: 0.2049 - accuracy: 0.938 - ETA: 42s - loss: 0.2046 - accuracy: 0.938 - ETA: 42s - loss: 0.2045 - accuracy: 0.938 - ETA: 42s - loss: 0.2045 - accuracy: 0.938 - ETA: 42s - loss: 0.2042 - accuracy: 0.938 - ETA: 42s - loss: 0.2041 - accuracy: 0.938 - ETA: 41s - loss: 0.2040 - accuracy: 0.938 - ETA: 41s - loss: 0.2043 - accuracy: 0.938 - ETA: 41s - loss: 0.2042 - accuracy: 0.938 - ETA: 41s - loss: 0.2040 - accuracy: 0.938 - ETA: 41s - loss: 0.2039 - accuracy: 0.938 - ETA: 41s - loss: 0.2037 - accuracy: 0.938 - ETA: 41s - loss: 0.2036 - accuracy: 0.938 - ETA: 41s - loss: 0.2034 - accuracy: 0.938 - ETA: 41s - loss: 0.2033 - accuracy: 0.938 - ETA: 41s - loss: 0.2031 - accuracy: 0.938 - ETA: 41s - loss: 0.2030 - accuracy: 0.938 - ETA: 41s - loss: 0.2027 - accuracy: 0.938 - ETA: 41s - loss: 0.2025 - accuracy: 0.939 - ETA: 41s - loss: 0.2024 - accuracy: 0.939 - ETA: 41s - loss: 0.2023 - accuracy: 0.939 - ETA: 40s - loss: 0.2023 - accuracy: 0.939 - ETA: 40s - loss: 0.2024 - accuracy: 0.939 - ETA: 40s - loss: 0.2024 - accuracy: 0.939 - ETA: 40s - loss: 0.2023 - accuracy: 0.939 - ETA: 40s - loss: 0.2022 - accuracy: 0.939 - ETA: 40s - loss: 0.2021 - accuracy: 0.939 - ETA: 40s - loss: 0.2020 - accuracy: 0.939 - ETA: 40s - loss: 0.2019 - accuracy: 0.939 - ETA: 40s - loss: 0.2018 - accuracy: 0.939 - ETA: 40s - loss: 0.2016 - accuracy: 0.939 - ETA: 40s - loss: 0.2015 - accuracy: 0.939 - ETA: 40s - loss: 0.2013 - accuracy: 0.939 - ETA: 40s - loss: 0.2013 - accuracy: 0.939 - ETA: 40s - loss: 0.2013 - accuracy: 0.939 - ETA: 40s - loss: 0.2011 - accuracy: 0.939 - ETA: 40s - loss: 0.2010 - accuracy: 0.939 - ETA: 40s - loss: 0.2008 - accuracy: 0.939 - ETA: 40s - loss: 0.2007 - accuracy: 0.939 - ETA: 39s - loss: 0.2006 - accuracy: 0.939 - ETA: 39s - loss: 0.2005 - accuracy: 0.939 - ETA: 39s - loss: 0.2004 - accuracy: 0.939 - ETA: 39s - loss: 0.2003 - accuracy: 0.939 - ETA: 39s - loss: 0.2003 - accuracy: 0.939 - ETA: 39s - loss: 0.2004 - accuracy: 0.939 - ETA: 39s - loss: 0.2002 - accuracy: 0.939 - ETA: 39s - loss: 0.2002 - accuracy: 0.939 - ETA: 39s - loss: 0.2002 - accuracy: 0.939 - ETA: 39s - loss: 0.2001 - accuracy: 0.939 - ETA: 39s - loss: 0.2000 - accuracy: 0.939 - ETA: 39s - loss: 0.1998 - accuracy: 0.939 - ETA: 39s - loss: 0.2000 - accuracy: 0.939 - ETA: 39s - loss: 0.2001 - accuracy: 0.939 - ETA: 39s - loss: 0.2001 - accuracy: 0.939 - ETA: 39s - loss: 0.1999 - accuracy: 0.939 - ETA: 38s - loss: 0.1999 - accuracy: 0.939 - ETA: 38s - loss: 0.1998 - accuracy: 0.939 - ETA: 38s - loss: 0.1996 - accuracy: 0.939 - ETA: 38s - loss: 0.1996 - accuracy: 0.939 - ETA: 38s - loss: 0.1996 - accuracy: 0.939 - ETA: 38s - loss: 0.1995 - accuracy: 0.939 - ETA: 38s - loss: 0.1996 - accuracy: 0.939 - ETA: 38s - loss: 0.1996 - accuracy: 0.939 - ETA: 38s - loss: 0.1996 - accuracy: 0.939 - ETA: 38s - loss: 0.1995 - accuracy: 0.939 - ETA: 38s - loss: 0.1994 - accuracy: 0.939 - ETA: 38s - loss: 0.1993 - accuracy: 0.939 - ETA: 38s - loss: 0.1993 - accuracy: 0.939 - ETA: 38s - loss: 0.1991 - accuracy: 0.939 - ETA: 38s - loss: 0.1990 - accuracy: 0.939 - ETA: 38s - loss: 0.1989 - accuracy: 0.939 - ETA: 37s - loss: 0.1988 - accuracy: 0.939 - ETA: 37s - loss: 0.1987 - accuracy: 0.939 - ETA: 37s - loss: 0.1988 - accuracy: 0.939 - ETA: 37s - loss: 0.1987 - accuracy: 0.940 - ETA: 37s - loss: 0.1986 - accuracy: 0.940 - ETA: 37s - loss: 0.1985 - accuracy: 0.940 - ETA: 37s - loss: 0.1984 - accuracy: 0.940 - ETA: 37s - loss: 0.1982 - accuracy: 0.940 - ETA: 37s - loss: 0.1980 - accuracy: 0.940 - ETA: 37s - loss: 0.1978 - accuracy: 0.940 - ETA: 37s - loss: 0.1977 - accuracy: 0.940 - ETA: 37s - loss: 0.1975 - accuracy: 0.940 - ETA: 36s - loss: 0.1974 - accuracy: 0.940 - ETA: 36s - loss: 0.1974 - accuracy: 0.940 - ETA: 36s - loss: 0.1973 - accuracy: 0.940 - ETA: 36s - loss: 0.1974 - accuracy: 0.940 - ETA: 36s - loss: 0.1974 - accuracy: 0.940 - ETA: 36s - loss: 0.1973 - accuracy: 0.940 - ETA: 36s - loss: 0.1971 - accuracy: 0.940 - ETA: 36s - loss: 0.1971 - accuracy: 0.940 - ETA: 36s - loss: 0.1971 - accuracy: 0.940 - ETA: 36s - loss: 0.1971 - accuracy: 0.940 - ETA: 36s - loss: 0.1969 - accuracy: 0.940 - ETA: 36s - loss: 0.1969 - accuracy: 0.940 - ETA: 36s - loss: 0.1968 - accuracy: 0.940 - ETA: 36s - loss: 0.1967 - accuracy: 0.940 - ETA: 36s - loss: 0.1966 - accuracy: 0.940 - ETA: 36s - loss: 0.1965 - accuracy: 0.940 - ETA: 36s - loss: 0.1964 - accuracy: 0.940 - ETA: 35s - loss: 0.1961 - accuracy: 0.940 - ETA: 35s - loss: 0.1961 - accuracy: 0.940 - ETA: 35s - loss: 0.1959 - accuracy: 0.940 - ETA: 35s - loss: 0.1958 - accuracy: 0.940 - ETA: 35s - loss: 0.1956 - accuracy: 0.941 - ETA: 35s - loss: 0.1955 - accuracy: 0.941 - ETA: 35s - loss: 0.1954 - accuracy: 0.941 - ETA: 35s - loss: 0.1953 - accuracy: 0.941 - ETA: 35s - loss: 0.1954 - accuracy: 0.941 - ETA: 35s - loss: 0.1953 - accuracy: 0.941 - ETA: 35s - loss: 0.1951 - accuracy: 0.941 - ETA: 35s - loss: 0.1951 - accuracy: 0.941 - ETA: 35s - loss: 0.1953 - accuracy: 0.941 - ETA: 35s - loss: 0.1952 - accuracy: 0.941 - ETA: 35s - loss: 0.1952 - accuracy: 0.941 - ETA: 35s - loss: 0.1952 - accuracy: 0.941 - ETA: 35s - loss: 0.1952 - accuracy: 0.941 - ETA: 34s - loss: 0.1951 - accuracy: 0.941 - ETA: 34s - loss: 0.1950 - accuracy: 0.941 - ETA: 34s - loss: 0.1949 - accuracy: 0.941 - ETA: 34s - loss: 0.1947 - accuracy: 0.941 - ETA: 34s - loss: 0.1948 - accuracy: 0.941 - ETA: 34s - loss: 0.1947 - accuracy: 0.941 - ETA: 34s - loss: 0.1946 - accuracy: 0.941 - ETA: 34s - loss: 0.1945 - accuracy: 0.941 - ETA: 34s - loss: 0.1947 - accuracy: 0.941 - ETA: 34s - loss: 0.1944 - accuracy: 0.941 - ETA: 34s - loss: 0.1943 - accuracy: 0.941 - ETA: 34s - loss: 0.1942 - accuracy: 0.941 - ETA: 34s - loss: 0.1941 - accuracy: 0.941 - ETA: 34s - loss: 0.1940 - accuracy: 0.941 - ETA: 34s - loss: 0.1939 - accuracy: 0.941 - ETA: 33s - loss: 0.1939 - accuracy: 0.941 - ETA: 33s - loss: 0.1938 - accuracy: 0.941 - ETA: 33s - loss: 0.1936 - accuracy: 0.941 - ETA: 33s - loss: 0.1937 - accuracy: 0.941 - ETA: 33s - loss: 0.1936 - accuracy: 0.941 - ETA: 33s - loss: 0.1935 - accuracy: 0.941 - ETA: 33s - loss: 0.1933 - accuracy: 0.941 - ETA: 33s - loss: 0.1932 - accuracy: 0.941 - ETA: 33s - loss: 0.1931 - accuracy: 0.941 - ETA: 33s - loss: 0.1930 - accuracy: 0.941 - ETA: 33s - loss: 0.1931 - accuracy: 0.9417"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1875 [======================>.......] - ETA: 33s - loss: 0.1929 - accuracy: 0.941 - ETA: 33s - loss: 0.1928 - accuracy: 0.941 - ETA: 33s - loss: 0.1926 - accuracy: 0.941 - ETA: 33s - loss: 0.1924 - accuracy: 0.942 - ETA: 33s - loss: 0.1923 - accuracy: 0.942 - ETA: 32s - loss: 0.1923 - accuracy: 0.941 - ETA: 32s - loss: 0.1922 - accuracy: 0.942 - ETA: 32s - loss: 0.1921 - accuracy: 0.942 - ETA: 32s - loss: 0.1919 - accuracy: 0.942 - ETA: 32s - loss: 0.1918 - accuracy: 0.942 - ETA: 32s - loss: 0.1918 - accuracy: 0.942 - ETA: 32s - loss: 0.1916 - accuracy: 0.942 - ETA: 32s - loss: 0.1917 - accuracy: 0.942 - ETA: 32s - loss: 0.1915 - accuracy: 0.942 - ETA: 32s - loss: 0.1915 - accuracy: 0.942 - ETA: 32s - loss: 0.1915 - accuracy: 0.942 - ETA: 32s - loss: 0.1914 - accuracy: 0.942 - ETA: 32s - loss: 0.1913 - accuracy: 0.942 - ETA: 32s - loss: 0.1913 - accuracy: 0.942 - ETA: 32s - loss: 0.1912 - accuracy: 0.942 - ETA: 32s - loss: 0.1909 - accuracy: 0.942 - ETA: 31s - loss: 0.1909 - accuracy: 0.942 - ETA: 31s - loss: 0.1907 - accuracy: 0.942 - ETA: 31s - loss: 0.1907 - accuracy: 0.942 - ETA: 31s - loss: 0.1907 - accuracy: 0.942 - ETA: 31s - loss: 0.1908 - accuracy: 0.942 - ETA: 31s - loss: 0.1907 - accuracy: 0.942 - ETA: 31s - loss: 0.1908 - accuracy: 0.942 - ETA: 31s - loss: 0.1907 - accuracy: 0.942 - ETA: 31s - loss: 0.1906 - accuracy: 0.942 - ETA: 31s - loss: 0.1905 - accuracy: 0.942 - ETA: 31s - loss: 0.1905 - accuracy: 0.942 - ETA: 31s - loss: 0.1904 - accuracy: 0.942 - ETA: 31s - loss: 0.1903 - accuracy: 0.942 - ETA: 31s - loss: 0.1900 - accuracy: 0.942 - ETA: 31s - loss: 0.1899 - accuracy: 0.942 - ETA: 31s - loss: 0.1898 - accuracy: 0.942 - ETA: 30s - loss: 0.1897 - accuracy: 0.942 - ETA: 30s - loss: 0.1896 - accuracy: 0.942 - ETA: 30s - loss: 0.1895 - accuracy: 0.942 - ETA: 30s - loss: 0.1894 - accuracy: 0.942 - ETA: 30s - loss: 0.1894 - accuracy: 0.942 - ETA: 30s - loss: 0.1893 - accuracy: 0.942 - ETA: 30s - loss: 0.1892 - accuracy: 0.942 - ETA: 30s - loss: 0.1893 - accuracy: 0.942 - ETA: 30s - loss: 0.1893 - accuracy: 0.942 - ETA: 30s - loss: 0.1892 - accuracy: 0.942 - ETA: 30s - loss: 0.1890 - accuracy: 0.942 - ETA: 30s - loss: 0.1891 - accuracy: 0.942 - ETA: 30s - loss: 0.1890 - accuracy: 0.943 - ETA: 30s - loss: 0.1889 - accuracy: 0.943 - ETA: 30s - loss: 0.1888 - accuracy: 0.943 - ETA: 30s - loss: 0.1887 - accuracy: 0.943 - ETA: 30s - loss: 0.1885 - accuracy: 0.943 - ETA: 29s - loss: 0.1885 - accuracy: 0.943 - ETA: 29s - loss: 0.1884 - accuracy: 0.943 - ETA: 29s - loss: 0.1884 - accuracy: 0.943 - ETA: 29s - loss: 0.1884 - accuracy: 0.943 - ETA: 29s - loss: 0.1884 - accuracy: 0.943 - ETA: 29s - loss: 0.1883 - accuracy: 0.943 - ETA: 29s - loss: 0.1883 - accuracy: 0.943 - ETA: 29s - loss: 0.1881 - accuracy: 0.943 - ETA: 29s - loss: 0.1880 - accuracy: 0.943 - ETA: 29s - loss: 0.1880 - accuracy: 0.943 - ETA: 29s - loss: 0.1880 - accuracy: 0.943 - ETA: 29s - loss: 0.1879 - accuracy: 0.943 - ETA: 29s - loss: 0.1878 - accuracy: 0.943 - ETA: 29s - loss: 0.1877 - accuracy: 0.943 - ETA: 29s - loss: 0.1876 - accuracy: 0.943 - ETA: 29s - loss: 0.1878 - accuracy: 0.943 - ETA: 29s - loss: 0.1877 - accuracy: 0.943 - ETA: 29s - loss: 0.1877 - accuracy: 0.943 - ETA: 28s - loss: 0.1876 - accuracy: 0.943 - ETA: 28s - loss: 0.1875 - accuracy: 0.943 - ETA: 28s - loss: 0.1874 - accuracy: 0.943 - ETA: 28s - loss: 0.1875 - accuracy: 0.943 - ETA: 28s - loss: 0.1874 - accuracy: 0.943 - ETA: 28s - loss: 0.1873 - accuracy: 0.943 - ETA: 28s - loss: 0.1872 - accuracy: 0.943 - ETA: 28s - loss: 0.1871 - accuracy: 0.943 - ETA: 28s - loss: 0.1870 - accuracy: 0.943 - ETA: 28s - loss: 0.1868 - accuracy: 0.943 - ETA: 28s - loss: 0.1867 - accuracy: 0.943 - ETA: 28s - loss: 0.1866 - accuracy: 0.943 - ETA: 28s - loss: 0.1865 - accuracy: 0.943 - ETA: 28s - loss: 0.1864 - accuracy: 0.943 - ETA: 28s - loss: 0.1862 - accuracy: 0.943 - ETA: 28s - loss: 0.1863 - accuracy: 0.943 - ETA: 28s - loss: 0.1862 - accuracy: 0.943 - ETA: 28s - loss: 0.1861 - accuracy: 0.943 - ETA: 28s - loss: 0.1860 - accuracy: 0.943 - ETA: 27s - loss: 0.1859 - accuracy: 0.943 - ETA: 27s - loss: 0.1858 - accuracy: 0.943 - ETA: 27s - loss: 0.1857 - accuracy: 0.943 - ETA: 27s - loss: 0.1858 - accuracy: 0.943 - ETA: 27s - loss: 0.1857 - accuracy: 0.943 - ETA: 27s - loss: 0.1856 - accuracy: 0.944 - ETA: 27s - loss: 0.1854 - accuracy: 0.944 - ETA: 27s - loss: 0.1853 - accuracy: 0.944 - ETA: 27s - loss: 0.1852 - accuracy: 0.944 - ETA: 27s - loss: 0.1851 - accuracy: 0.944 - ETA: 27s - loss: 0.1851 - accuracy: 0.944 - ETA: 27s - loss: 0.1849 - accuracy: 0.944 - ETA: 27s - loss: 0.1849 - accuracy: 0.944 - ETA: 27s - loss: 0.1849 - accuracy: 0.944 - ETA: 27s - loss: 0.1848 - accuracy: 0.944 - ETA: 27s - loss: 0.1847 - accuracy: 0.944 - ETA: 27s - loss: 0.1848 - accuracy: 0.944 - ETA: 27s - loss: 0.1848 - accuracy: 0.944 - ETA: 27s - loss: 0.1847 - accuracy: 0.944 - ETA: 26s - loss: 0.1846 - accuracy: 0.944 - ETA: 26s - loss: 0.1845 - accuracy: 0.944 - ETA: 26s - loss: 0.1844 - accuracy: 0.944 - ETA: 26s - loss: 0.1843 - accuracy: 0.944 - ETA: 26s - loss: 0.1842 - accuracy: 0.944 - ETA: 26s - loss: 0.1842 - accuracy: 0.944 - ETA: 26s - loss: 0.1841 - accuracy: 0.944 - ETA: 26s - loss: 0.1840 - accuracy: 0.944 - ETA: 26s - loss: 0.1840 - accuracy: 0.944 - ETA: 26s - loss: 0.1840 - accuracy: 0.944 - ETA: 26s - loss: 0.1839 - accuracy: 0.944 - ETA: 26s - loss: 0.1838 - accuracy: 0.944 - ETA: 26s - loss: 0.1837 - accuracy: 0.944 - ETA: 26s - loss: 0.1836 - accuracy: 0.944 - ETA: 26s - loss: 0.1835 - accuracy: 0.944 - ETA: 26s - loss: 0.1834 - accuracy: 0.944 - ETA: 26s - loss: 0.1833 - accuracy: 0.944 - ETA: 26s - loss: 0.1832 - accuracy: 0.944 - ETA: 25s - loss: 0.1832 - accuracy: 0.944 - ETA: 25s - loss: 0.1831 - accuracy: 0.944 - ETA: 25s - loss: 0.1830 - accuracy: 0.944 - ETA: 25s - loss: 0.1831 - accuracy: 0.944 - ETA: 25s - loss: 0.1830 - accuracy: 0.944 - ETA: 25s - loss: 0.1830 - accuracy: 0.944 - ETA: 25s - loss: 0.1829 - accuracy: 0.944 - ETA: 25s - loss: 0.1828 - accuracy: 0.944 - ETA: 25s - loss: 0.1827 - accuracy: 0.944 - ETA: 25s - loss: 0.1826 - accuracy: 0.944 - ETA: 25s - loss: 0.1825 - accuracy: 0.944 - ETA: 25s - loss: 0.1825 - accuracy: 0.944 - ETA: 25s - loss: 0.1825 - accuracy: 0.944 - ETA: 25s - loss: 0.1824 - accuracy: 0.944 - ETA: 25s - loss: 0.1824 - accuracy: 0.944 - ETA: 25s - loss: 0.1823 - accuracy: 0.944 - ETA: 25s - loss: 0.1821 - accuracy: 0.945 - ETA: 24s - loss: 0.1820 - accuracy: 0.945 - ETA: 24s - loss: 0.1818 - accuracy: 0.945 - ETA: 24s - loss: 0.1818 - accuracy: 0.945 - ETA: 24s - loss: 0.1819 - accuracy: 0.945 - ETA: 24s - loss: 0.1819 - accuracy: 0.945 - ETA: 24s - loss: 0.1818 - accuracy: 0.945 - ETA: 24s - loss: 0.1818 - accuracy: 0.945 - ETA: 24s - loss: 0.1817 - accuracy: 0.945 - ETA: 24s - loss: 0.1816 - accuracy: 0.945 - ETA: 24s - loss: 0.1815 - accuracy: 0.945 - ETA: 24s - loss: 0.1814 - accuracy: 0.945 - ETA: 24s - loss: 0.1814 - accuracy: 0.945 - ETA: 24s - loss: 0.1813 - accuracy: 0.945 - ETA: 24s - loss: 0.1813 - accuracy: 0.945 - ETA: 24s - loss: 0.1812 - accuracy: 0.945 - ETA: 23s - loss: 0.1813 - accuracy: 0.945 - ETA: 23s - loss: 0.1812 - accuracy: 0.945 - ETA: 23s - loss: 0.1811 - accuracy: 0.945 - ETA: 23s - loss: 0.1810 - accuracy: 0.945 - ETA: 23s - loss: 0.1810 - accuracy: 0.945 - ETA: 23s - loss: 0.1809 - accuracy: 0.945 - ETA: 23s - loss: 0.1809 - accuracy: 0.945 - ETA: 23s - loss: 0.1808 - accuracy: 0.945 - ETA: 23s - loss: 0.1807 - accuracy: 0.945 - ETA: 23s - loss: 0.1806 - accuracy: 0.945 - ETA: 23s - loss: 0.1806 - accuracy: 0.945 - ETA: 23s - loss: 0.1807 - accuracy: 0.945 - ETA: 23s - loss: 0.1806 - accuracy: 0.945 - ETA: 23s - loss: 0.1806 - accuracy: 0.945 - ETA: 23s - loss: 0.1806 - accuracy: 0.945 - ETA: 23s - loss: 0.1806 - accuracy: 0.945 - ETA: 23s - loss: 0.1805 - accuracy: 0.945 - ETA: 22s - loss: 0.1804 - accuracy: 0.945 - ETA: 22s - loss: 0.1802 - accuracy: 0.945 - ETA: 22s - loss: 0.1802 - accuracy: 0.945 - ETA: 22s - loss: 0.1801 - accuracy: 0.945 - ETA: 22s - loss: 0.1799 - accuracy: 0.945 - ETA: 22s - loss: 0.1799 - accuracy: 0.945 - ETA: 22s - loss: 0.1797 - accuracy: 0.945 - ETA: 22s - loss: 0.1796 - accuracy: 0.945 - ETA: 22s - loss: 0.1796 - accuracy: 0.9456"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1686/1875 [=========================>....] - ETA: 22s - loss: 0.1795 - accuracy: 0.945 - ETA: 22s - loss: 0.1794 - accuracy: 0.945 - ETA: 22s - loss: 0.1793 - accuracy: 0.945 - ETA: 22s - loss: 0.1792 - accuracy: 0.945 - ETA: 22s - loss: 0.1792 - accuracy: 0.945 - ETA: 22s - loss: 0.1792 - accuracy: 0.945 - ETA: 21s - loss: 0.1791 - accuracy: 0.945 - ETA: 21s - loss: 0.1790 - accuracy: 0.945 - ETA: 21s - loss: 0.1789 - accuracy: 0.945 - ETA: 21s - loss: 0.1788 - accuracy: 0.945 - ETA: 21s - loss: 0.1787 - accuracy: 0.945 - ETA: 21s - loss: 0.1788 - accuracy: 0.945 - ETA: 21s - loss: 0.1788 - accuracy: 0.945 - ETA: 21s - loss: 0.1787 - accuracy: 0.945 - ETA: 21s - loss: 0.1787 - accuracy: 0.945 - ETA: 21s - loss: 0.1787 - accuracy: 0.945 - ETA: 21s - loss: 0.1787 - accuracy: 0.945 - ETA: 21s - loss: 0.1786 - accuracy: 0.945 - ETA: 21s - loss: 0.1787 - accuracy: 0.945 - ETA: 21s - loss: 0.1786 - accuracy: 0.945 - ETA: 21s - loss: 0.1785 - accuracy: 0.945 - ETA: 21s - loss: 0.1785 - accuracy: 0.945 - ETA: 21s - loss: 0.1785 - accuracy: 0.945 - ETA: 20s - loss: 0.1784 - accuracy: 0.945 - ETA: 20s - loss: 0.1784 - accuracy: 0.945 - ETA: 20s - loss: 0.1783 - accuracy: 0.945 - ETA: 20s - loss: 0.1782 - accuracy: 0.946 - ETA: 20s - loss: 0.1781 - accuracy: 0.946 - ETA: 20s - loss: 0.1779 - accuracy: 0.946 - ETA: 20s - loss: 0.1779 - accuracy: 0.946 - ETA: 20s - loss: 0.1779 - accuracy: 0.946 - ETA: 20s - loss: 0.1778 - accuracy: 0.946 - ETA: 20s - loss: 0.1777 - accuracy: 0.946 - ETA: 20s - loss: 0.1776 - accuracy: 0.946 - ETA: 20s - loss: 0.1775 - accuracy: 0.946 - ETA: 20s - loss: 0.1775 - accuracy: 0.946 - ETA: 20s - loss: 0.1774 - accuracy: 0.946 - ETA: 20s - loss: 0.1774 - accuracy: 0.946 - ETA: 20s - loss: 0.1774 - accuracy: 0.946 - ETA: 20s - loss: 0.1772 - accuracy: 0.946 - ETA: 19s - loss: 0.1772 - accuracy: 0.946 - ETA: 19s - loss: 0.1771 - accuracy: 0.946 - ETA: 19s - loss: 0.1770 - accuracy: 0.946 - ETA: 19s - loss: 0.1770 - accuracy: 0.946 - ETA: 19s - loss: 0.1770 - accuracy: 0.946 - ETA: 19s - loss: 0.1769 - accuracy: 0.946 - ETA: 19s - loss: 0.1768 - accuracy: 0.946 - ETA: 19s - loss: 0.1767 - accuracy: 0.946 - ETA: 19s - loss: 0.1766 - accuracy: 0.946 - ETA: 19s - loss: 0.1764 - accuracy: 0.946 - ETA: 19s - loss: 0.1764 - accuracy: 0.946 - ETA: 19s - loss: 0.1762 - accuracy: 0.946 - ETA: 19s - loss: 0.1763 - accuracy: 0.946 - ETA: 19s - loss: 0.1761 - accuracy: 0.946 - ETA: 19s - loss: 0.1759 - accuracy: 0.946 - ETA: 19s - loss: 0.1758 - accuracy: 0.946 - ETA: 19s - loss: 0.1758 - accuracy: 0.946 - ETA: 18s - loss: 0.1756 - accuracy: 0.946 - ETA: 18s - loss: 0.1756 - accuracy: 0.946 - ETA: 18s - loss: 0.1756 - accuracy: 0.946 - ETA: 18s - loss: 0.1756 - accuracy: 0.946 - ETA: 18s - loss: 0.1758 - accuracy: 0.946 - ETA: 18s - loss: 0.1757 - accuracy: 0.946 - ETA: 18s - loss: 0.1757 - accuracy: 0.946 - ETA: 18s - loss: 0.1757 - accuracy: 0.946 - ETA: 18s - loss: 0.1757 - accuracy: 0.946 - ETA: 18s - loss: 0.1757 - accuracy: 0.946 - ETA: 18s - loss: 0.1755 - accuracy: 0.946 - ETA: 18s - loss: 0.1754 - accuracy: 0.946 - ETA: 18s - loss: 0.1753 - accuracy: 0.946 - ETA: 18s - loss: 0.1752 - accuracy: 0.946 - ETA: 17s - loss: 0.1751 - accuracy: 0.946 - ETA: 17s - loss: 0.1751 - accuracy: 0.946 - ETA: 17s - loss: 0.1751 - accuracy: 0.946 - ETA: 17s - loss: 0.1752 - accuracy: 0.946 - ETA: 17s - loss: 0.1754 - accuracy: 0.946 - ETA: 17s - loss: 0.1754 - accuracy: 0.946 - ETA: 17s - loss: 0.1753 - accuracy: 0.946 - ETA: 17s - loss: 0.1754 - accuracy: 0.946 - ETA: 17s - loss: 0.1753 - accuracy: 0.946 - ETA: 17s - loss: 0.1752 - accuracy: 0.946 - ETA: 17s - loss: 0.1752 - accuracy: 0.946 - ETA: 17s - loss: 0.1752 - accuracy: 0.946 - ETA: 17s - loss: 0.1751 - accuracy: 0.946 - ETA: 17s - loss: 0.1750 - accuracy: 0.946 - ETA: 17s - loss: 0.1751 - accuracy: 0.946 - ETA: 17s - loss: 0.1749 - accuracy: 0.946 - ETA: 16s - loss: 0.1748 - accuracy: 0.946 - ETA: 16s - loss: 0.1748 - accuracy: 0.946 - ETA: 16s - loss: 0.1747 - accuracy: 0.947 - ETA: 16s - loss: 0.1746 - accuracy: 0.947 - ETA: 16s - loss: 0.1744 - accuracy: 0.947 - ETA: 16s - loss: 0.1743 - accuracy: 0.947 - ETA: 16s - loss: 0.1744 - accuracy: 0.947 - ETA: 16s - loss: 0.1743 - accuracy: 0.947 - ETA: 16s - loss: 0.1742 - accuracy: 0.947 - ETA: 16s - loss: 0.1742 - accuracy: 0.947 - ETA: 16s - loss: 0.1744 - accuracy: 0.947 - ETA: 16s - loss: 0.1745 - accuracy: 0.947 - ETA: 16s - loss: 0.1745 - accuracy: 0.947 - ETA: 16s - loss: 0.1745 - accuracy: 0.947 - ETA: 16s - loss: 0.1744 - accuracy: 0.947 - ETA: 15s - loss: 0.1745 - accuracy: 0.947 - ETA: 15s - loss: 0.1744 - accuracy: 0.947 - ETA: 15s - loss: 0.1743 - accuracy: 0.947 - ETA: 15s - loss: 0.1742 - accuracy: 0.947 - ETA: 15s - loss: 0.1742 - accuracy: 0.947 - ETA: 15s - loss: 0.1741 - accuracy: 0.947 - ETA: 15s - loss: 0.1741 - accuracy: 0.947 - ETA: 15s - loss: 0.1741 - accuracy: 0.947 - ETA: 15s - loss: 0.1740 - accuracy: 0.947 - ETA: 15s - loss: 0.1741 - accuracy: 0.947 - ETA: 15s - loss: 0.1740 - accuracy: 0.947 - ETA: 15s - loss: 0.1739 - accuracy: 0.947 - ETA: 15s - loss: 0.1738 - accuracy: 0.947 - ETA: 15s - loss: 0.1737 - accuracy: 0.947 - ETA: 15s - loss: 0.1736 - accuracy: 0.947 - ETA: 15s - loss: 0.1734 - accuracy: 0.947 - ETA: 14s - loss: 0.1733 - accuracy: 0.947 - ETA: 14s - loss: 0.1734 - accuracy: 0.947 - ETA: 14s - loss: 0.1735 - accuracy: 0.947 - ETA: 14s - loss: 0.1735 - accuracy: 0.947 - ETA: 14s - loss: 0.1734 - accuracy: 0.947 - ETA: 14s - loss: 0.1733 - accuracy: 0.947 - ETA: 14s - loss: 0.1732 - accuracy: 0.947 - ETA: 14s - loss: 0.1732 - accuracy: 0.947 - ETA: 14s - loss: 0.1731 - accuracy: 0.947 - ETA: 14s - loss: 0.1731 - accuracy: 0.947 - ETA: 14s - loss: 0.1730 - accuracy: 0.947 - ETA: 14s - loss: 0.1729 - accuracy: 0.947 - ETA: 14s - loss: 0.1728 - accuracy: 0.947 - ETA: 14s - loss: 0.1727 - accuracy: 0.947 - ETA: 13s - loss: 0.1726 - accuracy: 0.947 - ETA: 13s - loss: 0.1725 - accuracy: 0.947 - ETA: 13s - loss: 0.1724 - accuracy: 0.947 - ETA: 13s - loss: 0.1723 - accuracy: 0.947 - ETA: 13s - loss: 0.1722 - accuracy: 0.947 - ETA: 13s - loss: 0.1722 - accuracy: 0.947 - ETA: 13s - loss: 0.1721 - accuracy: 0.947 - ETA: 13s - loss: 0.1720 - accuracy: 0.947 - ETA: 13s - loss: 0.1720 - accuracy: 0.947 - ETA: 13s - loss: 0.1720 - accuracy: 0.947 - ETA: 13s - loss: 0.1720 - accuracy: 0.947 - ETA: 13s - loss: 0.1721 - accuracy: 0.947 - ETA: 13s - loss: 0.1720 - accuracy: 0.947 - ETA: 12s - loss: 0.1721 - accuracy: 0.947 - ETA: 12s - loss: 0.1720 - accuracy: 0.947 - ETA: 12s - loss: 0.1719 - accuracy: 0.947 - ETA: 12s - loss: 0.1719 - accuracy: 0.947 - ETA: 12s - loss: 0.1718 - accuracy: 0.947 - ETA: 12s - loss: 0.1716 - accuracy: 0.947 - ETA: 12s - loss: 0.1715 - accuracy: 0.947 - ETA: 12s - loss: 0.1715 - accuracy: 0.948 - ETA: 12s - loss: 0.1714 - accuracy: 0.948 - ETA: 12s - loss: 0.1713 - accuracy: 0.948 - ETA: 12s - loss: 0.1713 - accuracy: 0.948 - ETA: 12s - loss: 0.1713 - accuracy: 0.948 - ETA: 12s - loss: 0.1712 - accuracy: 0.948 - ETA: 12s - loss: 0.1712 - accuracy: 0.948 - ETA: 12s - loss: 0.1712 - accuracy: 0.948 - ETA: 12s - loss: 0.1712 - accuracy: 0.948 - ETA: 11s - loss: 0.1712 - accuracy: 0.948 - ETA: 11s - loss: 0.1713 - accuracy: 0.948 - ETA: 11s - loss: 0.1712 - accuracy: 0.948 - ETA: 11s - loss: 0.1711 - accuracy: 0.948 - ETA: 11s - loss: 0.1711 - accuracy: 0.948 - ETA: 11s - loss: 0.1710 - accuracy: 0.948 - ETA: 11s - loss: 0.1709 - accuracy: 0.948 - ETA: 11s - loss: 0.1709 - accuracy: 0.948 - ETA: 11s - loss: 0.1709 - accuracy: 0.948 - ETA: 11s - loss: 0.1710 - accuracy: 0.948 - ETA: 11s - loss: 0.1709 - accuracy: 0.948 - ETA: 11s - loss: 0.1708 - accuracy: 0.948 - ETA: 11s - loss: 0.1706 - accuracy: 0.948 - ETA: 11s - loss: 0.1705 - accuracy: 0.948 - ETA: 11s - loss: 0.1704 - accuracy: 0.948 - ETA: 10s - loss: 0.1703 - accuracy: 0.948 - ETA: 10s - loss: 0.1703 - accuracy: 0.948 - ETA: 10s - loss: 0.1703 - accuracy: 0.948 - ETA: 10s - loss: 0.1703 - accuracy: 0.948 - ETA: 10s - loss: 0.1702 - accuracy: 0.948 - ETA: 10s - loss: 0.1701 - accuracy: 0.948 - ETA: 10s - loss: 0.1700 - accuracy: 0.948 - ETA: 10s - loss: 0.1699 - accuracy: 0.948 - ETA: 10s - loss: 0.1700 - accuracy: 0.948 - ETA: 10s - loss: 0.1699 - accuracy: 0.9484"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - ETA: 10s - loss: 0.1698 - accuracy: 0.948 - ETA: 10s - loss: 0.1698 - accuracy: 0.948 - ETA: 10s - loss: 0.1697 - accuracy: 0.948 - ETA: 10s - loss: 0.1697 - accuracy: 0.948 - ETA: 9s - loss: 0.1696 - accuracy: 0.948 - ETA: 9s - loss: 0.1695 - accuracy: 0.94 - ETA: 9s - loss: 0.1693 - accuracy: 0.94 - ETA: 9s - loss: 0.1693 - accuracy: 0.94 - ETA: 9s - loss: 0.1692 - accuracy: 0.94 - ETA: 9s - loss: 0.1691 - accuracy: 0.94 - ETA: 9s - loss: 0.1690 - accuracy: 0.94 - ETA: 9s - loss: 0.1690 - accuracy: 0.94 - ETA: 9s - loss: 0.1688 - accuracy: 0.94 - ETA: 9s - loss: 0.1687 - accuracy: 0.94 - ETA: 9s - loss: 0.1687 - accuracy: 0.94 - ETA: 9s - loss: 0.1686 - accuracy: 0.94 - ETA: 9s - loss: 0.1686 - accuracy: 0.94 - ETA: 9s - loss: 0.1685 - accuracy: 0.94 - ETA: 9s - loss: 0.1684 - accuracy: 0.94 - ETA: 8s - loss: 0.1683 - accuracy: 0.94 - ETA: 8s - loss: 0.1682 - accuracy: 0.94 - ETA: 8s - loss: 0.1682 - accuracy: 0.94 - ETA: 8s - loss: 0.1681 - accuracy: 0.94 - ETA: 8s - loss: 0.1681 - accuracy: 0.94 - ETA: 8s - loss: 0.1681 - accuracy: 0.94 - ETA: 8s - loss: 0.1681 - accuracy: 0.94 - ETA: 8s - loss: 0.1681 - accuracy: 0.94 - ETA: 8s - loss: 0.1680 - accuracy: 0.94 - ETA: 8s - loss: 0.1679 - accuracy: 0.94 - ETA: 8s - loss: 0.1678 - accuracy: 0.94 - ETA: 8s - loss: 0.1676 - accuracy: 0.94 - ETA: 8s - loss: 0.1675 - accuracy: 0.94 - ETA: 8s - loss: 0.1674 - accuracy: 0.94 - ETA: 8s - loss: 0.1673 - accuracy: 0.94 - ETA: 7s - loss: 0.1672 - accuracy: 0.94 - ETA: 7s - loss: 0.1672 - accuracy: 0.94 - ETA: 7s - loss: 0.1672 - accuracy: 0.94 - ETA: 7s - loss: 0.1671 - accuracy: 0.94 - ETA: 7s - loss: 0.1670 - accuracy: 0.94 - ETA: 7s - loss: 0.1669 - accuracy: 0.94 - ETA: 7s - loss: 0.1670 - accuracy: 0.94 - ETA: 7s - loss: 0.1670 - accuracy: 0.94 - ETA: 7s - loss: 0.1669 - accuracy: 0.94 - ETA: 7s - loss: 0.1668 - accuracy: 0.94 - ETA: 7s - loss: 0.1667 - accuracy: 0.94 - ETA: 7s - loss: 0.1666 - accuracy: 0.94 - ETA: 7s - loss: 0.1666 - accuracy: 0.94 - ETA: 7s - loss: 0.1665 - accuracy: 0.94 - ETA: 7s - loss: 0.1665 - accuracy: 0.94 - ETA: 6s - loss: 0.1665 - accuracy: 0.94 - ETA: 6s - loss: 0.1664 - accuracy: 0.94 - ETA: 6s - loss: 0.1664 - accuracy: 0.94 - ETA: 6s - loss: 0.1663 - accuracy: 0.94 - ETA: 6s - loss: 0.1662 - accuracy: 0.94 - ETA: 6s - loss: 0.1661 - accuracy: 0.94 - ETA: 6s - loss: 0.1661 - accuracy: 0.94 - ETA: 6s - loss: 0.1660 - accuracy: 0.94 - ETA: 6s - loss: 0.1660 - accuracy: 0.94 - ETA: 6s - loss: 0.1660 - accuracy: 0.94 - ETA: 6s - loss: 0.1659 - accuracy: 0.94 - ETA: 6s - loss: 0.1658 - accuracy: 0.94 - ETA: 6s - loss: 0.1659 - accuracy: 0.94 - ETA: 6s - loss: 0.1658 - accuracy: 0.94 - ETA: 6s - loss: 0.1656 - accuracy: 0.94 - ETA: 6s - loss: 0.1658 - accuracy: 0.94 - ETA: 5s - loss: 0.1657 - accuracy: 0.94 - ETA: 5s - loss: 0.1657 - accuracy: 0.94 - ETA: 5s - loss: 0.1656 - accuracy: 0.94 - ETA: 5s - loss: 0.1656 - accuracy: 0.94 - ETA: 5s - loss: 0.1656 - accuracy: 0.94 - ETA: 5s - loss: 0.1656 - accuracy: 0.94 - ETA: 5s - loss: 0.1655 - accuracy: 0.94 - ETA: 5s - loss: 0.1654 - accuracy: 0.94 - ETA: 5s - loss: 0.1653 - accuracy: 0.94 - ETA: 5s - loss: 0.1653 - accuracy: 0.94 - ETA: 5s - loss: 0.1653 - accuracy: 0.94 - ETA: 5s - loss: 0.1653 - accuracy: 0.94 - ETA: 5s - loss: 0.1652 - accuracy: 0.94 - ETA: 5s - loss: 0.1651 - accuracy: 0.94 - ETA: 5s - loss: 0.1650 - accuracy: 0.94 - ETA: 4s - loss: 0.1650 - accuracy: 0.94 - ETA: 4s - loss: 0.1649 - accuracy: 0.94 - ETA: 4s - loss: 0.1648 - accuracy: 0.94 - ETA: 4s - loss: 0.1647 - accuracy: 0.94 - ETA: 4s - loss: 0.1646 - accuracy: 0.95 - ETA: 4s - loss: 0.1646 - accuracy: 0.95 - ETA: 4s - loss: 0.1646 - accuracy: 0.94 - ETA: 4s - loss: 0.1645 - accuracy: 0.95 - ETA: 4s - loss: 0.1644 - accuracy: 0.95 - ETA: 4s - loss: 0.1643 - accuracy: 0.95 - ETA: 4s - loss: 0.1643 - accuracy: 0.95 - ETA: 4s - loss: 0.1642 - accuracy: 0.95 - ETA: 4s - loss: 0.1642 - accuracy: 0.95 - ETA: 4s - loss: 0.1641 - accuracy: 0.95 - ETA: 4s - loss: 0.1641 - accuracy: 0.95 - ETA: 4s - loss: 0.1640 - accuracy: 0.95 - ETA: 4s - loss: 0.1639 - accuracy: 0.95 - ETA: 3s - loss: 0.1639 - accuracy: 0.95 - ETA: 3s - loss: 0.1639 - accuracy: 0.95 - ETA: 3s - loss: 0.1638 - accuracy: 0.95 - ETA: 3s - loss: 0.1639 - accuracy: 0.95 - ETA: 3s - loss: 0.1640 - accuracy: 0.95 - ETA: 3s - loss: 0.1639 - accuracy: 0.95 - ETA: 3s - loss: 0.1638 - accuracy: 0.95 - ETA: 3s - loss: 0.1637 - accuracy: 0.95 - ETA: 3s - loss: 0.1636 - accuracy: 0.95 - ETA: 3s - loss: 0.1636 - accuracy: 0.95 - ETA: 3s - loss: 0.1635 - accuracy: 0.95 - ETA: 3s - loss: 0.1634 - accuracy: 0.95 - ETA: 3s - loss: 0.1633 - accuracy: 0.95 - ETA: 3s - loss: 0.1632 - accuracy: 0.95 - ETA: 2s - loss: 0.1631 - accuracy: 0.95 - ETA: 2s - loss: 0.1629 - accuracy: 0.95 - ETA: 2s - loss: 0.1629 - accuracy: 0.95 - ETA: 2s - loss: 0.1627 - accuracy: 0.95 - ETA: 2s - loss: 0.1626 - accuracy: 0.95 - ETA: 2s - loss: 0.1625 - accuracy: 0.95 - ETA: 2s - loss: 0.1625 - accuracy: 0.95 - ETA: 2s - loss: 0.1624 - accuracy: 0.95 - ETA: 2s - loss: 0.1623 - accuracy: 0.95 - ETA: 2s - loss: 0.1622 - accuracy: 0.95 - ETA: 2s - loss: 0.1622 - accuracy: 0.95 - ETA: 2s - loss: 0.1621 - accuracy: 0.95 - ETA: 2s - loss: 0.1619 - accuracy: 0.95 - ETA: 2s - loss: 0.1618 - accuracy: 0.95 - ETA: 2s - loss: 0.1618 - accuracy: 0.95 - ETA: 1s - loss: 0.1618 - accuracy: 0.95 - ETA: 1s - loss: 0.1617 - accuracy: 0.95 - ETA: 1s - loss: 0.1616 - accuracy: 0.95 - ETA: 1s - loss: 0.1615 - accuracy: 0.95 - ETA: 1s - loss: 0.1614 - accuracy: 0.95 - ETA: 1s - loss: 0.1613 - accuracy: 0.95 - ETA: 1s - loss: 0.1612 - accuracy: 0.95 - ETA: 1s - loss: 0.1612 - accuracy: 0.95 - ETA: 1s - loss: 0.1610 - accuracy: 0.95 - ETA: 1s - loss: 0.1609 - accuracy: 0.95 - ETA: 1s - loss: 0.1608 - accuracy: 0.95 - ETA: 1s - loss: 0.1607 - accuracy: 0.95 - ETA: 1s - loss: 0.1606 - accuracy: 0.95 - ETA: 1s - loss: 0.1606 - accuracy: 0.95 - ETA: 1s - loss: 0.1605 - accuracy: 0.95 - ETA: 1s - loss: 0.1605 - accuracy: 0.95 - ETA: 0s - loss: 0.1605 - accuracy: 0.95 - ETA: 0s - loss: 0.1604 - accuracy: 0.95 - ETA: 0s - loss: 0.1604 - accuracy: 0.95 - ETA: 0s - loss: 0.1603 - accuracy: 0.95 - ETA: 0s - loss: 0.1602 - accuracy: 0.95 - ETA: 0s - loss: 0.1601 - accuracy: 0.95 - ETA: 0s - loss: 0.1600 - accuracy: 0.95 - ETA: 0s - loss: 0.1601 - accuracy: 0.95 - ETA: 0s - loss: 0.1605 - accuracy: 0.95 - ETA: 0s - loss: 0.1605 - accuracy: 0.95 - ETA: 0s - loss: 0.1604 - accuracy: 0.95 - ETA: 0s - loss: 0.1604 - accuracy: 0.95 - ETA: 0s - loss: 0.1603 - accuracy: 0.95 - ETA: 0s - loss: 0.1602 - accuracy: 0.95 - ETA: 0s - loss: 0.1605 - accuracy: 0.95 - ETA: 0s - loss: 0.1604 - accuracy: 0.95 - 121s 64ms/step - loss: 0.1604 - accuracy: 0.9514 - val_loss: 0.0781 - val_accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=1, validation_split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9721"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08150846712332525"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "m=model.export_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 28, 28, 1)         3         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                92170     \n",
      "_________________________________________________________________\n",
      "classification_head_1 (Softm (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 110,989\n",
      "Trainable params: 110,986\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "u=model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f0b547af60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "n, bins, patches = plt.hist(u, 20, density=1, facecolor='g', alpha = 0.25, lw=3 )\n",
    "plt.xlabel('CLASSES')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('HISTOGRAM OF PREDICTED VALUES')\n",
    "#plt.text(5, .25, 'type of object')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TITANIC SURVIVAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "    \n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 10s - loss: 1.5938 - accuracy: 0.500 - 1s 69ms/step - loss: 0.8055 - accuracy: 0.5996 - val_loss: 0.7250 - val_accuracy: 0.4560\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6527 - accuracy: 0.50 - 0s 14ms/step - loss: 0.6703 - accuracy: 0.6295 - val_loss: 0.5501 - val_accuracy: 0.7440\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7818 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6798 - accuracy: 0.6554 - val_loss: 0.5997 - val_accuracy: 0.7200\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7973 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6879 - accuracy: 0.6454 - val_loss: 0.5850 - val_accuracy: 0.7200\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8320 - accuracy: 0.53 - 0s 6ms/step - loss: 0.6648 - accuracy: 0.6454 - val_loss: 0.5582 - val_accuracy: 0.7280\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7654 - accuracy: 0.53 - 0s 6ms/step - loss: 0.6495 - accuracy: 0.6494 - val_loss: 0.5393 - val_accuracy: 0.7280\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7833 - accuracy: 0.53 - 0s 6ms/step - loss: 0.6460 - accuracy: 0.6514 - val_loss: 0.5471 - val_accuracy: 0.7200\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7718 - accuracy: 0.53 - 0s 6ms/step - loss: 0.6473 - accuracy: 0.6434 - val_loss: 0.5435 - val_accuracy: 0.7200\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7959 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6401 - accuracy: 0.6534 - val_loss: 0.5367 - val_accuracy: 0.7280\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7687 - accuracy: 0.53 - 0s 6ms/step - loss: 0.6346 - accuracy: 0.6514 - val_loss: 0.5279 - val_accuracy: 0.7280\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7729 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6303 - accuracy: 0.6534 - val_loss: 0.5285 - val_accuracy: 0.7360\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7544 - accuracy: 0.53 - ETA: 0s - loss: 0.6567 - accuracy: 0.62 - 0s 6ms/step - loss: 0.6289 - accuracy: 0.6554 - val_loss: 0.5239 - val_accuracy: 0.7360\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7684 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6241 - accuracy: 0.6614 - val_loss: 0.5202 - val_accuracy: 0.7360\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7513 - accuracy: 0.53 - ETA: 0s - loss: 0.6268 - accuracy: 0.65 - 0s 7ms/step - loss: 0.6213 - accuracy: 0.6614 - val_loss: 0.5201 - val_accuracy: 0.7360\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7554 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6181 - accuracy: 0.6653 - val_loss: 0.5136 - val_accuracy: 0.7440\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7443 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6136 - accuracy: 0.6713 - val_loss: 0.5112 - val_accuracy: 0.7440\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7406 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6099 - accuracy: 0.6733 - val_loss: 0.5069 - val_accuracy: 0.7440\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7369 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6713 - val_loss: 0.5046 - val_accuracy: 0.7440\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7345 - accuracy: 0.56 - 0s 6ms/step - loss: 0.6028 - accuracy: 0.6713 - val_loss: 0.5010 - val_accuracy: 0.7440\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7207 - accuracy: 0.56 - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6753 - val_loss: 0.4974 - val_accuracy: 0.7440\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7282 - accuracy: 0.56 - 0s 5ms/step - loss: 0.5954 - accuracy: 0.6733 - val_loss: 0.4937 - val_accuracy: 0.7440\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7173 - accuracy: 0.53 - 0s 6ms/step - loss: 0.5919 - accuracy: 0.6753 - val_loss: 0.4916 - val_accuracy: 0.7440\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7080 - accuracy: 0.53 - 0s 6ms/step - loss: 0.5888 - accuracy: 0.6733 - val_loss: 0.4880 - val_accuracy: 0.7440\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7139 - accuracy: 0.53 - 0s 20ms/step - loss: 0.5849 - accuracy: 0.6793 - val_loss: 0.4871 - val_accuracy: 0.7760\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.53 - ETA: 0s - loss: 0.5991 - accuracy: 0.64 - 0s 11ms/step - loss: 0.5821 - accuracy: 0.6793 - val_loss: 0.4830 - val_accuracy: 0.7680\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7093 - accuracy: 0.53 - 0s 6ms/step - loss: 0.5781 - accuracy: 0.6813 - val_loss: 0.4804 - val_accuracy: 0.7760\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.56 - 0s 15ms/step - loss: 0.5739 - accuracy: 0.6892 - val_loss: 0.4745 - val_accuracy: 0.7840\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.56 - 0s 5ms/step - loss: 0.5695 - accuracy: 0.6873 - val_loss: 0.4769 - val_accuracy: 0.7760\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.62 - 0s 14ms/step - loss: 0.5675 - accuracy: 0.7032 - val_loss: 0.4730 - val_accuracy: 0.7920\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6786 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7112 - val_loss: 0.4674 - val_accuracy: 0.7920\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7291 - val_loss: 0.4642 - val_accuracy: 0.7840\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.68 - ETA: 0s - loss: 0.5665 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7251 - val_loss: 0.4614 - val_accuracy: 0.7920\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7291 - val_loss: 0.4574 - val_accuracy: 0.7840\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.71 - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7410 - val_loss: 0.4571 - val_accuracy: 0.7920\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.71 - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7390 - val_loss: 0.4567 - val_accuracy: 0.7920\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.71 - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7450 - val_loss: 0.4523 - val_accuracy: 0.7920\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6435 - accuracy: 0.71 - 0s 11ms/step - loss: 0.5387 - accuracy: 0.7490 - val_loss: 0.4505 - val_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7570 - val_loss: 0.4462 - val_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7590 - val_loss: 0.4430 - val_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7570 - val_loss: 0.4441 - val_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7570 - val_loss: 0.4421 - val_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6292 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7629 - val_loss: 0.4406 - val_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6146 - accuracy: 0.71 - 0s 11ms/step - loss: 0.5226 - accuracy: 0.7610 - val_loss: 0.4378 - val_accuracy: 0.8080\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6206 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5204 - accuracy: 0.7649 - val_loss: 0.4347 - val_accuracy: 0.8080\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.71 - 0s 11ms/step - loss: 0.5172 - accuracy: 0.7689 - val_loss: 0.4335 - val_accuracy: 0.8160\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7669 - val_loss: 0.4321 - val_accuracy: 0.8160\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6043 - accuracy: 0.71 - ETA: 0s - loss: 0.5205 - accuracy: 0.76 - 0s 7ms/step - loss: 0.5134 - accuracy: 0.7709 - val_loss: 0.4293 - val_accuracy: 0.8160\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5113 - accuracy: 0.7729 - val_loss: 0.4287 - val_accuracy: 0.8160\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5987 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7709 - val_loss: 0.4288 - val_accuracy: 0.8160\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6049 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5081 - accuracy: 0.7709 - val_loss: 0.4260 - val_accuracy: 0.8160\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5952 - accuracy: 0.68 - 0s 16ms/step - loss: 0.5055 - accuracy: 0.7729 - val_loss: 0.4229 - val_accuracy: 0.8240\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7749 - val_loss: 0.4226 - val_accuracy: 0.8240\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7729 - val_loss: 0.4202 - val_accuracy: 0.8240\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7789 - val_loss: 0.4182 - val_accuracy: 0.8240\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5862 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7809 - val_loss: 0.4183 - val_accuracy: 0.8240\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5901 - accuracy: 0.68 - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7789 - val_loss: 0.4170 - val_accuracy: 0.8240\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5813 - accuracy: 0.68 - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7809 - val_loss: 0.4130 - val_accuracy: 0.8240\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5755 - accuracy: 0.68 - 0s 6ms/step - loss: 0.4916 - accuracy: 0.7849 - val_loss: 0.4124 - val_accuracy: 0.8240\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.68 - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7888 - val_loss: 0.4115 - val_accuracy: 0.8240\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.68 - 0s 14ms/step - loss: 0.4896 - accuracy: 0.7888 - val_loss: 0.4107 - val_accuracy: 0.8320\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.68 - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7869 - val_loss: 0.4109 - val_accuracy: 0.8320\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4875 - accuracy: 0.7888 - val_loss: 0.4091 - val_accuracy: 0.8320\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5753 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7888 - val_loss: 0.4083 - val_accuracy: 0.8320\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7908 - val_loss: 0.4087 - val_accuracy: 0.8320\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5729 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7908 - val_loss: 0.4068 - val_accuracy: 0.8320\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7908 - val_loss: 0.4036 - val_accuracy: 0.8240\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.68 - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7908 - val_loss: 0.4050 - val_accuracy: 0.8240\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7908 - val_loss: 0.4041 - val_accuracy: 0.8240\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7908 - val_loss: 0.4011 - val_accuracy: 0.8240\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7928 - val_loss: 0.4012 - val_accuracy: 0.8240\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5603 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7948 - val_loss: 0.4005 - val_accuracy: 0.8240\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7968 - val_loss: 0.3989 - val_accuracy: 0.8240\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7948 - val_loss: 0.3991 - val_accuracy: 0.8240\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5578 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7968 - val_loss: 0.3991 - val_accuracy: 0.8240\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7968 - val_loss: 0.3993 - val_accuracy: 0.8240\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5535 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7968 - val_loss: 0.3967 - val_accuracy: 0.8320\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7988 - val_loss: 0.3969 - val_accuracy: 0.8320\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7988 - val_loss: 0.3966 - val_accuracy: 0.8320\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5478 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7988 - val_loss: 0.3965 - val_accuracy: 0.8320\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5517 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7968 - val_loss: 0.3971 - val_accuracy: 0.8320\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7968 - val_loss: 0.3981 - val_accuracy: 0.8240\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5457 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7968 - val_loss: 0.3979 - val_accuracy: 0.8320\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5490 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7948 - val_loss: 0.3986 - val_accuracy: 0.8320\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7948 - val_loss: 0.3973 - val_accuracy: 0.8320\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7988 - val_loss: 0.3975 - val_accuracy: 0.8320\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.68 - 0s 6ms/step - loss: 0.4621 - accuracy: 0.7948 - val_loss: 0.3979 - val_accuracy: 0.8320\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4620 - accuracy: 0.7968 - val_loss: 0.3936 - val_accuracy: 0.8320\n",
      "Epoch 88/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7948 - val_loss: 0.3975 - val_accuracy: 0.8320\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5383 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7988 - val_loss: 0.3942 - val_accuracy: 0.8320\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7948 - val_loss: 0.3941 - val_accuracy: 0.8320\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5348 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7948 - val_loss: 0.3951 - val_accuracy: 0.8320\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7928 - val_loss: 0.3932 - val_accuracy: 0.8320\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5360 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7968 - val_loss: 0.3936 - val_accuracy: 0.8320\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7948 - val_loss: 0.3929 - val_accuracy: 0.8320\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7928 - val_loss: 0.3945 - val_accuracy: 0.8320\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7928 - val_loss: 0.3916 - val_accuracy: 0.8320\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7948 - val_loss: 0.3957 - val_accuracy: 0.8320\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5292 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7948 - val_loss: 0.3917 - val_accuracy: 0.8320\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7968 - val_loss: 0.3942 - val_accuracy: 0.8320\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7968 - val_loss: 0.3943 - val_accuracy: 0.8320\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7968 - val_loss: 0.3939 - val_accuracy: 0.8320\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5179 - accuracy: 0.71 - 0s 16ms/step - loss: 0.4492 - accuracy: 0.7968 - val_loss: 0.3940 - val_accuracy: 0.8400\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7968 - val_loss: 0.3932 - val_accuracy: 0.8400\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.71 - 0s 14ms/step - loss: 0.4481 - accuracy: 0.7968 - val_loss: 0.3926 - val_accuracy: 0.8480\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.71 - 0s 7ms/step - loss: 0.4472 - accuracy: 0.7968 - val_loss: 0.3927 - val_accuracy: 0.8480\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5154 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7968 - val_loss: 0.3931 - val_accuracy: 0.8480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 6df21843e83f13acd67b6dcb828b951e</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8479999899864197</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 8s - loss: 0.9307 - accuracy: 0.53 - 1s 58ms/step - loss: 0.7722 - accuracy: 0.6633 - val_loss: 0.5553 - val_accuracy: 0.7360\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8915 - accuracy: 0.56 - 0s 13ms/step - loss: 0.7070 - accuracy: 0.6733 - val_loss: 0.6286 - val_accuracy: 0.7440\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7259 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6804 - accuracy: 0.6713 - val_loss: 0.5963 - val_accuracy: 0.7440\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8326 - accuracy: 0.50 - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6614 - val_loss: 0.5655 - val_accuracy: 0.7440\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6966 - accuracy: 0.65 - 0s 15ms/step - loss: 0.6098 - accuracy: 0.7012 - val_loss: 0.5186 - val_accuracy: 0.7600\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7187 - accuracy: 0.62 - 0s 14ms/step - loss: 0.5885 - accuracy: 0.7052 - val_loss: 0.5131 - val_accuracy: 0.7760\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.62 - 0s 12ms/step - loss: 0.5795 - accuracy: 0.7231 - val_loss: 0.4982 - val_accuracy: 0.7840\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.65 - 0s 12ms/step - loss: 0.5699 - accuracy: 0.7291 - val_loss: 0.4943 - val_accuracy: 0.7920\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7410 - val_loss: 0.4846 - val_accuracy: 0.7920\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7430 - val_loss: 0.4793 - val_accuracy: 0.7840\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.71 - 0s 12ms/step - loss: 0.5439 - accuracy: 0.7570 - val_loss: 0.4725 - val_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.71 - 0s 14ms/step - loss: 0.5361 - accuracy: 0.7570 - val_loss: 0.4673 - val_accuracy: 0.8160\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6326 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7629 - val_loss: 0.4629 - val_accuracy: 0.8160\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6269 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7669 - val_loss: 0.4595 - val_accuracy: 0.8160\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.71 - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7629 - val_loss: 0.4559 - val_accuracy: 0.8160\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.71 - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7590 - val_loss: 0.4520 - val_accuracy: 0.8160\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6094 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7590 - val_loss: 0.4507 - val_accuracy: 0.8160\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7689 - val_loss: 0.4466 - val_accuracy: 0.8160\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5998 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7649 - val_loss: 0.4457 - val_accuracy: 0.8160\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5953 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7669 - val_loss: 0.4454 - val_accuracy: 0.8160\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5911 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7669 - val_loss: 0.4433 - val_accuracy: 0.8160\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5879 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7709 - val_loss: 0.4424 - val_accuracy: 0.8160\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5837 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7689 - val_loss: 0.4417 - val_accuracy: 0.8160\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5805 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7669 - val_loss: 0.4405 - val_accuracy: 0.8160\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7649 - val_loss: 0.4403 - val_accuracy: 0.8160\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7669 - val_loss: 0.4385 - val_accuracy: 0.8160\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5703 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4814 - accuracy: 0.7789 - val_loss: 0.4372 - val_accuracy: 0.8160\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7829 - val_loss: 0.4363 - val_accuracy: 0.8160\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7829 - val_loss: 0.4369 - val_accuracy: 0.8160\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7829 - val_loss: 0.4370 - val_accuracy: 0.8160\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7809 - val_loss: 0.4361 - val_accuracy: 0.8080\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7829 - val_loss: 0.4369 - val_accuracy: 0.8080\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7809 - val_loss: 0.4373 - val_accuracy: 0.8080\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5564 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7809 - val_loss: 0.4375 - val_accuracy: 0.8080\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7829 - val_loss: 0.4381 - val_accuracy: 0.8080\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5508 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7829 - val_loss: 0.4374 - val_accuracy: 0.8080\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7829 - val_loss: 0.4373 - val_accuracy: 0.8160\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5478 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7888 - val_loss: 0.4374 - val_accuracy: 0.8160\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7869 - val_loss: 0.4373 - val_accuracy: 0.8160\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5442 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7869 - val_loss: 0.4373 - val_accuracy: 0.8160\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7869 - val_loss: 0.4377 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 4209f6835815937cbb38f2a6401169d8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8159999847412109</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 16s - loss: 0.7542 - accuracy: 0.437 - ETA: 0s - loss: 0.7364 - accuracy: 0.566 - 2s 107ms/step - loss: 0.6852 - accuracy: 0.5936 - val_loss: 0.9642 - val_accuracy: 0.7040\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.53 - ETA: 0s - loss: 0.5937 - accuracy: 0.67 - 0s 28ms/step - loss: 0.5879 - accuracy: 0.6892 - val_loss: 0.7590 - val_accuracy: 0.7600\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5787 - accuracy: 0.65 - ETA: 0s - loss: 0.5420 - accuracy: 0.71 - 0s 10ms/step - loss: 0.5269 - accuracy: 0.7291 - val_loss: 0.6077 - val_accuracy: 0.7440\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.71 - ETA: 0s - loss: 0.5167 - accuracy: 0.75 - ETA: 0s - loss: 0.4922 - accuracy: 0.76 - 0s 10ms/step - loss: 0.4876 - accuracy: 0.7590 - val_loss: 0.5416 - val_accuracy: 0.7600\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.75 - ETA: 0s - loss: 0.4809 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4797 - accuracy: 0.7669 - val_loss: 0.5908 - val_accuracy: 0.7600\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.78 - ETA: 0s - loss: 0.4818 - accuracy: 0.79 - ETA: 0s - loss: 0.4587 - accuracy: 0.77 - 1s 32ms/step - loss: 0.4575 - accuracy: 0.7749 - val_loss: 0.5040 - val_accuracy: 0.7840\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.78 - ETA: 0s - loss: 0.4542 - accuracy: 0.79 - ETA: 0s - loss: 0.4495 - accuracy: 0.78 - 0s 26ms/step - loss: 0.4475 - accuracy: 0.7809 - val_loss: 0.5321 - val_accuracy: 0.8080\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.81 - ETA: 0s - loss: 0.4216 - accuracy: 0.81 - ETA: 0s - loss: 0.4391 - accuracy: 0.81 - 0s 12ms/step - loss: 0.4342 - accuracy: 0.8088 - val_loss: 0.5100 - val_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.84 - ETA: 0s - loss: 0.4286 - accuracy: 0.82 - 0s 8ms/step - loss: 0.4271 - accuracy: 0.8068 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.84 - ETA: 0s - loss: 0.4213 - accuracy: 0.83 - 0s 9ms/step - loss: 0.4244 - accuracy: 0.8108 - val_loss: 0.5617 - val_accuracy: 0.7840\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.84 - ETA: 0s - loss: 0.4142 - accuracy: 0.82 - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8167 - val_loss: 0.5057 - val_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.84 - ETA: 0s - loss: 0.4022 - accuracy: 0.83 - ETA: 0s - loss: 0.4070 - accuracy: 0.82 - 0s 10ms/step - loss: 0.4077 - accuracy: 0.8207 - val_loss: 0.4916 - val_accuracy: 0.7840\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.87 - ETA: 0s - loss: 0.4011 - accuracy: 0.84 - 0s 9ms/step - loss: 0.4033 - accuracy: 0.8307 - val_loss: 0.4744 - val_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.84 - ETA: 0s - loss: 0.3841 - accuracy: 0.83 - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8347 - val_loss: 0.4599 - val_accuracy: 0.7920\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.84 - ETA: 0s - loss: 0.3978 - accuracy: 0.83 - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8267 - val_loss: 0.4880 - val_accuracy: 0.7840\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.87 - ETA: 0s - loss: 0.3737 - accuracy: 0.85 - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8406 - val_loss: 0.4741 - val_accuracy: 0.8080\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4037 - accuracy: 0.87 - ETA: 0s - loss: 0.3764 - accuracy: 0.84 - 0s 9ms/step - loss: 0.3762 - accuracy: 0.8386 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3748 - accuracy: 0.90 - ETA: 0s - loss: 0.3665 - accuracy: 0.86 - 0s 9ms/step - loss: 0.3646 - accuracy: 0.8586 - val_loss: 0.4788 - val_accuracy: 0.7920\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.90 - ETA: 0s - loss: 0.3630 - accuracy: 0.85 - ETA: 0s - loss: 0.3659 - accuracy: 0.85 - 0s 11ms/step - loss: 0.3660 - accuracy: 0.8486 - val_loss: 0.5211 - val_accuracy: 0.7840\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.90 - ETA: 0s - loss: 0.3589 - accuracy: 0.86 - 0s 10ms/step - loss: 0.3568 - accuracy: 0.8566 - val_loss: 0.5763 - val_accuracy: 0.7840\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3621 - accuracy: 0.90 - ETA: 0s - loss: 0.3336 - accuracy: 0.86 - ETA: 0s - loss: 0.3502 - accuracy: 0.86 - 0s 9ms/step - loss: 0.3465 - accuracy: 0.8606 - val_loss: 0.4840 - val_accuracy: 0.7760\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.90 - ETA: 0s - loss: 0.3441 - accuracy: 0.87 - 0s 7ms/step - loss: 0.3453 - accuracy: 0.8625 - val_loss: 0.5041 - val_accuracy: 0.7920\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.90 - ETA: 0s - loss: 0.3532 - accuracy: 0.86 - 0s 6ms/step - loss: 0.3396 - accuracy: 0.8665 - val_loss: 0.5420 - val_accuracy: 0.7760\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.90 - ETA: 0s - loss: 0.3347 - accuracy: 0.87 - 0s 8ms/step - loss: 0.3341 - accuracy: 0.8685 - val_loss: 0.4817 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 59494f20b4ea2c87da71d2f095029348</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8080000281333923</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 1024</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 10s - loss: 2.5320 - accuracy: 0.500 - 1s 76ms/step - loss: 2.0462 - accuracy: 0.5418 - val_loss: 0.7452 - val_accuracy: 0.7280\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1140 - accuracy: 0.56 - 0s 4ms/step - loss: 1.2425 - accuracy: 0.6394 - val_loss: 0.8926 - val_accuracy: 0.7200\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.1612 - accuracy: 0.46 - 0s 18ms/step - loss: 1.3428 - accuracy: 0.5139 - val_loss: 0.5267 - val_accuracy: 0.7360\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0114 - accuracy: 0.53 - 0s 13ms/step - loss: 0.8969 - accuracy: 0.6195 - val_loss: 0.5560 - val_accuracy: 0.7440\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9911 - accuracy: 0.68 - 0s 5ms/step - loss: 0.8817 - accuracy: 0.6275 - val_loss: 0.7229 - val_accuracy: 0.7360\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8518 - accuracy: 0.43 - 0s 5ms/step - loss: 1.0101 - accuracy: 0.5976 - val_loss: 0.8433 - val_accuracy: 0.5760\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5404 - accuracy: 0.40 - ETA: 0s - loss: 1.0138 - accuracy: 0.58 - 0s 7ms/step - loss: 0.9962 - accuracy: 0.5817 - val_loss: 0.7183 - val_accuracy: 0.7360\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2367 - accuracy: 0.46 - ETA: 0s - loss: 0.9775 - accuracy: 0.57 - 0s 6ms/step - loss: 0.9838 - accuracy: 0.5837 - val_loss: 0.5326 - val_accuracy: 0.7280\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8819 - accuracy: 0.53 - 0s 4ms/step - loss: 0.8656 - accuracy: 0.5976 - val_loss: 0.5504 - val_accuracy: 0.7360\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2488 - accuracy: 0.50 - 0s 14ms/step - loss: 0.9257 - accuracy: 0.6016 - val_loss: 0.5919 - val_accuracy: 0.7520\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4071 - accuracy: 0.46 - 0s 4ms/step - loss: 0.8959 - accuracy: 0.6056 - val_loss: 0.6266 - val_accuracy: 0.7280\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9675 - accuracy: 0.53 - 0s 5ms/step - loss: 0.9417 - accuracy: 0.6255 - val_loss: 0.5273 - val_accuracy: 0.7440\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2411 - accuracy: 0.50 - ETA: 0s - loss: 0.7771 - accuracy: 0.63 - 0s 7ms/step - loss: 0.7789 - accuracy: 0.6255 - val_loss: 0.7251 - val_accuracy: 0.5440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 36a4a6c275ab90958a2a6395b117a0a2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7519999742507935</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 9s - loss: 3.1499 - accuracy: 0.46 - 1s 61ms/step - loss: 1.5734 - accuracy: 0.5578 - val_loss: 1.0151 - val_accuracy: 0.6320\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7979 - accuracy: 0.56 - 0s 12ms/step - loss: 1.0935 - accuracy: 0.6116 - val_loss: 0.5985 - val_accuracy: 0.7360\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8924 - accuracy: 0.53 - 0s 13ms/step - loss: 0.8443 - accuracy: 0.6116 - val_loss: 0.4703 - val_accuracy: 0.7680\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9005 - accuracy: 0.56 - 0s 14ms/step - loss: 0.8007 - accuracy: 0.6474 - val_loss: 0.5108 - val_accuracy: 0.7760\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8011 - accuracy: 0.62 - 0s 11ms/step - loss: 0.7938 - accuracy: 0.6554 - val_loss: 0.5148 - val_accuracy: 0.7840\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0501 - accuracy: 0.50 - ETA: 0s - loss: 0.7994 - accuracy: 0.68 - 0s 7ms/step - loss: 0.7841 - accuracy: 0.6833 - val_loss: 0.5267 - val_accuracy: 0.7760\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7359 - accuracy: 0.56 - 0s 4ms/step - loss: 0.8211 - accuracy: 0.6653 - val_loss: 0.5387 - val_accuracy: 0.7600\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9288 - accuracy: 0.65 - 0s 4ms/step - loss: 0.7894 - accuracy: 0.6773 - val_loss: 0.5863 - val_accuracy: 0.7600\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0838 - accuracy: 0.62 - 0s 15ms/step - loss: 0.7751 - accuracy: 0.6932 - val_loss: 0.4424 - val_accuracy: 0.8080\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.71 - ETA: 0s - loss: 0.7365 - accuracy: 0.71 - 0s 10ms/step - loss: 0.7361 - accuracy: 0.7331 - val_loss: 0.4299 - val_accuracy: 0.8080\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8455 - accuracy: 0.68 - ETA: 0s - loss: 0.7356 - accuracy: 0.71 - 0s 7ms/step - loss: 0.7094 - accuracy: 0.7151 - val_loss: 0.4912 - val_accuracy: 0.8080\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9382 - accuracy: 0.68 - 0s 4ms/step - loss: 0.6626 - accuracy: 0.7231 - val_loss: 0.5165 - val_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8118 - accuracy: 0.59 - ETA: 0s - loss: 0.6628 - accuracy: 0.70 - 0s 6ms/step - loss: 0.6552 - accuracy: 0.7032 - val_loss: 0.4220 - val_accuracy: 0.8080\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8491 - accuracy: 0.68 - ETA: 0s - loss: 0.6553 - accuracy: 0.75 - 0s 7ms/step - loss: 0.6332 - accuracy: 0.7570 - val_loss: 0.4284 - val_accuracy: 0.8080\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7698 - accuracy: 0.71 - ETA: 0s - loss: 0.6335 - accuracy: 0.73 - 0s 17ms/step - loss: 0.6278 - accuracy: 0.7371 - val_loss: 0.4645 - val_accuracy: 0.8160\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.62 - 0s 4ms/step - loss: 0.6232 - accuracy: 0.7131 - val_loss: 0.4717 - val_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.68 - 0s 12ms/step - loss: 0.6848 - accuracy: 0.7251 - val_loss: 0.4792 - val_accuracy: 0.8240\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6326 - accuracy: 0.65 - ETA: 0s - loss: 0.5832 - accuracy: 0.74 - 0s 7ms/step - loss: 0.5838 - accuracy: 0.7470 - val_loss: 0.5130 - val_accuracy: 0.8080\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6326 - accuracy: 0.71 - ETA: 0s - loss: 0.6925 - accuracy: 0.72 - 0s 16ms/step - loss: 0.6745 - accuracy: 0.7271 - val_loss: 0.4274 - val_accuracy: 0.8640\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.78 - 0s 6ms/step - loss: 0.6314 - accuracy: 0.7351 - val_loss: 0.4302 - val_accuracy: 0.8080\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.71 - ETA: 0s - loss: 0.6827 - accuracy: 0.73 - 0s 6ms/step - loss: 0.6815 - accuracy: 0.7311 - val_loss: 0.3771 - val_accuracy: 0.8640\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5678 - accuracy: 0.7590 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5441 - accuracy: 0.7530 - val_loss: 0.4045 - val_accuracy: 0.8320\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5797 - accuracy: 0.7450 - val_loss: 0.4289 - val_accuracy: 0.8240\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7510 - val_loss: 0.3731 - val_accuracy: 0.8400\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.84 - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7649 - val_loss: 0.3489 - val_accuracy: 0.8560\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5156 - accuracy: 0.7789 - val_loss: 0.4226 - val_accuracy: 0.8160\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9489 - accuracy: 0.68 - ETA: 0s - loss: 0.5716 - accuracy: 0.76 - 0s 7ms/step - loss: 0.5787 - accuracy: 0.7610 - val_loss: 0.4255 - val_accuracy: 0.8080\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7530 - val_loss: 0.4542 - val_accuracy: 0.8080\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.68 - ETA: 0s - loss: 0.6051 - accuracy: 0.76 - 0s 7ms/step - loss: 0.5994 - accuracy: 0.7709 - val_loss: 0.3699 - val_accuracy: 0.8480\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.81 - ETA: 0s - loss: 0.5949 - accuracy: 0.77 - 0s 8ms/step - loss: 0.5770 - accuracy: 0.7709 - val_loss: 0.4027 - val_accuracy: 0.8160\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5224 - accuracy: 0.7649 - val_loss: 0.4107 - val_accuracy: 0.8400\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7709 - val_loss: 0.3933 - val_accuracy: 0.8080\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5541 - accuracy: 0.7689 - val_loss: 0.4788 - val_accuracy: 0.8160\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5597 - accuracy: 0.7649 - val_loss: 0.4971 - val_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6666 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7789 - val_loss: 0.4629 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d7de3be74e0a46889826a5922bf4ca3b</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8640000224113464</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 1024</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 22s - loss: 0.7954 - accuracy: 0.500 - 2s 125ms/step - loss: 0.8581 - accuracy: 0.5000 - val_loss: 0.6511 - val_accuracy: 0.7120\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9256 - accuracy: 0.50 - 0s 4ms/step - loss: 0.8534 - accuracy: 0.4462 - val_loss: 0.6412 - val_accuracy: 0.6960\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2242 - accuracy: 0.31 - 0s 4ms/step - loss: 0.8567 - accuracy: 0.4801 - val_loss: 0.6416 - val_accuracy: 0.6960\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9857 - accuracy: 0.50 - 0s 4ms/step - loss: 0.8300 - accuracy: 0.5398 - val_loss: 0.6408 - val_accuracy: 0.6960\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7175 - accuracy: 0.50 - 0s 5ms/step - loss: 0.7589 - accuracy: 0.5279 - val_loss: 0.6376 - val_accuracy: 0.7040\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.56 - 0s 4ms/step - loss: 0.7789 - accuracy: 0.5279 - val_loss: 0.6325 - val_accuracy: 0.7040\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7942 - accuracy: 0.43 - 0s 4ms/step - loss: 0.7836 - accuracy: 0.5060 - val_loss: 0.6231 - val_accuracy: 0.7040\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9052 - accuracy: 0.46 - ETA: 0s - loss: 0.7612 - accuracy: 0.52 - 0s 6ms/step - loss: 0.7761 - accuracy: 0.5259 - val_loss: 0.6196 - val_accuracy: 0.6880\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.46 - ETA: 0s - loss: 0.7357 - accuracy: 0.54 - 0s 7ms/step - loss: 0.7166 - accuracy: 0.5697 - val_loss: 0.6180 - val_accuracy: 0.6880\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7458 - accuracy: 0.68 - ETA: 0s - loss: 0.7653 - accuracy: 0.56 - 0s 7ms/step - loss: 0.7669 - accuracy: 0.5598 - val_loss: 0.6170 - val_accuracy: 0.6880\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8925 - accuracy: 0.43 - ETA: 0s - loss: 0.7482 - accuracy: 0.56 - 0s 8ms/step - loss: 0.7480 - accuracy: 0.5578 - val_loss: 0.6147 - val_accuracy: 0.6960\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8611 - accuracy: 0.46 - ETA: 0s - loss: 0.7241 - accuracy: 0.59 - 0s 7ms/step - loss: 0.7272 - accuracy: 0.5777 - val_loss: 0.6123 - val_accuracy: 0.7120\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7126 - accuracy: 0.65 - 0s 15ms/step - loss: 0.7179 - accuracy: 0.6036 - val_loss: 0.6127 - val_accuracy: 0.7200\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.37 - ETA: 0s - loss: 0.7208 - accuracy: 0.54 - 0s 21ms/step - loss: 0.7101 - accuracy: 0.5578 - val_loss: 0.6114 - val_accuracy: 0.7280\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8099 - accuracy: 0.50 - ETA: 0s - loss: 0.7156 - accuracy: 0.58 - ETA: 0s - loss: 0.6994 - accuracy: 0.58 - 0s 11ms/step - loss: 0.7046 - accuracy: 0.5817 - val_loss: 0.6083 - val_accuracy: 0.7200\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7640 - accuracy: 0.40 - ETA: 0s - loss: 0.6897 - accuracy: 0.60 - 0s 8ms/step - loss: 0.6802 - accuracy: 0.6056 - val_loss: 0.6032 - val_accuracy: 0.7200\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.53 - 0s 5ms/step - loss: 0.7171 - accuracy: 0.5637 - val_loss: 0.6006 - val_accuracy: 0.7280\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.71 - ETA: 0s - loss: 0.7177 - accuracy: 0.59 - 0s 7ms/step - loss: 0.7092 - accuracy: 0.5896 - val_loss: 0.5978 - val_accuracy: 0.7280\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8627 - accuracy: 0.50 - ETA: 0s - loss: 0.7223 - accuracy: 0.58 - 0s 18ms/step - loss: 0.7238 - accuracy: 0.5857 - val_loss: 0.5959 - val_accuracy: 0.7360\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7053 - accuracy: 0.46 - ETA: 0s - loss: 0.7184 - accuracy: 0.56 - ETA: 0s - loss: 0.7185 - accuracy: 0.58 - 0s 12ms/step - loss: 0.7127 - accuracy: 0.5837 - val_loss: 0.5950 - val_accuracy: 0.7360\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7300 - accuracy: 0.53 - ETA: 0s - loss: 0.7165 - accuracy: 0.57 - 0s 6ms/step - loss: 0.7047 - accuracy: 0.5797 - val_loss: 0.5981 - val_accuracy: 0.7200\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7409 - accuracy: 0.56 - 0s 6ms/step - loss: 0.7169 - accuracy: 0.5797 - val_loss: 0.5973 - val_accuracy: 0.7200\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7449 - accuracy: 0.59 - ETA: 0s - loss: 0.7153 - accuracy: 0.61 - 0s 6ms/step - loss: 0.7147 - accuracy: 0.6036 - val_loss: 0.5969 - val_accuracy: 0.7280\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6568 - accuracy: 0.68 - ETA: 0s - loss: 0.7003 - accuracy: 0.59 - 0s 7ms/step - loss: 0.7006 - accuracy: 0.6056 - val_loss: 0.5955 - val_accuracy: 0.7200\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8050 - accuracy: 0.59 - ETA: 0s - loss: 0.7045 - accuracy: 0.61 - 0s 7ms/step - loss: 0.6918 - accuracy: 0.6096 - val_loss: 0.5931 - val_accuracy: 0.7200\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7818 - accuracy: 0.56 - ETA: 0s - loss: 0.6869 - accuracy: 0.60 - 0s 7ms/step - loss: 0.6917 - accuracy: 0.6116 - val_loss: 0.5920 - val_accuracy: 0.7200\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8021 - accuracy: 0.50 - ETA: 0s - loss: 0.7188 - accuracy: 0.59 - 0s 7ms/step - loss: 0.7211 - accuracy: 0.5837 - val_loss: 0.5919 - val_accuracy: 0.7200\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8450 - accuracy: 0.40 - 0s 5ms/step - loss: 0.6908 - accuracy: 0.6096 - val_loss: 0.5916 - val_accuracy: 0.7200\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7759 - accuracy: 0.53 - ETA: 0s - loss: 0.7175 - accuracy: 0.58 - 0s 6ms/step - loss: 0.6978 - accuracy: 0.6056 - val_loss: 0.5909 - val_accuracy: 0.7200\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7789 - accuracy: 0.50 - 0s 6ms/step - loss: 0.6728 - accuracy: 0.6255 - val_loss: 0.5890 - val_accuracy: 0.7200\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.62 - ETA: 0s - loss: 0.6732 - accuracy: 0.59 - 0s 7ms/step - loss: 0.6745 - accuracy: 0.5916 - val_loss: 0.5885 - val_accuracy: 0.7200\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8441 - accuracy: 0.53 - ETA: 0s - loss: 0.7046 - accuracy: 0.61 - 0s 7ms/step - loss: 0.7045 - accuracy: 0.6096 - val_loss: 0.5894 - val_accuracy: 0.7360\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7577 - accuracy: 0.46 - 0s 6ms/step - loss: 0.6835 - accuracy: 0.5916 - val_loss: 0.5892 - val_accuracy: 0.7200\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.56 - ETA: 0s - loss: 0.6686 - accuracy: 0.64 - 0s 7ms/step - loss: 0.6726 - accuracy: 0.6315 - val_loss: 0.5900 - val_accuracy: 0.7200\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7302 - accuracy: 0.43 - 0s 5ms/step - loss: 0.6862 - accuracy: 0.6056 - val_loss: 0.5917 - val_accuracy: 0.7120\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7204 - accuracy: 0.59 - 0s 4ms/step - loss: 0.6687 - accuracy: 0.6135 - val_loss: 0.5922 - val_accuracy: 0.7120\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6961 - accuracy: 0.59 - 0s 6ms/step - loss: 0.6514 - accuracy: 0.6335 - val_loss: 0.5896 - val_accuracy: 0.7200\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7437 - accuracy: 0.46 - ETA: 0s - loss: 0.7071 - accuracy: 0.57 - 0s 7ms/step - loss: 0.6900 - accuracy: 0.5857 - val_loss: 0.5885 - val_accuracy: 0.7120\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8378 - accuracy: 0.46 - ETA: 0s - loss: 0.6855 - accuracy: 0.59 - 0s 7ms/step - loss: 0.6800 - accuracy: 0.6076 - val_loss: 0.5880 - val_accuracy: 0.7120\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7359 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.63 - 0s 7ms/step - loss: 0.6908 - accuracy: 0.6175 - val_loss: 0.5867 - val_accuracy: 0.7360\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7756 - accuracy: 0.46 - ETA: 0s - loss: 0.6994 - accuracy: 0.59 - 0s 21ms/step - loss: 0.6909 - accuracy: 0.5936 - val_loss: 0.5855 - val_accuracy: 0.7680\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.59 - ETA: 0s - loss: 0.6590 - accuracy: 0.66 - ETA: 0s - loss: 0.6792 - accuracy: 0.63 - 0s 14ms/step - loss: 0.6711 - accuracy: 0.6375 - val_loss: 0.5837 - val_accuracy: 0.7600\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.62 - ETA: 0s - loss: 0.6900 - accuracy: 0.58 - 0s 7ms/step - loss: 0.6823 - accuracy: 0.5956 - val_loss: 0.5815 - val_accuracy: 0.7600\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7469 - accuracy: 0.46 - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6275 - val_loss: 0.5782 - val_accuracy: 0.7680\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7903 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6634 - accuracy: 0.6335 - val_loss: 0.5776 - val_accuracy: 0.7680\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7090 - accuracy: 0.50 - ETA: 0s - loss: 0.6901 - accuracy: 0.59 - 0s 6ms/step - loss: 0.6734 - accuracy: 0.6016 - val_loss: 0.5756 - val_accuracy: 0.7600\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7392 - accuracy: 0.43 - ETA: 0s - loss: 0.6718 - accuracy: 0.62 - 0s 7ms/step - loss: 0.6736 - accuracy: 0.6195 - val_loss: 0.5752 - val_accuracy: 0.7680\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6628 - accuracy: 0.63 - 0s 7ms/step - loss: 0.6564 - accuracy: 0.6235 - val_loss: 0.5776 - val_accuracy: 0.7680\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7087 - accuracy: 0.50 - ETA: 0s - loss: 0.6534 - accuracy: 0.62 - 0s 6ms/step - loss: 0.6484 - accuracy: 0.6315 - val_loss: 0.5787 - val_accuracy: 0.7520\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6528 - accuracy: 0.62 - ETA: 0s - loss: 0.6692 - accuracy: 0.62 - 0s 6ms/step - loss: 0.6636 - accuracy: 0.6275 - val_loss: 0.5766 - val_accuracy: 0.7600\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7613 - accuracy: 0.59 - ETA: 0s - loss: 0.6678 - accuracy: 0.64 - 0s 6ms/step - loss: 0.6678 - accuracy: 0.6394 - val_loss: 0.5729 - val_accuracy: 0.7680\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7428 - accuracy: 0.50 - 0s 4ms/step - loss: 0.6779 - accuracy: 0.6076 - val_loss: 0.5753 - val_accuracy: 0.7680\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8043 - accuracy: 0.43 - ETA: 0s - loss: 0.6958 - accuracy: 0.58 - 0s 7ms/step - loss: 0.6978 - accuracy: 0.5876 - val_loss: 0.5765 - val_accuracy: 0.7680\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.65 - ETA: 0s - loss: 0.6690 - accuracy: 0.61 - 0s 7ms/step - loss: 0.6702 - accuracy: 0.6135 - val_loss: 0.5781 - val_accuracy: 0.7680\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.59 - ETA: 0s - loss: 0.6503 - accuracy: 0.62 - 0s 7ms/step - loss: 0.6526 - accuracy: 0.6235 - val_loss: 0.5774 - val_accuracy: 0.7600\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.56 - ETA: 0s - loss: 0.6781 - accuracy: 0.60 - 0s 8ms/step - loss: 0.6762 - accuracy: 0.6036 - val_loss: 0.5776 - val_accuracy: 0.7680\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7070 - accuracy: 0.53 - ETA: 0s - loss: 0.6710 - accuracy: 0.60 - 0s 8ms/step - loss: 0.6667 - accuracy: 0.6016 - val_loss: 0.5750 - val_accuracy: 0.7600\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6845 - accuracy: 0.56 - ETA: 0s - loss: 0.6586 - accuracy: 0.61 - 0s 7ms/step - loss: 0.6465 - accuracy: 0.6255 - val_loss: 0.5734 - val_accuracy: 0.7680\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6969 - accuracy: 0.50 - ETA: 0s - loss: 0.6590 - accuracy: 0.61 - 0s 22ms/step - loss: 0.6522 - accuracy: 0.6315 - val_loss: 0.5709 - val_accuracy: 0.7760\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.53 - ETA: 0s - loss: 0.6662 - accuracy: 0.62 - 0s 7ms/step - loss: 0.6692 - accuracy: 0.6275 - val_loss: 0.5708 - val_accuracy: 0.7760\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6678 - accuracy: 0.59 - ETA: 0s - loss: 0.6495 - accuracy: 0.64 - 0s 7ms/step - loss: 0.6472 - accuracy: 0.6434 - val_loss: 0.5718 - val_accuracy: 0.7760\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6993 - accuracy: 0.56 - ETA: 0s - loss: 0.6500 - accuracy: 0.63 - 0s 6ms/step - loss: 0.6586 - accuracy: 0.6355 - val_loss: 0.5718 - val_accuracy: 0.7760\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.53 - ETA: 0s - loss: 0.6667 - accuracy: 0.61 - 0s 6ms/step - loss: 0.6666 - accuracy: 0.6116 - val_loss: 0.5700 - val_accuracy: 0.7760\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7253 - accuracy: 0.59 - ETA: 0s - loss: 0.6560 - accuracy: 0.61 - 0s 7ms/step - loss: 0.6530 - accuracy: 0.6155 - val_loss: 0.5675 - val_accuracy: 0.7760\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7268 - accuracy: 0.56 - ETA: 0s - loss: 0.6434 - accuracy: 0.64 - 0s 6ms/step - loss: 0.6437 - accuracy: 0.6514 - val_loss: 0.5640 - val_accuracy: 0.7760\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6805 - accuracy: 0.59 - 0s 5ms/step - loss: 0.6438 - accuracy: 0.6554 - val_loss: 0.5613 - val_accuracy: 0.7760\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7270 - accuracy: 0.53 - ETA: 0s - loss: 0.6337 - accuracy: 0.64 - 0s 7ms/step - loss: 0.6344 - accuracy: 0.6414 - val_loss: 0.5608 - val_accuracy: 0.7760\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7500 - accuracy: 0.56 - ETA: 0s - loss: 0.6549 - accuracy: 0.64 - 0s 6ms/step - loss: 0.6539 - accuracy: 0.6414 - val_loss: 0.5671 - val_accuracy: 0.7600\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.68 - ETA: 0s - loss: 0.6523 - accuracy: 0.63 - 0s 7ms/step - loss: 0.6479 - accuracy: 0.6335 - val_loss: 0.5673 - val_accuracy: 0.7440\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.53 - ETA: 0s - loss: 0.6356 - accuracy: 0.64 - 0s 20ms/step - loss: 0.6284 - accuracy: 0.6534 - val_loss: 0.5604 - val_accuracy: 0.7840\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7108 - accuracy: 0.46 - ETA: 0s - loss: 0.6334 - accuracy: 0.64 - ETA: 0s - loss: 0.6411 - accuracy: 0.64 - 0s 12ms/step - loss: 0.6404 - accuracy: 0.6375 - val_loss: 0.5553 - val_accuracy: 0.7840\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7660 - accuracy: 0.46 - ETA: 0s - loss: 0.6260 - accuracy: 0.65 - 0s 13ms/step - loss: 0.6271 - accuracy: 0.6494 - val_loss: 0.5559 - val_accuracy: 0.7920\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7041 - accuracy: 0.59 - ETA: 0s - loss: 0.6428 - accuracy: 0.64 - 0s 7ms/step - loss: 0.6270 - accuracy: 0.6534 - val_loss: 0.5503 - val_accuracy: 0.7840\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7077 - accuracy: 0.59 - ETA: 0s - loss: 0.6477 - accuracy: 0.63 - 0s 7ms/step - loss: 0.6415 - accuracy: 0.6434 - val_loss: 0.5444 - val_accuracy: 0.7840\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.6546 - accuracy: 0.59 - ETA: 0s - loss: 0.6230 - accuracy: 0.64 - 0s 17ms/step - loss: 0.6137 - accuracy: 0.6594 - val_loss: 0.5372 - val_accuracy: 0.8240\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.53 - ETA: 0s - loss: 0.6311 - accuracy: 0.65 - 0s 14ms/step - loss: 0.6225 - accuracy: 0.6653 - val_loss: 0.5332 - val_accuracy: 0.8320\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.59 - ETA: 0s - loss: 0.6344 - accuracy: 0.67 - 0s 16ms/step - loss: 0.6208 - accuracy: 0.6773 - val_loss: 0.5384 - val_accuracy: 0.8400\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6646 - accuracy: 0.65 - ETA: 0s - loss: 0.6171 - accuracy: 0.65 - 0s 7ms/step - loss: 0.6221 - accuracy: 0.6494 - val_loss: 0.5465 - val_accuracy: 0.7680\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8126 - accuracy: 0.50 - ETA: 0s - loss: 0.6414 - accuracy: 0.67 - 0s 7ms/step - loss: 0.6270 - accuracy: 0.6853 - val_loss: 0.5414 - val_accuracy: 0.8000\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7163 - accuracy: 0.53 - ETA: 0s - loss: 0.6400 - accuracy: 0.64 - 0s 9ms/step - loss: 0.6335 - accuracy: 0.6534 - val_loss: 0.5328 - val_accuracy: 0.8400\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.59 - ETA: 0s - loss: 0.6246 - accuracy: 0.67 - 0s 6ms/step - loss: 0.6307 - accuracy: 0.6753 - val_loss: 0.5362 - val_accuracy: 0.8240\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8152 - accuracy: 0.56 - ETA: 0s - loss: 0.6411 - accuracy: 0.66 - 0s 8ms/step - loss: 0.6244 - accuracy: 0.6693 - val_loss: 0.5315 - val_accuracy: 0.8400\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7280 - accuracy: 0.50 - 0s 5ms/step - loss: 0.6191 - accuracy: 0.6793 - val_loss: 0.5305 - val_accuracy: 0.8400\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7765 - accuracy: 0.46 - 0s 13ms/step - loss: 0.6417 - accuracy: 0.6335 - val_loss: 0.5267 - val_accuracy: 0.8560\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.56 - ETA: 0s - loss: 0.6133 - accuracy: 0.67 - 0s 6ms/step - loss: 0.6196 - accuracy: 0.6753 - val_loss: 0.5233 - val_accuracy: 0.8400\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.62 - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6494 - val_loss: 0.5151 - val_accuracy: 0.8400\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6873 - val_loss: 0.5143 - val_accuracy: 0.8480\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6879 - accuracy: 0.53 - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6693 - val_loss: 0.5169 - val_accuracy: 0.8400\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8002 - accuracy: 0.53 - 0s 4ms/step - loss: 0.6456 - accuracy: 0.6375 - val_loss: 0.5230 - val_accuracy: 0.8320\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.68 - 0s 6ms/step - loss: 0.6026 - accuracy: 0.6853 - val_loss: 0.5158 - val_accuracy: 0.8480\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.59 - ETA: 0s - loss: 0.6182 - accuracy: 0.67 - 0s 7ms/step - loss: 0.6156 - accuracy: 0.6693 - val_loss: 0.5106 - val_accuracy: 0.8480\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.59 - ETA: 0s - loss: 0.6000 - accuracy: 0.69 - 0s 7ms/step - loss: 0.5990 - accuracy: 0.6992 - val_loss: 0.5031 - val_accuracy: 0.8400\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7018 - accuracy: 0.62 - ETA: 0s - loss: 0.6256 - accuracy: 0.67 - 0s 7ms/step - loss: 0.6268 - accuracy: 0.6693 - val_loss: 0.5077 - val_accuracy: 0.8480\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.75 - ETA: 0s - loss: 0.5921 - accuracy: 0.71 - 0s 7ms/step - loss: 0.5842 - accuracy: 0.7211 - val_loss: 0.5116 - val_accuracy: 0.8480\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.59 - ETA: 0s - loss: 0.6296 - accuracy: 0.66 - 0s 7ms/step - loss: 0.6224 - accuracy: 0.6733 - val_loss: 0.5165 - val_accuracy: 0.8480\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6437 - accuracy: 0.59 - ETA: 0s - loss: 0.5988 - accuracy: 0.68 - 0s 7ms/step - loss: 0.5845 - accuracy: 0.6972 - val_loss: 0.5177 - val_accuracy: 0.8240\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.68 - ETA: 0s - loss: 0.6171 - accuracy: 0.68 - 0s 7ms/step - loss: 0.6166 - accuracy: 0.6892 - val_loss: 0.5057 - val_accuracy: 0.8240\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7496 - accuracy: 0.62 - ETA: 0s - loss: 0.6300 - accuracy: 0.67 - 0s 9ms/step - loss: 0.6120 - accuracy: 0.6892 - val_loss: 0.5061 - val_accuracy: 0.8160\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5545 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5931 - accuracy: 0.6873 - val_loss: 0.5137 - val_accuracy: 0.8400\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7487 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6192 - accuracy: 0.6892 - val_loss: 0.5098 - val_accuracy: 0.8320\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.62 - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6813 - val_loss: 0.5003 - val_accuracy: 0.8560\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7222 - accuracy: 0.56 - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6972 - val_loss: 0.4893 - val_accuracy: 0.8560\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6773 - val_loss: 0.4888 - val_accuracy: 0.8560\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.68 - ETA: 0s - loss: 0.5820 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5858 - accuracy: 0.7151 - val_loss: 0.4898 - val_accuracy: 0.8400\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6786 - accuracy: 0.68 - ETA: 0s - loss: 0.6255 - accuracy: 0.68 - 0s 6ms/step - loss: 0.6126 - accuracy: 0.6952 - val_loss: 0.4981 - val_accuracy: 0.8480\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7377 - accuracy: 0.59 - 0s 19ms/step - loss: 0.5866 - accuracy: 0.7072 - val_loss: 0.5083 - val_accuracy: 0.8640\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.71 - ETA: 0s - loss: 0.5615 - accuracy: 0.75 - ETA: 0s - loss: 0.5719 - accuracy: 0.73 - 0s 15ms/step - loss: 0.5764 - accuracy: 0.7251 - val_loss: 0.5202 - val_accuracy: 0.8560\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6017 - accuracy: 0.75 - ETA: 0s - loss: 0.5515 - accuracy: 0.76 - 0s 10ms/step - loss: 0.5541 - accuracy: 0.7490 - val_loss: 0.4996 - val_accuracy: 0.8560\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.62 - ETA: 0s - loss: 0.6073 - accuracy: 0.70 - 0s 7ms/step - loss: 0.6005 - accuracy: 0.7092 - val_loss: 0.4884 - val_accuracy: 0.8480\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.81 - ETA: 0s - loss: 0.5946 - accuracy: 0.70 - 0s 7ms/step - loss: 0.5967 - accuracy: 0.7151 - val_loss: 0.4852 - val_accuracy: 0.8560\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7131 - val_loss: 0.4729 - val_accuracy: 0.8400\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7012 - val_loss: 0.4679 - val_accuracy: 0.8480\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5742 - accuracy: 0.6992 - val_loss: 0.4715 - val_accuracy: 0.8320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7461 - accuracy: 0.62 - ETA: 0s - loss: 0.6049 - accuracy: 0.70 - 0s 7ms/step - loss: 0.6020 - accuracy: 0.7052 - val_loss: 0.4737 - val_accuracy: 0.8560\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8362 - accuracy: 0.65 - ETA: 0s - loss: 0.6055 - accuracy: 0.71 - 0s 6ms/step - loss: 0.6086 - accuracy: 0.7112 - val_loss: 0.4758 - val_accuracy: 0.8560\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7092 - val_loss: 0.4884 - val_accuracy: 0.8400\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.56 - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7032 - val_loss: 0.4866 - val_accuracy: 0.8400\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7450 - val_loss: 0.4734 - val_accuracy: 0.8560\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5887 - accuracy: 0.6972 - val_loss: 0.4643 - val_accuracy: 0.8560\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6021 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7151 - val_loss: 0.4582 - val_accuracy: 0.8400\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7092 - val_loss: 0.4627 - val_accuracy: 0.8480\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.59 - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7211 - val_loss: 0.4812 - val_accuracy: 0.8480\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5612 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5804 - accuracy: 0.6992 - val_loss: 0.4851 - val_accuracy: 0.8320\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.56 - ETA: 0s - loss: 0.5872 - accuracy: 0.72 - 0s 7ms/step - loss: 0.5829 - accuracy: 0.7251 - val_loss: 0.4662 - val_accuracy: 0.8560\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.65 - ETA: 0s - loss: 0.5906 - accuracy: 0.71 - 0s 7ms/step - loss: 0.5819 - accuracy: 0.7231 - val_loss: 0.4665 - val_accuracy: 0.8560\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5854 - accuracy: 0.6912 - val_loss: 0.4700 - val_accuracy: 0.8480\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.59 - ETA: 0s - loss: 0.6079 - accuracy: 0.70 - 0s 7ms/step - loss: 0.5881 - accuracy: 0.7191 - val_loss: 0.4706 - val_accuracy: 0.8480\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5862 - accuracy: 0.75 - ETA: 0s - loss: 0.5607 - accuracy: 0.73 - 0s 7ms/step - loss: 0.5619 - accuracy: 0.7430 - val_loss: 0.4630 - val_accuracy: 0.8400\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6657 - accuracy: 0.62 - ETA: 0s - loss: 0.5731 - accuracy: 0.70 - 0s 7ms/step - loss: 0.5822 - accuracy: 0.7052 - val_loss: 0.4629 - val_accuracy: 0.8320\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7156 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5730 - accuracy: 0.7052 - val_loss: 0.4651 - val_accuracy: 0.8480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 5af5b78bd9f79808385b5b1a9e85ef8a</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8640000224113464</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 9s - loss: 1.4493 - accuracy: 0.53 - 1s 72ms/step - loss: 0.7195 - accuracy: 0.6474 - val_loss: 0.6154 - val_accuracy: 0.7200\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7513 - accuracy: 0.46 - 0s 4ms/step - loss: 0.6777 - accuracy: 0.6394 - val_loss: 0.5559 - val_accuracy: 0.7120\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7775 - accuracy: 0.53 - 0s 19ms/step - loss: 0.7092 - accuracy: 0.6554 - val_loss: 0.5430 - val_accuracy: 0.7280\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9088 - accuracy: 0.56 - 0s 4ms/step - loss: 0.7188 - accuracy: 0.6414 - val_loss: 0.6011 - val_accuracy: 0.7120\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8649 - accuracy: 0.46 - 0s 4ms/step - loss: 0.7123 - accuracy: 0.6275 - val_loss: 0.6217 - val_accuracy: 0.7280\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9428 - accuracy: 0.46 - 0s 3ms/step - loss: 0.6782 - accuracy: 0.6275 - val_loss: 0.5876 - val_accuracy: 0.7280\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8072 - accuracy: 0.46 - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6255 - val_loss: 0.5477 - val_accuracy: 0.7200\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8339 - accuracy: 0.53 - 0s 12ms/step - loss: 0.6349 - accuracy: 0.6394 - val_loss: 0.5505 - val_accuracy: 0.7360\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7890 - accuracy: 0.46 - 0s 5ms/step - loss: 0.6319 - accuracy: 0.6315 - val_loss: 0.5472 - val_accuracy: 0.7360\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8192 - accuracy: 0.50 - 0s 6ms/step - loss: 0.6297 - accuracy: 0.6335 - val_loss: 0.5501 - val_accuracy: 0.7280\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7967 - accuracy: 0.46 - 0s 5ms/step - loss: 0.6259 - accuracy: 0.6355 - val_loss: 0.5462 - val_accuracy: 0.7360\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8010 - accuracy: 0.50 - 0s 12ms/step - loss: 0.6211 - accuracy: 0.6394 - val_loss: 0.5428 - val_accuracy: 0.7520\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7869 - accuracy: 0.53 - ETA: 0s - loss: 0.6202 - accuracy: 0.65 - 0s 7ms/step - loss: 0.6158 - accuracy: 0.6534 - val_loss: 0.5396 - val_accuracy: 0.7520\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7731 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6108 - accuracy: 0.6494 - val_loss: 0.5364 - val_accuracy: 0.7520\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7744 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6073 - accuracy: 0.6534 - val_loss: 0.5346 - val_accuracy: 0.7520\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7639 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6005 - accuracy: 0.6594 - val_loss: 0.5292 - val_accuracy: 0.7520\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7539 - accuracy: 0.56 - 0s 5ms/step - loss: 0.5961 - accuracy: 0.6633 - val_loss: 0.5281 - val_accuracy: 0.7520\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7403 - accuracy: 0.56 - 0s 5ms/step - loss: 0.5906 - accuracy: 0.6653 - val_loss: 0.5251 - val_accuracy: 0.7520\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7370 - accuracy: 0.56 - 0s 6ms/step - loss: 0.5858 - accuracy: 0.6733 - val_loss: 0.5251 - val_accuracy: 0.7440\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7227 - accuracy: 0.56 - 0s 6ms/step - loss: 0.5814 - accuracy: 0.6833 - val_loss: 0.5269 - val_accuracy: 0.7520\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.53 - 0s 6ms/step - loss: 0.5776 - accuracy: 0.6813 - val_loss: 0.5188 - val_accuracy: 0.7520\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7121 - accuracy: 0.53 - 0s 6ms/step - loss: 0.5727 - accuracy: 0.6873 - val_loss: 0.5236 - val_accuracy: 0.7360\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.59 - 0s 6ms/step - loss: 0.5672 - accuracy: 0.6912 - val_loss: 0.5315 - val_accuracy: 0.7520\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6971 - accuracy: 0.62 - 0s 5ms/step - loss: 0.5688 - accuracy: 0.7092 - val_loss: 0.5095 - val_accuracy: 0.7360\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7227 - accuracy: 0.53 - 0s 13ms/step - loss: 0.5642 - accuracy: 0.7072 - val_loss: 0.5147 - val_accuracy: 0.7600\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.62 - 0s 5ms/step - loss: 0.5553 - accuracy: 0.7072 - val_loss: 0.5138 - val_accuracy: 0.7600\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6760 - accuracy: 0.62 - 0s 11ms/step - loss: 0.5527 - accuracy: 0.7171 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6566 - accuracy: 0.62 - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7311 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.68 - 0s 7ms/step - loss: 0.5419 - accuracy: 0.7450 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7410 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7470 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.68 - ETA: 0s - loss: 0.5486 - accuracy: 0.74 - 0s 13ms/step - loss: 0.5305 - accuracy: 0.7530 - val_loss: 0.4904 - val_accuracy: 0.7840\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7629 - val_loss: 0.4917 - val_accuracy: 0.7680\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5267 - accuracy: 0.7550 - val_loss: 0.4778 - val_accuracy: 0.7840\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.71 - 0s 12ms/step - loss: 0.5190 - accuracy: 0.7590 - val_loss: 0.4713 - val_accuracy: 0.7920\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.68 - 0s 16ms/step - loss: 0.5167 - accuracy: 0.7669 - val_loss: 0.4599 - val_accuracy: 0.8080\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5101 - accuracy: 0.7729 - val_loss: 0.4565 - val_accuracy: 0.8080\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5995 - accuracy: 0.71 - 0s 12ms/step - loss: 0.5083 - accuracy: 0.7769 - val_loss: 0.4547 - val_accuracy: 0.8160\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5920 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7729 - val_loss: 0.4529 - val_accuracy: 0.8160\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5968 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5046 - accuracy: 0.7809 - val_loss: 0.4464 - val_accuracy: 0.8080\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7769 - val_loss: 0.4473 - val_accuracy: 0.8160\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7769 - val_loss: 0.4471 - val_accuracy: 0.8080\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7789 - val_loss: 0.4431 - val_accuracy: 0.8160\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5803 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7769 - val_loss: 0.4417 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5822 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7849 - val_loss: 0.4493 - val_accuracy: 0.8000\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5799 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7749 - val_loss: 0.4407 - val_accuracy: 0.8160\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5869 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7729 - val_loss: 0.4373 - val_accuracy: 0.8160\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5934 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7829 - val_loss: 0.4370 - val_accuracy: 0.8080\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.71 - 0s 16ms/step - loss: 0.4789 - accuracy: 0.7869 - val_loss: 0.4433 - val_accuracy: 0.8240\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7849 - val_loss: 0.4386 - val_accuracy: 0.8160\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7869 - val_loss: 0.4356 - val_accuracy: 0.8240\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7849 - val_loss: 0.4341 - val_accuracy: 0.8240\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7908 - val_loss: 0.4286 - val_accuracy: 0.8240\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.71 - ETA: 0s - loss: 0.4763 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7888 - val_loss: 0.4201 - val_accuracy: 0.8160\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7968 - val_loss: 0.4235 - val_accuracy: 0.8240\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5490 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7968 - val_loss: 0.4229 - val_accuracy: 0.8240\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7988 - val_loss: 0.4246 - val_accuracy: 0.8240\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4598 - accuracy: 0.8028 - val_loss: 0.4259 - val_accuracy: 0.8160\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4590 - accuracy: 0.8008 - val_loss: 0.4337 - val_accuracy: 0.8160\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7988 - val_loss: 0.4285 - val_accuracy: 0.8160\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4561 - accuracy: 0.8008 - val_loss: 0.4312 - val_accuracy: 0.8160\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7968 - val_loss: 0.4282 - val_accuracy: 0.8160\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8028 - val_loss: 0.4324 - val_accuracy: 0.8240\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4539 - accuracy: 0.8028 - val_loss: 0.4299 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3d76cd7352428cfee36d47813b3550fe</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8240000009536743</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 9s - loss: 2.2536 - accuracy: 0.53 - 1s 61ms/step - loss: 1.8932 - accuracy: 0.5578 - val_loss: 0.6901 - val_accuracy: 0.6800\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5544 - accuracy: 0.53 - 0s 12ms/step - loss: 1.4150 - accuracy: 0.5737 - val_loss: 0.5192 - val_accuracy: 0.7280\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0439 - accuracy: 0.62 - 0s 11ms/step - loss: 1.3169 - accuracy: 0.6375 - val_loss: 0.7177 - val_accuracy: 0.7520\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9968 - accuracy: 0.59 - 0s 4ms/step - loss: 1.1824 - accuracy: 0.6355 - val_loss: 0.5099 - val_accuracy: 0.7520\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0568 - accuracy: 0.50 - 0s 14ms/step - loss: 1.1568 - accuracy: 0.6175 - val_loss: 0.5013 - val_accuracy: 0.7600\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8916 - accuracy: 0.62 - 0s 15ms/step - loss: 1.2382 - accuracy: 0.5976 - val_loss: 0.5798 - val_accuracy: 0.7760\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8412 - accuracy: 0.65 - ETA: 0s - loss: 1.1282 - accuracy: 0.63 - 0s 7ms/step - loss: 1.2120 - accuracy: 0.6434 - val_loss: 0.4832 - val_accuracy: 0.7600\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9986 - accuracy: 0.56 - ETA: 0s - loss: 1.0498 - accuracy: 0.61 - 0s 7ms/step - loss: 1.0685 - accuracy: 0.6175 - val_loss: 0.5779 - val_accuracy: 0.7760\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2035 - accuracy: 0.59 - ETA: 0s - loss: 1.0589 - accuracy: 0.62 - 0s 15ms/step - loss: 1.0201 - accuracy: 0.6295 - val_loss: 0.4144 - val_accuracy: 0.8320\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8348 - accuracy: 0.65 - ETA: 0s - loss: 0.9159 - accuracy: 0.63 - 0s 6ms/step - loss: 0.9528 - accuracy: 0.6315 - val_loss: 0.4332 - val_accuracy: 0.8080\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.62 - 0s 6ms/step - loss: 0.8118 - accuracy: 0.6773 - val_loss: 0.4337 - val_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3462 - accuracy: 0.62 - ETA: 0s - loss: 0.9474 - accuracy: 0.68 - 0s 6ms/step - loss: 0.9507 - accuracy: 0.6813 - val_loss: 0.4621 - val_accuracy: 0.8160\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2637 - accuracy: 0.65 - ETA: 0s - loss: 0.9376 - accuracy: 0.66 - 0s 7ms/step - loss: 0.9079 - accuracy: 0.6713 - val_loss: 0.4298 - val_accuracy: 0.8080\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8202 - accuracy: 0.53 - ETA: 0s - loss: 0.7963 - accuracy: 0.68 - 0s 7ms/step - loss: 0.7784 - accuracy: 0.6853 - val_loss: 0.4408 - val_accuracy: 0.8160\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8472 - accuracy: 0.53 - 0s 5ms/step - loss: 0.7686 - accuracy: 0.6733 - val_loss: 0.4679 - val_accuracy: 0.7920\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8428 - accuracy: 0.59 - 0s 6ms/step - loss: 0.8208 - accuracy: 0.7012 - val_loss: 0.4163 - val_accuracy: 0.8160\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.71 - ETA: 0s - loss: 0.7132 - accuracy: 0.69 - 0s 8ms/step - loss: 0.7127 - accuracy: 0.6992 - val_loss: 0.3994 - val_accuracy: 0.8160\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8180 - accuracy: 0.56 - 0s 5ms/step - loss: 0.7278 - accuracy: 0.7052 - val_loss: 0.4097 - val_accuracy: 0.8240\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.75 - 0s 5ms/step - loss: 0.6658 - accuracy: 0.7331 - val_loss: 0.4245 - val_accuracy: 0.8160\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.65 - 0s 14ms/step - loss: 0.7515 - accuracy: 0.7191 - val_loss: 0.3803 - val_accuracy: 0.8400\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.75 - ETA: 0s - loss: 0.6979 - accuracy: 0.69 - 0s 17ms/step - loss: 0.6893 - accuracy: 0.6952 - val_loss: 0.3732 - val_accuracy: 0.8480\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5858 - accuracy: 0.68 - ETA: 0s - loss: 0.6012 - accuracy: 0.74 - 0s 15ms/step - loss: 0.6272 - accuracy: 0.7311 - val_loss: 0.3962 - val_accuracy: 0.8720\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0011 - accuracy: 0.75 - 0s 5ms/step - loss: 0.6240 - accuracy: 0.7550 - val_loss: 0.3819 - val_accuracy: 0.8320\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.68 - ETA: 0s - loss: 0.6105 - accuracy: 0.74 - 0s 6ms/step - loss: 0.6048 - accuracy: 0.7430 - val_loss: 0.3852 - val_accuracy: 0.8160\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.75 - ETA: 0s - loss: 0.5993 - accuracy: 0.75 - 0s 6ms/step - loss: 0.6092 - accuracy: 0.7550 - val_loss: 0.3662 - val_accuracy: 0.8640\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8872 - accuracy: 0.75 - ETA: 0s - loss: 0.6153 - accuracy: 0.75 - 0s 6ms/step - loss: 0.6179 - accuracy: 0.7450 - val_loss: 0.4226 - val_accuracy: 0.8320\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.65 - ETA: 0s - loss: 0.7354 - accuracy: 0.73 - 0s 7ms/step - loss: 0.8071 - accuracy: 0.7291 - val_loss: 0.3885 - val_accuracy: 0.8240\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.78 - 0s 6ms/step - loss: 0.6581 - accuracy: 0.7470 - val_loss: 0.3634 - val_accuracy: 0.8640\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4581 - accuracy: 0.81 - ETA: 0s - loss: 0.5778 - accuracy: 0.76 - 0s 6ms/step - loss: 0.5999 - accuracy: 0.7610 - val_loss: 0.3828 - val_accuracy: 0.8160\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.62 - 0s 11ms/step - loss: 0.6379 - accuracy: 0.7291 - val_loss: 0.3811 - val_accuracy: 0.8800\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.75 - ETA: 0s - loss: 0.5644 - accuracy: 0.76 - 0s 11ms/step - loss: 0.5706 - accuracy: 0.7629 - val_loss: 0.3715 - val_accuracy: 0.8240\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8548 - accuracy: 0.78 - ETA: 0s - loss: 0.5644 - accuracy: 0.73 - 0s 8ms/step - loss: 0.5901 - accuracy: 0.7430 - val_loss: 0.3805 - val_accuracy: 0.8560\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2242 - accuracy: 0.75 - ETA: 0s - loss: 0.5473 - accuracy: 0.79 - 0s 7ms/step - loss: 0.5301 - accuracy: 0.7948 - val_loss: 0.3738 - val_accuracy: 0.8320\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.75 - ETA: 0s - loss: 0.5355 - accuracy: 0.78 - 0s 7ms/step - loss: 0.5420 - accuracy: 0.7809 - val_loss: 0.3727 - val_accuracy: 0.8640\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.84 - ETA: 0s - loss: 0.5551 - accuracy: 0.76 - 0s 7ms/step - loss: 0.5842 - accuracy: 0.7649 - val_loss: 0.3856 - val_accuracy: 0.8320\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5996 - accuracy: 0.62 - ETA: 0s - loss: 0.5625 - accuracy: 0.74 - 0s 7ms/step - loss: 0.5616 - accuracy: 0.7510 - val_loss: 0.3635 - val_accuracy: 0.8480\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5594 - accuracy: 0.7669 - val_loss: 0.3897 - val_accuracy: 0.8480\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4586 - accuracy: 0.84 - 0s 4ms/step - loss: 0.5842 - accuracy: 0.7769 - val_loss: 0.3535 - val_accuracy: 0.8720\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.75 - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7888 - val_loss: 0.3688 - val_accuracy: 0.8480\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0292 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5626 - accuracy: 0.7629 - val_loss: 0.3753 - val_accuracy: 0.8320\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8464 - accuracy: 0.71 - ETA: 0s - loss: 0.5631 - accuracy: 0.79 - 0s 7ms/step - loss: 0.5522 - accuracy: 0.8008 - val_loss: 0.3590 - val_accuracy: 0.8640\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6858 - accuracy: 0.71 - ETA: 0s - loss: 0.5521 - accuracy: 0.77 - 0s 6ms/step - loss: 0.5431 - accuracy: 0.7749 - val_loss: 0.3735 - val_accuracy: 0.8320\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7514 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5885 - accuracy: 0.7490 - val_loss: 0.3601 - val_accuracy: 0.8560\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.78 - ETA: 0s - loss: 0.5310 - accuracy: 0.77 - 0s 6ms/step - loss: 0.5282 - accuracy: 0.7789 - val_loss: 0.3725 - val_accuracy: 0.8480\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6256 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7789 - val_loss: 0.3973 - val_accuracy: 0.8240\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7605 - accuracy: 0.75 - ETA: 0s - loss: 0.5272 - accuracy: 0.76 - 0s 7ms/step - loss: 0.5529 - accuracy: 0.7709 - val_loss: 0.3564 - val_accuracy: 0.8720\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.71 - ETA: 0s - loss: 0.5370 - accuracy: 0.78 - 0s 8ms/step - loss: 0.5161 - accuracy: 0.7928 - val_loss: 0.3674 - val_accuracy: 0.8640\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7968 - val_loss: 0.3745 - val_accuracy: 0.8480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: a7a7e30357d7ebe989f49a64d15fb861</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8799999952316284</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 17s - loss: 0.7460 - accuracy: 0.500 - ETA: 0s - loss: 0.7454 - accuracy: 0.604 - 2s 99ms/step - loss: 0.7319 - accuracy: 0.6076 - val_loss: 0.5892 - val_accuracy: 0.7280\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9232 - accuracy: 0.43 - ETA: 0s - loss: 0.7404 - accuracy: 0.62 - 0s 6ms/step - loss: 0.7432 - accuracy: 0.6215 - val_loss: 0.6092 - val_accuracy: 0.7120\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8136 - accuracy: 0.56 - 0s 4ms/step - loss: 0.7723 - accuracy: 0.6076 - val_loss: 0.5948 - val_accuracy: 0.7200\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8005 - accuracy: 0.50 - 0s 4ms/step - loss: 0.7479 - accuracy: 0.6076 - val_loss: 0.5983 - val_accuracy: 0.7120\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8583 - accuracy: 0.43 - 0s 4ms/step - loss: 0.7177 - accuracy: 0.6175 - val_loss: 0.6035 - val_accuracy: 0.7200\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8516 - accuracy: 0.46 - ETA: 0s - loss: 0.6609 - accuracy: 0.64 - 0s 7ms/step - loss: 0.6762 - accuracy: 0.6414 - val_loss: 0.5963 - val_accuracy: 0.7280\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8636 - accuracy: 0.43 - ETA: 0s - loss: 0.7581 - accuracy: 0.60 - 0s 18ms/step - loss: 0.7374 - accuracy: 0.6275 - val_loss: 0.5858 - val_accuracy: 0.7600\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7627 - accuracy: 0.46 - ETA: 0s - loss: 0.7318 - accuracy: 0.59 - 0s 8ms/step - loss: 0.7216 - accuracy: 0.6195 - val_loss: 0.5758 - val_accuracy: 0.7520\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7538 - accuracy: 0.68 - ETA: 0s - loss: 0.7359 - accuracy: 0.61 - 0s 7ms/step - loss: 0.7223 - accuracy: 0.6255 - val_loss: 0.5703 - val_accuracy: 0.7280\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7802 - accuracy: 0.56 - ETA: 0s - loss: 0.6821 - accuracy: 0.63 - 0s 7ms/step - loss: 0.6802 - accuracy: 0.6355 - val_loss: 0.5623 - val_accuracy: 0.7520\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.71 - 0s 6ms/step - loss: 0.6866 - accuracy: 0.6594 - val_loss: 0.5610 - val_accuracy: 0.7440\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7582 - accuracy: 0.59 - 0s 6ms/step - loss: 0.6831 - accuracy: 0.6494 - val_loss: 0.5506 - val_accuracy: 0.7600\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6687 - accuracy: 0.59 - ETA: 0s - loss: 0.6909 - accuracy: 0.63 - 0s 8ms/step - loss: 0.6743 - accuracy: 0.6614 - val_loss: 0.5261 - val_accuracy: 0.7600\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8038 - accuracy: 0.65 - ETA: 0s - loss: 0.6787 - accuracy: 0.65 - 0s 6ms/step - loss: 0.6752 - accuracy: 0.6574 - val_loss: 0.5390 - val_accuracy: 0.7600\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7819 - accuracy: 0.62 - ETA: 0s - loss: 0.6318 - accuracy: 0.66 - 0s 17ms/step - loss: 0.6295 - accuracy: 0.6633 - val_loss: 0.5166 - val_accuracy: 0.7840\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7405 - accuracy: 0.59 - ETA: 0s - loss: 0.6825 - accuracy: 0.65 - 0s 7ms/step - loss: 0.6696 - accuracy: 0.6693 - val_loss: 0.5254 - val_accuracy: 0.7840\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8555 - accuracy: 0.50 - 0s 4ms/step - loss: 0.6631 - accuracy: 0.6315 - val_loss: 0.5224 - val_accuracy: 0.7680\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7878 - accuracy: 0.62 - 0s 14ms/step - loss: 0.6494 - accuracy: 0.6534 - val_loss: 0.5289 - val_accuracy: 0.7920\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8808 - accuracy: 0.53 - ETA: 0s - loss: 0.6956 - accuracy: 0.63 - 0s 7ms/step - loss: 0.6655 - accuracy: 0.6494 - val_loss: 0.5237 - val_accuracy: 0.7920\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7547 - accuracy: 0.56 - ETA: 0s - loss: 0.6213 - accuracy: 0.67 - 0s 8ms/step - loss: 0.6400 - accuracy: 0.6733 - val_loss: 0.5256 - val_accuracy: 0.7920\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7870 - accuracy: 0.53 - 0s 5ms/step - loss: 0.5989 - accuracy: 0.7012 - val_loss: 0.5033 - val_accuracy: 0.7920\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5557 - accuracy: 0.75 - ETA: 0s - loss: 0.6238 - accuracy: 0.67 - 0s 6ms/step - loss: 0.6230 - accuracy: 0.6713 - val_loss: 0.4821 - val_accuracy: 0.7840\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.68 - ETA: 0s - loss: 0.6233 - accuracy: 0.67 - 0s 7ms/step - loss: 0.6176 - accuracy: 0.6793 - val_loss: 0.4654 - val_accuracy: 0.7840\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.59 - 0s 13ms/step - loss: 0.6578 - accuracy: 0.6554 - val_loss: 0.4570 - val_accuracy: 0.8080\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6329 - accuracy: 0.62 - ETA: 0s - loss: 0.6056 - accuracy: 0.69 - 0s 7ms/step - loss: 0.5949 - accuracy: 0.6992 - val_loss: 0.4978 - val_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8433 - accuracy: 0.62 - ETA: 0s - loss: 0.6491 - accuracy: 0.66 - 0s 7ms/step - loss: 0.6345 - accuracy: 0.6713 - val_loss: 0.5180 - val_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.62 - ETA: 0s - loss: 0.6039 - accuracy: 0.69 - 0s 6ms/step - loss: 0.6019 - accuracy: 0.6952 - val_loss: 0.4998 - val_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5627 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5849 - accuracy: 0.6653 - val_loss: 0.5083 - val_accuracy: 0.8080\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.71 - ETA: 0s - loss: 0.5978 - accuracy: 0.66 - 0s 18ms/step - loss: 0.5865 - accuracy: 0.6793 - val_loss: 0.4772 - val_accuracy: 0.8240\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8387 - accuracy: 0.56 - ETA: 0s - loss: 0.6106 - accuracy: 0.68 - ETA: 0s - loss: 0.6039 - accuracy: 0.70 - 0s 23ms/step - loss: 0.5904 - accuracy: 0.7072 - val_loss: 0.4604 - val_accuracy: 0.8400\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.71 - ETA: 0s - loss: 0.5982 - accuracy: 0.69 - 0s 8ms/step - loss: 0.5911 - accuracy: 0.7032 - val_loss: 0.4845 - val_accuracy: 0.8080\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8204 - accuracy: 0.65 - ETA: 0s - loss: 0.6126 - accuracy: 0.67 - 0s 8ms/step - loss: 0.6235 - accuracy: 0.6932 - val_loss: 0.4598 - val_accuracy: 0.8400\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.65 - ETA: 0s - loss: 0.6130 - accuracy: 0.68 - 0s 7ms/step - loss: 0.5998 - accuracy: 0.6873 - val_loss: 0.4587 - val_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8658 - accuracy: 0.59 - ETA: 0s - loss: 0.6279 - accuracy: 0.68 - 0s 7ms/step - loss: 0.6153 - accuracy: 0.6912 - val_loss: 0.4567 - val_accuracy: 0.8080\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7954 - accuracy: 0.65 - ETA: 0s - loss: 0.6220 - accuracy: 0.69 - 0s 6ms/step - loss: 0.6210 - accuracy: 0.6932 - val_loss: 0.4769 - val_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5964 - accuracy: 0.7072 - val_loss: 0.4702 - val_accuracy: 0.8080\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5760 - accuracy: 0.7131 - val_loss: 0.4595 - val_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.56 - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7131 - val_loss: 0.4343 - val_accuracy: 0.8080\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7191 - val_loss: 0.4173 - val_accuracy: 0.8320\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9073 - accuracy: 0.46 - 0s 14ms/step - loss: 0.5809 - accuracy: 0.7092 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.68 - ETA: 0s - loss: 0.5773 - accuracy: 0.71 - 0s 8ms/step - loss: 0.5768 - accuracy: 0.7072 - val_loss: 0.4226 - val_accuracy: 0.8400\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6621 - accuracy: 0.78 - ETA: 0s - loss: 0.5795 - accuracy: 0.75 - 0s 7ms/step - loss: 0.5886 - accuracy: 0.7450 - val_loss: 0.4368 - val_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8343 - accuracy: 0.53 - ETA: 0s - loss: 0.6238 - accuracy: 0.67 - 0s 6ms/step - loss: 0.6157 - accuracy: 0.6773 - val_loss: 0.4485 - val_accuracy: 0.7920\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6438 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5623 - accuracy: 0.7351 - val_loss: 0.4149 - val_accuracy: 0.8160\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6537 - accuracy: 0.59 - 0s 6ms/step - loss: 0.5647 - accuracy: 0.6972 - val_loss: 0.3949 - val_accuracy: 0.8240\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7138 - accuracy: 0.68 - ETA: 0s - loss: 0.5849 - accuracy: 0.69 - 0s 8ms/step - loss: 0.5925 - accuracy: 0.7092 - val_loss: 0.4101 - val_accuracy: 0.8320\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7677 - accuracy: 0.59 - ETA: 0s - loss: 0.5726 - accuracy: 0.71 - 0s 8ms/step - loss: 0.5746 - accuracy: 0.7151 - val_loss: 0.4503 - val_accuracy: 0.8160\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7470 - val_loss: 0.4621 - val_accuracy: 0.7840\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6509 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7450 - val_loss: 0.4434 - val_accuracy: 0.7840\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7594 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7271 - val_loss: 0.4421 - val_accuracy: 0.8080\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7193 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7351 - val_loss: 0.4255 - val_accuracy: 0.8160\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7592 - accuracy: 0.56 - ETA: 0s - loss: 0.5773 - accuracy: 0.71 - 0s 8ms/step - loss: 0.5618 - accuracy: 0.7291 - val_loss: 0.4411 - val_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6343 - accuracy: 0.62 - ETA: 0s - loss: 0.5624 - accuracy: 0.69 - 0s 8ms/step - loss: 0.5649 - accuracy: 0.6952 - val_loss: 0.4412 - val_accuracy: 0.8160\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5531 - accuracy: 0.7131 - val_loss: 0.4330 - val_accuracy: 0.8160\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7231 - accuracy: 0.56 - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7032 - val_loss: 0.4225 - val_accuracy: 0.8080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: ad76739854d0f7c2e7d1742bbb959121</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8479999899864197</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 9s - loss: 0.9798 - accuracy: 0.56 - 1s 60ms/step - loss: 1.5889 - accuracy: 0.5797 - val_loss: 0.7977 - val_accuracy: 0.7040\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.8266 - accuracy: 0.50 - 0s 11ms/step - loss: 1.3364 - accuracy: 0.5817 - val_loss: 0.5531 - val_accuracy: 0.7360\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.0889 - accuracy: 0.43 - 0s 4ms/step - loss: 1.4593 - accuracy: 0.5936 - val_loss: 0.5873 - val_accuracy: 0.7360\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0174 - accuracy: 0.53 - 0s 11ms/step - loss: 1.2430 - accuracy: 0.5996 - val_loss: 0.5477 - val_accuracy: 0.7440\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1907 - accuracy: 0.65 - ETA: 0s - loss: 1.1092 - accuracy: 0.64 - 0s 7ms/step - loss: 1.0630 - accuracy: 0.6454 - val_loss: 0.4679 - val_accuracy: 0.7440\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3038 - accuracy: 0.56 - ETA: 0s - loss: 1.0501 - accuracy: 0.64 - 0s 15ms/step - loss: 1.0404 - accuracy: 0.6474 - val_loss: 0.5775 - val_accuracy: 0.7520\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5135 - accuracy: 0.43 - ETA: 0s - loss: 1.0278 - accuracy: 0.62 - 0s 16ms/step - loss: 0.9837 - accuracy: 0.6375 - val_loss: 0.4447 - val_accuracy: 0.7840\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0065 - accuracy: 0.65 - ETA: 0s - loss: 0.9349 - accuracy: 0.65 - 0s 6ms/step - loss: 0.9549 - accuracy: 0.6434 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6882 - accuracy: 0.65 - 0s 7ms/step - loss: 0.8723 - accuracy: 0.6972 - val_loss: 0.5271 - val_accuracy: 0.7680\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8494 - accuracy: 0.46 - ETA: 0s - loss: 0.9659 - accuracy: 0.63 - 0s 6ms/step - loss: 0.9506 - accuracy: 0.6434 - val_loss: 0.4342 - val_accuracy: 0.7760\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3073 - accuracy: 0.62 - 0s 11ms/step - loss: 0.8487 - accuracy: 0.6912 - val_loss: 0.4945 - val_accuracy: 0.7920\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7470 - accuracy: 0.62 - ETA: 0s - loss: 0.8171 - accuracy: 0.67 - 0s 16ms/step - loss: 0.7957 - accuracy: 0.6833 - val_loss: 0.4487 - val_accuracy: 0.8080\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7667 - accuracy: 0.62 - ETA: 0s - loss: 0.7918 - accuracy: 0.70 - 0s 6ms/step - loss: 0.7788 - accuracy: 0.7052 - val_loss: 0.4712 - val_accuracy: 0.7920\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7505 - accuracy: 0.59 - 0s 12ms/step - loss: 0.7594 - accuracy: 0.6873 - val_loss: 0.4053 - val_accuracy: 0.8240\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.71 - 0s 5ms/step - loss: 0.7080 - accuracy: 0.6873 - val_loss: 0.4524 - val_accuracy: 0.7920\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8891 - accuracy: 0.65 - 0s 6ms/step - loss: 0.7617 - accuracy: 0.6992 - val_loss: 0.4158 - val_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2227 - accuracy: 0.59 - 0s 7ms/step - loss: 0.7762 - accuracy: 0.6892 - val_loss: 0.4469 - val_accuracy: 0.8080\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0457 - accuracy: 0.62 - 0s 6ms/step - loss: 0.7689 - accuracy: 0.6972 - val_loss: 0.4181 - val_accuracy: 0.8240\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2015 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7191 - val_loss: 0.4043 - val_accuracy: 0.8080\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.65 - 0s 12ms/step - loss: 0.7108 - accuracy: 0.7231 - val_loss: 0.4007 - val_accuracy: 0.8400\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7480 - accuracy: 0.71 - 0s 16ms/step - loss: 0.6376 - accuracy: 0.7331 - val_loss: 0.3886 - val_accuracy: 0.8640\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.75 - 0s 6ms/step - loss: 0.6305 - accuracy: 0.7311 - val_loss: 0.3949 - val_accuracy: 0.8320\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7262 - accuracy: 0.78 - 0s 6ms/step - loss: 0.6037 - accuracy: 0.7610 - val_loss: 0.3861 - val_accuracy: 0.8160\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7510 - val_loss: 0.3742 - val_accuracy: 0.8640\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.62 - 0s 6ms/step - loss: 0.5800 - accuracy: 0.7570 - val_loss: 0.4097 - val_accuracy: 0.8160\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6248 - accuracy: 0.65 - ETA: 0s - loss: 0.6437 - accuracy: 0.72 - 0s 7ms/step - loss: 0.6373 - accuracy: 0.7291 - val_loss: 0.4069 - val_accuracy: 0.8080\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8364 - accuracy: 0.68 - ETA: 0s - loss: 0.6095 - accuracy: 0.72 - 0s 7ms/step - loss: 0.6055 - accuracy: 0.7271 - val_loss: 0.3926 - val_accuracy: 0.8320\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5926 - accuracy: 0.62 - 0s 15ms/step - loss: 0.5621 - accuracy: 0.7450 - val_loss: 0.3572 - val_accuracy: 0.8800\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7530 - accuracy: 0.75 - 0s 4ms/step - loss: 0.6117 - accuracy: 0.7371 - val_loss: 0.3996 - val_accuracy: 0.8320\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9348 - accuracy: 0.62 - 0s 4ms/step - loss: 0.6090 - accuracy: 0.7410 - val_loss: 0.3684 - val_accuracy: 0.8560\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.84 - 0s 4ms/step - loss: 0.5895 - accuracy: 0.7689 - val_loss: 0.3672 - val_accuracy: 0.8560\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5814 - accuracy: 0.7729 - val_loss: 0.3695 - val_accuracy: 0.8640\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5570 - accuracy: 0.7669 - val_loss: 0.3928 - val_accuracy: 0.8080\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6713 - accuracy: 0.75 - ETA: 0s - loss: 0.5434 - accuracy: 0.77 - 0s 6ms/step - loss: 0.5336 - accuracy: 0.7809 - val_loss: 0.4056 - val_accuracy: 0.8080\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8373 - accuracy: 0.65 - 0s 6ms/step - loss: 0.5482 - accuracy: 0.7450 - val_loss: 0.3779 - val_accuracy: 0.8400\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8036 - accuracy: 0.71 - 0s 5ms/step - loss: 0.6281 - accuracy: 0.7629 - val_loss: 0.3611 - val_accuracy: 0.8640\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7416 - accuracy: 0.75 - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7749 - val_loss: 0.3914 - val_accuracy: 0.8480\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8784 - accuracy: 0.68 - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7629 - val_loss: 0.3638 - val_accuracy: 0.8560\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 564e55f223a4401aa7adb21f6e3203fb</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8799999952316284</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 11s - loss: 1.0575 - accuracy: 0.375 - 1s 74ms/step - loss: 0.8011 - accuracy: 0.5916 - val_loss: 0.7006 - val_accuracy: 0.6240\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9699 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6511 - accuracy: 0.6554 - val_loss: 0.7825 - val_accuracy: 0.3600\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7477 - accuracy: 0.46 - 0s 13ms/step - loss: 0.6731 - accuracy: 0.6554 - val_loss: 0.6438 - val_accuracy: 0.6880\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.59 - ETA: 0s - loss: 0.6569 - accuracy: 0.69 - 0s 13ms/step - loss: 0.6559 - accuracy: 0.6912 - val_loss: 0.6048 - val_accuracy: 0.7440\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.50 - ETA: 0s - loss: 0.6082 - accuracy: 0.72 - 0s 17ms/step - loss: 0.5928 - accuracy: 0.7271 - val_loss: 0.5293 - val_accuracy: 0.7760\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5995 - accuracy: 0.68 - ETA: 0s - loss: 0.6273 - accuracy: 0.71 - 0s 8ms/step - loss: 0.6238 - accuracy: 0.7112 - val_loss: 0.5260 - val_accuracy: 0.7760\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.75 - ETA: 0s - loss: 0.5416 - accuracy: 0.74 - 0s 15ms/step - loss: 0.5435 - accuracy: 0.7430 - val_loss: 0.4565 - val_accuracy: 0.8160\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.78 - ETA: 0s - loss: 0.5683 - accuracy: 0.75 - 0s 15ms/step - loss: 0.5642 - accuracy: 0.7510 - val_loss: 0.4529 - val_accuracy: 0.8240\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5684 - accuracy: 0.65 - ETA: 0s - loss: 0.5803 - accuracy: 0.73 - 0s 7ms/step - loss: 0.5829 - accuracy: 0.7291 - val_loss: 0.4395 - val_accuracy: 0.8080\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5306 - accuracy: 0.68 - ETA: 0s - loss: 0.5601 - accuracy: 0.76 - 0s 7ms/step - loss: 0.5613 - accuracy: 0.7570 - val_loss: 0.4243 - val_accuracy: 0.8160\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5561 - accuracy: 0.71 - ETA: 0s - loss: 0.5532 - accuracy: 0.75 - 0s 7ms/step - loss: 0.5425 - accuracy: 0.7570 - val_loss: 0.4161 - val_accuracy: 0.8240\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6878 - accuracy: 0.68 - ETA: 0s - loss: 0.5124 - accuracy: 0.75 - 0s 16ms/step - loss: 0.5165 - accuracy: 0.7550 - val_loss: 0.4212 - val_accuracy: 0.8320\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7199 - accuracy: 0.71 - ETA: 0s - loss: 0.5488 - accuracy: 0.75 - 0s 8ms/step - loss: 0.5344 - accuracy: 0.7510 - val_loss: 0.4168 - val_accuracy: 0.8240\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6738 - accuracy: 0.75 - ETA: 0s - loss: 0.5056 - accuracy: 0.79 - 0s 7ms/step - loss: 0.5002 - accuracy: 0.7908 - val_loss: 0.4261 - val_accuracy: 0.8160\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.71 - ETA: 0s - loss: 0.5078 - accuracy: 0.76 - 0s 7ms/step - loss: 0.4994 - accuracy: 0.7729 - val_loss: 0.4233 - val_accuracy: 0.8240\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5009 - accuracy: 0.81 - ETA: 0s - loss: 0.5058 - accuracy: 0.77 - 0s 16ms/step - loss: 0.5078 - accuracy: 0.7649 - val_loss: 0.4018 - val_accuracy: 0.8400\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7842 - accuracy: 0.71 - ETA: 0s - loss: 0.5293 - accuracy: 0.77 - 0s 10ms/step - loss: 0.5279 - accuracy: 0.7590 - val_loss: 0.3955 - val_accuracy: 0.8240\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.75 - ETA: 0s - loss: 0.4919 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4917 - accuracy: 0.7689 - val_loss: 0.3983 - val_accuracy: 0.8160\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.71 - ETA: 0s - loss: 0.4996 - accuracy: 0.78 - 0s 7ms/step - loss: 0.5143 - accuracy: 0.7829 - val_loss: 0.3936 - val_accuracy: 0.8400\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.78 - ETA: 0s - loss: 0.4950 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4887 - accuracy: 0.7829 - val_loss: 0.3833 - val_accuracy: 0.8400\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6761 - accuracy: 0.62 - ETA: 0s - loss: 0.5332 - accuracy: 0.76 - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7729 - val_loss: 0.3819 - val_accuracy: 0.8320\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7948 - val_loss: 0.3867 - val_accuracy: 0.8400\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7629 - val_loss: 0.4006 - val_accuracy: 0.8080\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7809 - val_loss: 0.3896 - val_accuracy: 0.8160\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4930 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4830 - accuracy: 0.8028 - val_loss: 0.3886 - val_accuracy: 0.8240\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7928 - val_loss: 0.3897 - val_accuracy: 0.8240\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7845 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7749 - val_loss: 0.3883 - val_accuracy: 0.8160\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.78 - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7669 - val_loss: 0.4069 - val_accuracy: 0.8080\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7769 - val_loss: 0.3831 - val_accuracy: 0.8160\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.78 - ETA: 0s - loss: 0.4652 - accuracy: 0.79 - 0s 8ms/step - loss: 0.4795 - accuracy: 0.8008 - val_loss: 0.3995 - val_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.71 - ETA: 0s - loss: 0.4630 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4746 - accuracy: 0.7849 - val_loss: 0.3791 - val_accuracy: 0.8320\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.81 - ETA: 0s - loss: 0.4680 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4606 - accuracy: 0.7829 - val_loss: 0.4263 - val_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.78 - ETA: 0s - loss: 0.4464 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7988 - val_loss: 0.4138 - val_accuracy: 0.7920\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4616 - accuracy: 0.78 - ETA: 0s - loss: 0.4800 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4745 - accuracy: 0.7829 - val_loss: 0.3828 - val_accuracy: 0.8320\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.78 - 0s 12ms/step - loss: 0.5024 - accuracy: 0.7749 - val_loss: 0.3591 - val_accuracy: 0.8640\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.78 - ETA: 0s - loss: 0.5191 - accuracy: 0.78 - 0s 7ms/step - loss: 0.5072 - accuracy: 0.7849 - val_loss: 0.3923 - val_accuracy: 0.8160\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.71 - ETA: 0s - loss: 0.4963 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4922 - accuracy: 0.7928 - val_loss: 0.4187 - val_accuracy: 0.8240\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4276 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4455 - accuracy: 0.8028 - val_loss: 0.4002 - val_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6055 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4904 - accuracy: 0.7809 - val_loss: 0.4002 - val_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7709 - val_loss: 0.4033 - val_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7829 - val_loss: 0.3937 - val_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4662 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4651 - accuracy: 0.8008 - val_loss: 0.3840 - val_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.75 - ETA: 0s - loss: 0.4712 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4602 - accuracy: 0.7908 - val_loss: 0.3774 - val_accuracy: 0.8080\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.78 - ETA: 0s - loss: 0.4883 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4815 - accuracy: 0.7869 - val_loss: 0.3686 - val_accuracy: 0.8400\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.62 - ETA: 0s - loss: 0.4850 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4733 - accuracy: 0.7849 - val_loss: 0.3959 - val_accuracy: 0.8320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 6012e5d6c93e14999456fe7d17d5c193</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8640000224113464</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 15s - loss: 0.7800 - accuracy: 0.593 - 2s 95ms/step - loss: 0.7235 - accuracy: 0.5199 - val_loss: 0.8674 - val_accuracy: 0.2960\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.50 - 0s 19ms/step - loss: 0.6740 - accuracy: 0.6394 - val_loss: 0.7180 - val_accuracy: 0.3360\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6755 - accuracy: 0.53 - 0s 20ms/step - loss: 0.6472 - accuracy: 0.6534 - val_loss: 0.6705 - val_accuracy: 0.6080\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.56 - 0s 16ms/step - loss: 0.6326 - accuracy: 0.6633 - val_loss: 0.6295 - val_accuracy: 0.6960\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.56 - 0s 12ms/step - loss: 0.6233 - accuracy: 0.6693 - val_loss: 0.6004 - val_accuracy: 0.7200\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.56 - 0s 13ms/step - loss: 0.6162 - accuracy: 0.6733 - val_loss: 0.5815 - val_accuracy: 0.7360\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6728 - accuracy: 0.56 - ETA: 0s - loss: 0.6210 - accuracy: 0.66 - 0s 7ms/step - loss: 0.6101 - accuracy: 0.6773 - val_loss: 0.5731 - val_accuracy: 0.7280\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6708 - accuracy: 0.59 - 0s 4ms/step - loss: 0.6057 - accuracy: 0.6853 - val_loss: 0.5703 - val_accuracy: 0.7360\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.59 - 0s 4ms/step - loss: 0.6010 - accuracy: 0.6992 - val_loss: 0.5697 - val_accuracy: 0.7200\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6634 - accuracy: 0.59 - ETA: 0s - loss: 0.6067 - accuracy: 0.69 - 0s 6ms/step - loss: 0.5961 - accuracy: 0.7012 - val_loss: 0.5696 - val_accuracy: 0.7200\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6607 - accuracy: 0.56 - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7131 - val_loss: 0.5690 - val_accuracy: 0.7280\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6550 - accuracy: 0.56 - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7191 - val_loss: 0.5652 - val_accuracy: 0.7360\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.56 - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7151 - val_loss: 0.5620 - val_accuracy: 0.7200\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6488 - accuracy: 0.56 - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7191 - val_loss: 0.5604 - val_accuracy: 0.7280\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.56 - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7211 - val_loss: 0.5582 - val_accuracy: 0.7120\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6404 - accuracy: 0.56 - 0s 12ms/step - loss: 0.5591 - accuracy: 0.7211 - val_loss: 0.5560 - val_accuracy: 0.7440\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.59 - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7231 - val_loss: 0.5544 - val_accuracy: 0.7360\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.62 - 0s 6ms/step - loss: 0.5416 - accuracy: 0.7271 - val_loss: 0.5520 - val_accuracy: 0.7360\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.59 - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7231 - val_loss: 0.5511 - val_accuracy: 0.7280\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5917 - accuracy: 0.59 - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7430 - val_loss: 0.5513 - val_accuracy: 0.7280\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5930 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7510 - val_loss: 0.5595 - val_accuracy: 0.7120\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.62 - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7689 - val_loss: 0.5662 - val_accuracy: 0.7280\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.62 - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7550 - val_loss: 0.5712 - val_accuracy: 0.7280\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7809 - val_loss: 0.5650 - val_accuracy: 0.7280\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7829 - val_loss: 0.5720 - val_accuracy: 0.6880\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7908 - val_loss: 0.5772 - val_accuracy: 0.6640\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7948 - val_loss: 0.5815 - val_accuracy: 0.6560\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4482 - accuracy: 0.8108 - val_loss: 0.5823 - val_accuracy: 0.6720\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4981 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8048 - val_loss: 0.5987 - val_accuracy: 0.6640\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 4fab9f5a338081cacc85c284fdefaae3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7440000176429749</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 18s - loss: 0.8866 - accuracy: 0.468 - ETA: 0s - loss: 0.8585 - accuracy: 0.570 - 2s 100ms/step - loss: 0.8419 - accuracy: 0.5717 - val_loss: 0.6259 - val_accuracy: 0.7040\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.56 - ETA: 0s - loss: 0.7325 - accuracy: 0.64 - 0s 6ms/step - loss: 0.7343 - accuracy: 0.6355 - val_loss: 0.6672 - val_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7374 - accuracy: 0.65 - 0s 5ms/step - loss: 0.7358 - accuracy: 0.6215 - val_loss: 0.6594 - val_accuracy: 0.6720\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7065 - accuracy: 0.56 - 0s 12ms/step - loss: 0.7067 - accuracy: 0.6414 - val_loss: 0.6478 - val_accuracy: 0.7520\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8203 - accuracy: 0.56 - ETA: 0s - loss: 0.6990 - accuracy: 0.63 - 0s 9ms/step - loss: 0.6854 - accuracy: 0.6355 - val_loss: 0.6328 - val_accuracy: 0.7200\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8254 - accuracy: 0.59 - ETA: 0s - loss: 0.7214 - accuracy: 0.64 - 0s 8ms/step - loss: 0.7292 - accuracy: 0.6434 - val_loss: 0.6320 - val_accuracy: 0.7520\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8334 - accuracy: 0.56 - ETA: 0s - loss: 0.7675 - accuracy: 0.60 - 0s 8ms/step - loss: 0.7360 - accuracy: 0.6275 - val_loss: 0.6074 - val_accuracy: 0.7280\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8306 - accuracy: 0.53 - ETA: 0s - loss: 0.7500 - accuracy: 0.61 - 0s 8ms/step - loss: 0.7157 - accuracy: 0.6315 - val_loss: 0.5897 - val_accuracy: 0.7200\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.56 - ETA: 0s - loss: 0.6806 - accuracy: 0.60 - 0s 7ms/step - loss: 0.6700 - accuracy: 0.6275 - val_loss: 0.6010 - val_accuracy: 0.7280\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8042 - accuracy: 0.65 - ETA: 0s - loss: 0.6879 - accuracy: 0.66 - 0s 15ms/step - loss: 0.6597 - accuracy: 0.6813 - val_loss: 0.5782 - val_accuracy: 0.7600\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8966 - accuracy: 0.59 - ETA: 0s - loss: 0.6605 - accuracy: 0.66 - 0s 8ms/step - loss: 0.6734 - accuracy: 0.6673 - val_loss: 0.5775 - val_accuracy: 0.7600\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8273 - accuracy: 0.53 - ETA: 0s - loss: 0.6567 - accuracy: 0.66 - 0s 14ms/step - loss: 0.6568 - accuracy: 0.6653 - val_loss: 0.5618 - val_accuracy: 0.7680\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6833 - accuracy: 0.62 - ETA: 0s - loss: 0.6775 - accuracy: 0.63 - 0s 9ms/step - loss: 0.6625 - accuracy: 0.6414 - val_loss: 0.5692 - val_accuracy: 0.7360\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.65 - ETA: 0s - loss: 0.6391 - accuracy: 0.68 - 0s 9ms/step - loss: 0.6434 - accuracy: 0.6713 - val_loss: 0.5328 - val_accuracy: 0.7440\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.62 - ETA: 0s - loss: 0.6926 - accuracy: 0.65 - 0s 17ms/step - loss: 0.6654 - accuracy: 0.6653 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5975 - accuracy: 0.62 - ETA: 0s - loss: 0.6697 - accuracy: 0.62 - 0s 9ms/step - loss: 0.6634 - accuracy: 0.6434 - val_loss: 0.5087 - val_accuracy: 0.7680\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7729 - accuracy: 0.56 - 0s 12ms/step - loss: 0.6717 - accuracy: 0.6594 - val_loss: 0.5256 - val_accuracy: 0.7840\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.56 - ETA: 0s - loss: 0.6123 - accuracy: 0.68 - 0s 8ms/step - loss: 0.6284 - accuracy: 0.6773 - val_loss: 0.5001 - val_accuracy: 0.7680\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7727 - accuracy: 0.56 - 0s 6ms/step - loss: 0.6652 - accuracy: 0.6673 - val_loss: 0.5287 - val_accuracy: 0.7840\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.65 - ETA: 0s - loss: 0.6981 - accuracy: 0.65 - 0s 8ms/step - loss: 0.6436 - accuracy: 0.6713 - val_loss: 0.5138 - val_accuracy: 0.7680\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8724 - accuracy: 0.65 - ETA: 0s - loss: 0.6662 - accuracy: 0.67 - 0s 8ms/step - loss: 0.6335 - accuracy: 0.6892 - val_loss: 0.4956 - val_accuracy: 0.7840\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6453 - accuracy: 0.71 - ETA: 0s - loss: 0.6449 - accuracy: 0.67 - 0s 8ms/step - loss: 0.6536 - accuracy: 0.6514 - val_loss: 0.5111 - val_accuracy: 0.7840\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6119 - accuracy: 0.65 - ETA: 0s - loss: 0.6184 - accuracy: 0.69 - 0s 16ms/step - loss: 0.6125 - accuracy: 0.6952 - val_loss: 0.5040 - val_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6189 - accuracy: 0.68 - ETA: 0s - loss: 0.6959 - accuracy: 0.65 - 0s 8ms/step - loss: 0.6823 - accuracy: 0.6594 - val_loss: 0.4983 - val_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8726 - accuracy: 0.53 - ETA: 0s - loss: 0.6223 - accuracy: 0.68 - 0s 7ms/step - loss: 0.6126 - accuracy: 0.7032 - val_loss: 0.4804 - val_accuracy: 0.7920\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6838 - accuracy: 0.62 - ETA: 0s - loss: 0.6217 - accuracy: 0.69 - 0s 17ms/step - loss: 0.6165 - accuracy: 0.6972 - val_loss: 0.4588 - val_accuracy: 0.8160\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.62 - ETA: 0s - loss: 0.6026 - accuracy: 0.70 - 0s 8ms/step - loss: 0.5918 - accuracy: 0.7112 - val_loss: 0.4527 - val_accuracy: 0.7920\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6448 - accuracy: 0.56 - ETA: 0s - loss: 0.6052 - accuracy: 0.69 - 0s 8ms/step - loss: 0.5867 - accuracy: 0.7191 - val_loss: 0.4507 - val_accuracy: 0.8160\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.75 - ETA: 0s - loss: 0.6421 - accuracy: 0.70 - 0s 6ms/step - loss: 0.6121 - accuracy: 0.7191 - val_loss: 0.4470 - val_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.56 - ETA: 0s - loss: 0.5894 - accuracy: 0.72 - 0s 7ms/step - loss: 0.5619 - accuracy: 0.7351 - val_loss: 0.4413 - val_accuracy: 0.8080\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.65 - ETA: 0s - loss: 0.5612 - accuracy: 0.71 - 0s 8ms/step - loss: 0.5617 - accuracy: 0.7251 - val_loss: 0.4249 - val_accuracy: 0.8080\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7457 - accuracy: 0.59 - ETA: 0s - loss: 0.6085 - accuracy: 0.69 - 0s 13ms/step - loss: 0.5979 - accuracy: 0.6992 - val_loss: 0.4319 - val_accuracy: 0.8240\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6525 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7510 - val_loss: 0.4389 - val_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7112 - val_loss: 0.4234 - val_accuracy: 0.7840\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.59 - ETA: 0s - loss: 0.5555 - accuracy: 0.72 - 0s 6ms/step - loss: 0.5564 - accuracy: 0.7311 - val_loss: 0.4398 - val_accuracy: 0.7840\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.87 - ETA: 0s - loss: 0.5656 - accuracy: 0.74 - 0s 8ms/step - loss: 0.5417 - accuracy: 0.7450 - val_loss: 0.4410 - val_accuracy: 0.7840\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.71 - ETA: 0s - loss: 0.5823 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5775 - accuracy: 0.7072 - val_loss: 0.4358 - val_accuracy: 0.7840\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.62 - 0s 5ms/step - loss: 0.5621 - accuracy: 0.7371 - val_loss: 0.4368 - val_accuracy: 0.8080\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.71 - ETA: 0s - loss: 0.5530 - accuracy: 0.74 - 0s 7ms/step - loss: 0.5380 - accuracy: 0.7510 - val_loss: 0.4206 - val_accuracy: 0.7760\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6142 - accuracy: 0.68 - ETA: 0s - loss: 0.5469 - accuracy: 0.72 - 0s 7ms/step - loss: 0.5196 - accuracy: 0.7291 - val_loss: 0.4090 - val_accuracy: 0.8160\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7166 - accuracy: 0.56 - ETA: 0s - loss: 0.5779 - accuracy: 0.69 - 0s 8ms/step - loss: 0.5574 - accuracy: 0.7092 - val_loss: 0.4090 - val_accuracy: 0.8080\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.68 - ETA: 0s - loss: 0.5450 - accuracy: 0.72 - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7331 - val_loss: 0.4010 - val_accuracy: 0.8240\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.71 - ETA: 0s - loss: 0.5612 - accuracy: 0.74 - 0s 8ms/step - loss: 0.5670 - accuracy: 0.7371 - val_loss: 0.4063 - val_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5845 - accuracy: 0.62 - ETA: 0s - loss: 0.5952 - accuracy: 0.71 - 0s 8ms/step - loss: 0.5734 - accuracy: 0.7390 - val_loss: 0.4343 - val_accuracy: 0.7840\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5218 - accuracy: 0.68 - ETA: 0s - loss: 0.5577 - accuracy: 0.73 - 0s 7ms/step - loss: 0.5385 - accuracy: 0.7450 - val_loss: 0.4173 - val_accuracy: 0.7840\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.71 - ETA: 0s - loss: 0.6053 - accuracy: 0.70 - 0s 8ms/step - loss: 0.5654 - accuracy: 0.7231 - val_loss: 0.4036 - val_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.59 - ETA: 0s - loss: 0.5671 - accuracy: 0.72 - 0s 19ms/step - loss: 0.5313 - accuracy: 0.7470 - val_loss: 0.4084 - val_accuracy: 0.8400\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.71 - ETA: 0s - loss: 0.5427 - accuracy: 0.75 - ETA: 0s - loss: 0.5136 - accuracy: 0.77 - 0s 11ms/step - loss: 0.5079 - accuracy: 0.7769 - val_loss: 0.4034 - val_accuracy: 0.8240\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7371 - val_loss: 0.3894 - val_accuracy: 0.8320\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7734 - accuracy: 0.65 - ETA: 0s - loss: 0.5448 - accuracy: 0.76 - 0s 16ms/step - loss: 0.5375 - accuracy: 0.7649 - val_loss: 0.3824 - val_accuracy: 0.8560\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.71 - ETA: 0s - loss: 0.5537 - accuracy: 0.71 - ETA: 0s - loss: 0.5415 - accuracy: 0.73 - 0s 13ms/step - loss: 0.5192 - accuracy: 0.7390 - val_loss: 0.3890 - val_accuracy: 0.8480\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.68 - ETA: 0s - loss: 0.5399 - accuracy: 0.74 - 0s 9ms/step - loss: 0.5306 - accuracy: 0.7490 - val_loss: 0.3875 - val_accuracy: 0.8560\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.71 - 0s 15ms/step - loss: 0.5094 - accuracy: 0.7351 - val_loss: 0.3878 - val_accuracy: 0.8640\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5207 - accuracy: 0.68 - ETA: 0s - loss: 0.5309 - accuracy: 0.74 - 0s 8ms/step - loss: 0.5205 - accuracy: 0.7510 - val_loss: 0.3949 - val_accuracy: 0.8640\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.78 - ETA: 0s - loss: 0.5416 - accuracy: 0.74 - 0s 8ms/step - loss: 0.5160 - accuracy: 0.7550 - val_loss: 0.4063 - val_accuracy: 0.8080\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.75 - ETA: 0s - loss: 0.5444 - accuracy: 0.74 - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7430 - val_loss: 0.4076 - val_accuracy: 0.8320\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7789 - val_loss: 0.4105 - val_accuracy: 0.8240\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5560 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7550 - val_loss: 0.3916 - val_accuracy: 0.8160\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.78 - ETA: 0s - loss: 0.5320 - accuracy: 0.73 - 0s 7ms/step - loss: 0.5120 - accuracy: 0.7490 - val_loss: 0.3860 - val_accuracy: 0.8320\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5497 - accuracy: 0.68 - ETA: 0s - loss: 0.5154 - accuracy: 0.74 - 0s 8ms/step - loss: 0.5117 - accuracy: 0.7570 - val_loss: 0.3854 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: a0c16cb600601461ea7045b880ccac55</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8640000224113464</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 1024</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 10s - loss: 3.4060 - accuracy: 0.531 - 1s 66ms/step - loss: 2.0410 - accuracy: 0.5737 - val_loss: 0.6179 - val_accuracy: 0.7120\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.8108 - accuracy: 0.43 - 0s 11ms/step - loss: 1.6353 - accuracy: 0.5777 - val_loss: 0.5799 - val_accuracy: 0.7200\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 0.40 - 0s 12ms/step - loss: 1.8359 - accuracy: 0.5896 - val_loss: 0.5946 - val_accuracy: 0.7360\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7736 - accuracy: 0.56 - 0s 12ms/step - loss: 1.6580 - accuracy: 0.6355 - val_loss: 0.5057 - val_accuracy: 0.7440\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8121 - accuracy: 0.65 - 0s 5ms/step - loss: 1.2784 - accuracy: 0.6135 - val_loss: 0.5564 - val_accuracy: 0.7360\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1746 - accuracy: 0.56 - 0s 4ms/step - loss: 1.2952 - accuracy: 0.6155 - val_loss: 0.5061 - val_accuracy: 0.7360\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0791 - accuracy: 0.50 - 0s 11ms/step - loss: 1.1022 - accuracy: 0.6275 - val_loss: 0.4614 - val_accuracy: 0.7920\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7359 - accuracy: 0.68 - ETA: 0s - loss: 1.1500 - accuracy: 0.65 - 0s 7ms/step - loss: 1.1794 - accuracy: 0.6574 - val_loss: 0.4866 - val_accuracy: 0.7680\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1924 - accuracy: 0.59 - ETA: 0s - loss: 1.0523 - accuracy: 0.61 - 0s 7ms/step - loss: 1.0434 - accuracy: 0.6175 - val_loss: 0.4947 - val_accuracy: 0.7840\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.4502 - accuracy: 0.59 - ETA: 0s - loss: 1.0649 - accuracy: 0.65 - 0s 7ms/step - loss: 1.0619 - accuracy: 0.6554 - val_loss: 0.4785 - val_accuracy: 0.7840\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1778 - accuracy: 0.56 - ETA: 0s - loss: 0.9059 - accuracy: 0.65 - 0s 7ms/step - loss: 0.9264 - accuracy: 0.6554 - val_loss: 0.4254 - val_accuracy: 0.7840\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9628 - accuracy: 0.53 - ETA: 0s - loss: 0.9453 - accuracy: 0.67 - 0s 7ms/step - loss: 0.9279 - accuracy: 0.6813 - val_loss: 0.5128 - val_accuracy: 0.7680\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1636 - accuracy: 0.46 - 0s 13ms/step - loss: 1.0170 - accuracy: 0.6534 - val_loss: 0.4129 - val_accuracy: 0.8400\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6702 - accuracy: 0.56 - ETA: 0s - loss: 0.8601 - accuracy: 0.67 - 0s 7ms/step - loss: 0.8478 - accuracy: 0.6733 - val_loss: 0.4285 - val_accuracy: 0.8160\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7923 - accuracy: 0.62 - ETA: 0s - loss: 0.9480 - accuracy: 0.70 - 0s 7ms/step - loss: 0.9278 - accuracy: 0.7032 - val_loss: 0.4223 - val_accuracy: 0.8080\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0668 - accuracy: 0.59 - 0s 5ms/step - loss: 0.8812 - accuracy: 0.6813 - val_loss: 0.4144 - val_accuracy: 0.8160\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3196 - accuracy: 0.56 - ETA: 0s - loss: 0.8052 - accuracy: 0.67 - 0s 13ms/step - loss: 0.8188 - accuracy: 0.6733 - val_loss: 0.3923 - val_accuracy: 0.8880\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.65 - 0s 4ms/step - loss: 0.7217 - accuracy: 0.7092 - val_loss: 0.4372 - val_accuracy: 0.8160\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1279 - accuracy: 0.78 - ETA: 0s - loss: 0.7535 - accuracy: 0.72 - 0s 7ms/step - loss: 0.7777 - accuracy: 0.7211 - val_loss: 0.4436 - val_accuracy: 0.7920\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8606 - accuracy: 0.59 - 0s 4ms/step - loss: 0.7331 - accuracy: 0.7211 - val_loss: 0.3962 - val_accuracy: 0.8240\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3187 - accuracy: 0.59 - 0s 4ms/step - loss: 0.7281 - accuracy: 0.7251 - val_loss: 0.4165 - val_accuracy: 0.8080\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6493 - accuracy: 0.68 - 0s 4ms/step - loss: 0.6849 - accuracy: 0.7271 - val_loss: 0.4046 - val_accuracy: 0.8080\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9265 - accuracy: 0.68 - 0s 4ms/step - loss: 0.6847 - accuracy: 0.7231 - val_loss: 0.4057 - val_accuracy: 0.8160\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6068 - accuracy: 0.71 - 0s 5ms/step - loss: 0.6459 - accuracy: 0.7490 - val_loss: 0.3810 - val_accuracy: 0.8480\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.68 - ETA: 0s - loss: 0.6402 - accuracy: 0.71 - 0s 7ms/step - loss: 0.6511 - accuracy: 0.7112 - val_loss: 0.3890 - val_accuracy: 0.8720\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.71 - ETA: 0s - loss: 0.6127 - accuracy: 0.74 - 0s 7ms/step - loss: 0.6018 - accuracy: 0.7470 - val_loss: 0.3747 - val_accuracy: 0.8720\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7233 - accuracy: 0.71 - 0s 4ms/step - loss: 0.6560 - accuracy: 0.7171 - val_loss: 0.4042 - val_accuracy: 0.8080\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8892 - accuracy: 0.75 - ETA: 0s - loss: 0.6840 - accuracy: 0.73 - 0s 6ms/step - loss: 0.6592 - accuracy: 0.7450 - val_loss: 0.3839 - val_accuracy: 0.8400\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.65 - 0s 6ms/step - loss: 0.5972 - accuracy: 0.7490 - val_loss: 0.3987 - val_accuracy: 0.8080\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.68 - 0s 6ms/step - loss: 0.6712 - accuracy: 0.7251 - val_loss: 0.3762 - val_accuracy: 0.8640\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.59 - 0s 5ms/step - loss: 0.6807 - accuracy: 0.7251 - val_loss: 0.3865 - val_accuracy: 0.8560\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.81 - 0s 5ms/step - loss: 0.6228 - accuracy: 0.7390 - val_loss: 0.3756 - val_accuracy: 0.8480\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5775 - accuracy: 0.7490 - val_loss: 0.3659 - val_accuracy: 0.8880\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8744 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5722 - accuracy: 0.7729 - val_loss: 0.3844 - val_accuracy: 0.8640\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5901 - accuracy: 0.7530 - val_loss: 0.3918 - val_accuracy: 0.8080\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8650 - accuracy: 0.65 - ETA: 0s - loss: 0.5623 - accuracy: 0.76 - 0s 7ms/step - loss: 0.5555 - accuracy: 0.7649 - val_loss: 0.3792 - val_accuracy: 0.8560\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5895 - accuracy: 0.68 - ETA: 0s - loss: 0.6111 - accuracy: 0.75 - 0s 7ms/step - loss: 0.5840 - accuracy: 0.7590 - val_loss: 0.3932 - val_accuracy: 0.8080\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.65 - ETA: 0s - loss: 0.6247 - accuracy: 0.75 - 0s 7ms/step - loss: 0.6064 - accuracy: 0.7550 - val_loss: 0.4047 - val_accuracy: 0.8160\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9381 - accuracy: 0.78 - ETA: 0s - loss: 0.6159 - accuracy: 0.75 - 0s 7ms/step - loss: 0.6687 - accuracy: 0.7490 - val_loss: 0.3861 - val_accuracy: 0.8640\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.78 - ETA: 0s - loss: 0.6520 - accuracy: 0.75 - 0s 6ms/step - loss: 0.6228 - accuracy: 0.7669 - val_loss: 0.3781 - val_accuracy: 0.8320\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5602 - accuracy: 0.7450 - val_loss: 0.3906 - val_accuracy: 0.8640\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5886 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7769 - val_loss: 0.3651 - val_accuracy: 0.8800\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9267 - accuracy: 0.75 - ETA: 0s - loss: 0.6352 - accuracy: 0.75 - 0s 7ms/step - loss: 0.5949 - accuracy: 0.7629 - val_loss: 0.3867 - val_accuracy: 0.8400\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7684 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5581 - accuracy: 0.7928 - val_loss: 0.3819 - val_accuracy: 0.8320\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9321 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5727 - accuracy: 0.7669 - val_loss: 0.3661 - val_accuracy: 0.8720\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9192 - accuracy: 0.75 - ETA: 0s - loss: 0.5647 - accuracy: 0.77 - 0s 7ms/step - loss: 0.5524 - accuracy: 0.7829 - val_loss: 0.3893 - val_accuracy: 0.8240\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.75 - ETA: 0s - loss: 0.5485 - accuracy: 0.77 - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7649 - val_loss: 0.3669 - val_accuracy: 0.8720\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7809 - val_loss: 0.3774 - val_accuracy: 0.8560\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7729 - val_loss: 0.3922 - val_accuracy: 0.8320\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.68 - ETA: 0s - loss: 0.5331 - accuracy: 0.76 - 0s 7ms/step - loss: 0.5319 - accuracy: 0.7649 - val_loss: 0.3634 - val_accuracy: 0.8720\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.84 - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7948 - val_loss: 0.3855 - val_accuracy: 0.8400\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8294 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5591 - accuracy: 0.7749 - val_loss: 0.3708 - val_accuracy: 0.8560\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7769 - val_loss: 0.3674 - val_accuracy: 0.8560\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5468 - accuracy: 0.8028 - val_loss: 0.3834 - val_accuracy: 0.8560\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.71 - ETA: 0s - loss: 0.5779 - accuracy: 0.76 - 0s 6ms/step - loss: 0.5653 - accuracy: 0.7629 - val_loss: 0.3620 - val_accuracy: 0.8800\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5963 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7769 - val_loss: 0.3888 - val_accuracy: 0.8480\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5178 - accuracy: 0.7809 - val_loss: 0.3672 - val_accuracy: 0.8640\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7078 - accuracy: 0.81 - ETA: 0s - loss: 0.4925 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4890 - accuracy: 0.7869 - val_loss: 0.3841 - val_accuracy: 0.8480\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.81 - ETA: 0s - loss: 0.4929 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4975 - accuracy: 0.7789 - val_loss: 0.3698 - val_accuracy: 0.8560\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4627 - accuracy: 0.75 - ETA: 0s - loss: 0.5296 - accuracy: 0.77 - 0s 8ms/step - loss: 0.5139 - accuracy: 0.7749 - val_loss: 0.3702 - val_accuracy: 0.8400\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7412 - accuracy: 0.75 - ETA: 0s - loss: 0.5332 - accuracy: 0.78 - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7869 - val_loss: 0.3736 - val_accuracy: 0.8560\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7789 - val_loss: 0.3694 - val_accuracy: 0.8640\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.78 - ETA: 0s - loss: 0.5461 - accuracy: 0.77 - 0s 6ms/step - loss: 0.5562 - accuracy: 0.7769 - val_loss: 0.3787 - val_accuracy: 0.8480\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.78 - ETA: 0s - loss: 0.4795 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4906 - accuracy: 0.7789 - val_loss: 0.3672 - val_accuracy: 0.8640\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6969 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7709 - val_loss: 0.3757 - val_accuracy: 0.8480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 924623a8b126abca3374323391a81936</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8880000114440918</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 10s - loss: 1.0594 - accuracy: 0.562 - 1s 64ms/step - loss: 1.1463 - accuracy: 0.5538 - val_loss: 0.7009 - val_accuracy: 0.6640\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0914 - accuracy: 0.53 - 0s 11ms/step - loss: 0.9470 - accuracy: 0.6016 - val_loss: 0.6256 - val_accuracy: 0.7360\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3097 - accuracy: 0.50 - 0s 4ms/step - loss: 0.9370 - accuracy: 0.5936 - val_loss: 0.5139 - val_accuracy: 0.7360\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8817 - accuracy: 0.62 - 0s 15ms/step - loss: 0.9470 - accuracy: 0.6016 - val_loss: 0.5715 - val_accuracy: 0.7440\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8827 - accuracy: 0.53 - 0s 4ms/step - loss: 0.9104 - accuracy: 0.6275 - val_loss: 0.5154 - val_accuracy: 0.7440\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9638 - accuracy: 0.56 - 0s 4ms/step - loss: 0.8310 - accuracy: 0.6474 - val_loss: 0.5637 - val_accuracy: 0.7360\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8599 - accuracy: 0.53 - 0s 5ms/step - loss: 0.8235 - accuracy: 0.5896 - val_loss: 0.5742 - val_accuracy: 0.7440\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4448 - accuracy: 0.50 - ETA: 0s - loss: 0.9000 - accuracy: 0.62 - 0s 15ms/step - loss: 0.8769 - accuracy: 0.6255 - val_loss: 0.4859 - val_accuracy: 0.7600\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9158 - accuracy: 0.46 - ETA: 0s - loss: 0.7419 - accuracy: 0.62 - 0s 7ms/step - loss: 0.7187 - accuracy: 0.6335 - val_loss: 0.5709 - val_accuracy: 0.7440\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9242 - accuracy: 0.50 - ETA: 0s - loss: 0.8050 - accuracy: 0.64 - 0s 7ms/step - loss: 0.7820 - accuracy: 0.6394 - val_loss: 0.5478 - val_accuracy: 0.7440\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8577 - accuracy: 0.59 - 0s 5ms/step - loss: 0.7806 - accuracy: 0.6474 - val_loss: 0.5217 - val_accuracy: 0.7280\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8335 - accuracy: 0.56 - ETA: 0s - loss: 0.7431 - accuracy: 0.64 - 0s 7ms/step - loss: 0.7480 - accuracy: 0.6554 - val_loss: 0.5343 - val_accuracy: 0.7440\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1188 - accuracy: 0.50 - ETA: 0s - loss: 0.8413 - accuracy: 0.60 - 0s 7ms/step - loss: 0.7943 - accuracy: 0.6215 - val_loss: 0.4781 - val_accuracy: 0.7600\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9962 - accuracy: 0.62 - ETA: 0s - loss: 0.6772 - accuracy: 0.67 - 0s 7ms/step - loss: 0.6669 - accuracy: 0.6773 - val_loss: 0.5011 - val_accuracy: 0.7520\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9351 - accuracy: 0.50 - ETA: 0s - loss: 0.7770 - accuracy: 0.59 - 0s 7ms/step - loss: 0.7627 - accuracy: 0.6056 - val_loss: 0.5120 - val_accuracy: 0.7440\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0226 - accuracy: 0.65 - ETA: 0s - loss: 0.7084 - accuracy: 0.64 - 0s 5ms/step - loss: 0.7123 - accuracy: 0.6434 - val_loss: 0.4822 - val_accuracy: 0.7520\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6470 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6853 - val_loss: 0.5080 - val_accuracy: 0.7520\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6753 - val_loss: 0.4755 - val_accuracy: 0.7360\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5977 - accuracy: 0.6793 - val_loss: 0.5002 - val_accuracy: 0.7600\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.62 - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6853 - val_loss: 0.4890 - val_accuracy: 0.7520\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7997 - accuracy: 0.59 - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6594 - val_loss: 0.5269 - val_accuracy: 0.7600\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6659 - accuracy: 0.56 - 0s 12ms/step - loss: 0.6470 - accuracy: 0.6693 - val_loss: 0.4701 - val_accuracy: 0.7760\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.50 - ETA: 0s - loss: 0.5958 - accuracy: 0.69 - 0s 16ms/step - loss: 0.6030 - accuracy: 0.6952 - val_loss: 0.4783 - val_accuracy: 0.7840\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8146 - accuracy: 0.50 - 0s 4ms/step - loss: 0.6125 - accuracy: 0.6713 - val_loss: 0.4696 - val_accuracy: 0.7840\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6368 - accuracy: 0.68 - 0s 13ms/step - loss: 0.6203 - accuracy: 0.6713 - val_loss: 0.4863 - val_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7298 - accuracy: 0.50 - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6813 - val_loss: 0.4773 - val_accuracy: 0.7840\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8412 - accuracy: 0.62 - 0s 12ms/step - loss: 0.6149 - accuracy: 0.7072 - val_loss: 0.4531 - val_accuracy: 0.8160\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6470 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7450 - val_loss: 0.4639 - val_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7112 - val_loss: 0.4898 - val_accuracy: 0.8080\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7431 - accuracy: 0.50 - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7092 - val_loss: 0.4767 - val_accuracy: 0.8080\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8173 - accuracy: 0.50 - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7072 - val_loss: 0.4517 - val_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7616 - accuracy: 0.53 - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7311 - val_loss: 0.4599 - val_accuracy: 0.8080\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7191 - val_loss: 0.4626 - val_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7278 - accuracy: 0.59 - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7052 - val_loss: 0.5015 - val_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8334 - accuracy: 0.59 - 0s 4ms/step - loss: 0.5667 - accuracy: 0.7191 - val_loss: 0.4520 - val_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6783 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7251 - val_loss: 0.4436 - val_accuracy: 0.8160\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7570 - val_loss: 0.4692 - val_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.56 - 0s 5ms/step - loss: 0.5519 - accuracy: 0.7371 - val_loss: 0.4400 - val_accuracy: 0.8080\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6744 - accuracy: 0.65 - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7590 - val_loss: 0.4600 - val_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6572 - accuracy: 0.78 - 0s 6ms/step - loss: 0.5528 - accuracy: 0.7311 - val_loss: 0.4596 - val_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6859 - accuracy: 0.59 - ETA: 0s - loss: 0.5463 - accuracy: 0.74 - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7390 - val_loss: 0.4518 - val_accuracy: 0.8080\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.68 - ETA: 0s - loss: 0.5106 - accuracy: 0.75 - 0s 7ms/step - loss: 0.5181 - accuracy: 0.7550 - val_loss: 0.4291 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7505 - accuracy: 0.65 - ETA: 0s - loss: 0.5453 - accuracy: 0.74 - 0s 14ms/step - loss: 0.5346 - accuracy: 0.7530 - val_loss: 0.4240 - val_accuracy: 0.8320\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5724 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7709 - val_loss: 0.4441 - val_accuracy: 0.8160\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5949 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7590 - val_loss: 0.4139 - val_accuracy: 0.8240\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7689 - val_loss: 0.4157 - val_accuracy: 0.8160\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.62 - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7809 - val_loss: 0.4214 - val_accuracy: 0.8160\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7709 - val_loss: 0.4243 - val_accuracy: 0.8160\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7829 - val_loss: 0.4357 - val_accuracy: 0.8160\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7809 - val_loss: 0.4373 - val_accuracy: 0.8080\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7948 - val_loss: 0.4410 - val_accuracy: 0.8160\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7829 - val_loss: 0.4155 - val_accuracy: 0.8240\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7729 - val_loss: 0.4197 - val_accuracy: 0.8240\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5914 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7829 - val_loss: 0.4263 - val_accuracy: 0.8240\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7869 - val_loss: 0.4083 - val_accuracy: 0.8240\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5118 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7629 - val_loss: 0.4046 - val_accuracy: 0.8240\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7749 - val_loss: 0.4316 - val_accuracy: 0.8240\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7809 - val_loss: 0.4200 - val_accuracy: 0.8080\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5928 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7869 - val_loss: 0.4337 - val_accuracy: 0.8160\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7968 - val_loss: 0.4313 - val_accuracy: 0.8240\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7689 - val_loss: 0.3990 - val_accuracy: 0.8320\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5220 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4640 - accuracy: 0.8088 - val_loss: 0.4093 - val_accuracy: 0.8320\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.75 - ETA: 0s - loss: 0.4681 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4566 - accuracy: 0.8028 - val_loss: 0.4202 - val_accuracy: 0.8320\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5786 - accuracy: 0.75 - ETA: 0s - loss: 0.4954 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4793 - accuracy: 0.7869 - val_loss: 0.4195 - val_accuracy: 0.8320\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6214 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7968 - val_loss: 0.4094 - val_accuracy: 0.8240\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.71 - 0s 13ms/step - loss: 0.4855 - accuracy: 0.7869 - val_loss: 0.3807 - val_accuracy: 0.8480\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4661 - accuracy: 0.8008 - val_loss: 0.4083 - val_accuracy: 0.8240\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.71 - ETA: 0s - loss: 0.4934 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4865 - accuracy: 0.7749 - val_loss: 0.4116 - val_accuracy: 0.8400\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.71 - ETA: 0s - loss: 0.4775 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4766 - accuracy: 0.7928 - val_loss: 0.4175 - val_accuracy: 0.8320\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7829 - val_loss: 0.3995 - val_accuracy: 0.8320\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5409 - accuracy: 0.75 - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7908 - val_loss: 0.4022 - val_accuracy: 0.8400\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7988 - val_loss: 0.3915 - val_accuracy: 0.8320\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7948 - val_loss: 0.4058 - val_accuracy: 0.8320\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5462 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7928 - val_loss: 0.4056 - val_accuracy: 0.8400\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.78 - ETA: 0s - loss: 0.4475 - accuracy: 0.81 - 0s 7ms/step - loss: 0.4428 - accuracy: 0.8187 - val_loss: 0.4033 - val_accuracy: 0.8240\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7829 - val_loss: 0.4117 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 2938e6c4d383962bd40d2f09a1debecb</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8479999899864197</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 22s - loss: 0.7031 - accuracy: 0.500 - ETA: 1s - loss: 0.8547 - accuracy: 0.576 - 2s 123ms/step - loss: 0.8447 - accuracy: 0.5737 - val_loss: 0.6723 - val_accuracy: 0.3360\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8497 - accuracy: 0.46 - ETA: 0s - loss: 0.8287 - accuracy: 0.56 - 0s 14ms/step - loss: 0.8212 - accuracy: 0.5777 - val_loss: 0.6480 - val_accuracy: 0.7360\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9673 - accuracy: 0.59 - ETA: 0s - loss: 0.8046 - accuracy: 0.57 - ETA: 0s - loss: 0.8315 - accuracy: 0.57 - 0s 11ms/step - loss: 0.8202 - accuracy: 0.5777 - val_loss: 0.6681 - val_accuracy: 0.6560\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8191 - accuracy: 0.53 - ETA: 0s - loss: 0.8735 - accuracy: 0.55 - ETA: 0s - loss: 0.8473 - accuracy: 0.55 - 0s 11ms/step - loss: 0.8305 - accuracy: 0.5558 - val_loss: 0.6502 - val_accuracy: 0.7200\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8811 - accuracy: 0.53 - ETA: 0s - loss: 0.8208 - accuracy: 0.56 - 0s 6ms/step - loss: 0.8098 - accuracy: 0.5757 - val_loss: 0.6447 - val_accuracy: 0.7120\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8006 - accuracy: 0.53 - ETA: 0s - loss: 0.8111 - accuracy: 0.57 - 0s 6ms/step - loss: 0.7885 - accuracy: 0.5777 - val_loss: 0.6442 - val_accuracy: 0.7280\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9055 - accuracy: 0.56 - ETA: 0s - loss: 0.7487 - accuracy: 0.57 - 0s 18ms/step - loss: 0.8004 - accuracy: 0.5797 - val_loss: 0.6255 - val_accuracy: 0.7440\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8066 - accuracy: 0.46 - ETA: 0s - loss: 0.8113 - accuracy: 0.58 - 0s 7ms/step - loss: 0.8132 - accuracy: 0.5697 - val_loss: 0.5980 - val_accuracy: 0.7360\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9221 - accuracy: 0.50 - ETA: 0s - loss: 0.7694 - accuracy: 0.59 - 0s 6ms/step - loss: 0.7768 - accuracy: 0.6076 - val_loss: 0.6101 - val_accuracy: 0.7280\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0071 - accuracy: 0.59 - ETA: 0s - loss: 0.8497 - accuracy: 0.54 - 0s 6ms/step - loss: 0.8028 - accuracy: 0.5538 - val_loss: 0.6163 - val_accuracy: 0.7120\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6797 - accuracy: 0.62 - ETA: 0s - loss: 0.7263 - accuracy: 0.61 - 0s 9ms/step - loss: 0.7131 - accuracy: 0.6255 - val_loss: 0.6029 - val_accuracy: 0.7200\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7368 - accuracy: 0.50 - ETA: 0s - loss: 0.7630 - accuracy: 0.61 - 0s 7ms/step - loss: 0.7320 - accuracy: 0.6534 - val_loss: 0.5817 - val_accuracy: 0.7360\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9196 - accuracy: 0.59 - ETA: 0s - loss: 0.7897 - accuracy: 0.59 - 0s 9ms/step - loss: 0.7799 - accuracy: 0.6155 - val_loss: 0.5963 - val_accuracy: 0.7280\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.56 - ETA: 0s - loss: 0.7454 - accuracy: 0.59 - 0s 9ms/step - loss: 0.7200 - accuracy: 0.6155 - val_loss: 0.5931 - val_accuracy: 0.7200\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.59 - ETA: 0s - loss: 0.7272 - accuracy: 0.62 - 0s 7ms/step - loss: 0.7384 - accuracy: 0.6335 - val_loss: 0.5642 - val_accuracy: 0.7360\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9479 - accuracy: 0.59 - ETA: 0s - loss: 0.7350 - accuracy: 0.59 - 0s 10ms/step - loss: 0.7263 - accuracy: 0.6155 - val_loss: 0.5523 - val_accuracy: 0.7360\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9514 - accuracy: 0.53 - ETA: 0s - loss: 0.7653 - accuracy: 0.61 - 0s 6ms/step - loss: 0.7453 - accuracy: 0.6116 - val_loss: 0.5725 - val_accuracy: 0.7440\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9284 - accuracy: 0.56 - ETA: 0s - loss: 0.6822 - accuracy: 0.63 - 0s 18ms/step - loss: 0.6931 - accuracy: 0.6394 - val_loss: 0.5379 - val_accuracy: 0.7680\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.62 - ETA: 0s - loss: 0.7069 - accuracy: 0.65 - 0s 9ms/step - loss: 0.7020 - accuracy: 0.6434 - val_loss: 0.5488 - val_accuracy: 0.7600\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8360 - accuracy: 0.50 - ETA: 0s - loss: 0.7446 - accuracy: 0.63 - 0s 8ms/step - loss: 0.7460 - accuracy: 0.6434 - val_loss: 0.5469 - val_accuracy: 0.7600\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9133 - accuracy: 0.43 - ETA: 0s - loss: 0.6800 - accuracy: 0.62 - 0s 7ms/step - loss: 0.6624 - accuracy: 0.6394 - val_loss: 0.5340 - val_accuracy: 0.7520\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8085 - accuracy: 0.59 - ETA: 0s - loss: 0.6663 - accuracy: 0.66 - 0s 6ms/step - loss: 0.6529 - accuracy: 0.6713 - val_loss: 0.5221 - val_accuracy: 0.7600\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9873 - accuracy: 0.53 - ETA: 0s - loss: 0.6981 - accuracy: 0.65 - 0s 20ms/step - loss: 0.6908 - accuracy: 0.6554 - val_loss: 0.5257 - val_accuracy: 0.8240\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7117 - accuracy: 0.62 - ETA: 0s - loss: 0.6533 - accuracy: 0.66 - ETA: 0s - loss: 0.6176 - accuracy: 0.67 - 0s 9ms/step - loss: 0.6094 - accuracy: 0.6833 - val_loss: 0.5319 - val_accuracy: 0.7920\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7282 - accuracy: 0.56 - ETA: 0s - loss: 0.6517 - accuracy: 0.67 - 0s 6ms/step - loss: 0.6175 - accuracy: 0.6952 - val_loss: 0.5106 - val_accuracy: 0.8240\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6973 - accuracy: 0.62 - ETA: 0s - loss: 0.6168 - accuracy: 0.69 - 0s 9ms/step - loss: 0.6126 - accuracy: 0.6833 - val_loss: 0.4873 - val_accuracy: 0.7920\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.62 - ETA: 0s - loss: 0.6159 - accuracy: 0.67 - 0s 10ms/step - loss: 0.6284 - accuracy: 0.6713 - val_loss: 0.4991 - val_accuracy: 0.8160\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.65 - ETA: 0s - loss: 0.6116 - accuracy: 0.68 - 0s 7ms/step - loss: 0.6241 - accuracy: 0.6873 - val_loss: 0.4970 - val_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.65 - ETA: 0s - loss: 0.6006 - accuracy: 0.70 - 0s 8ms/step - loss: 0.5962 - accuracy: 0.7151 - val_loss: 0.4925 - val_accuracy: 0.8080\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5806 - accuracy: 0.65 - ETA: 0s - loss: 0.5732 - accuracy: 0.70 - 0s 9ms/step - loss: 0.5861 - accuracy: 0.7072 - val_loss: 0.4760 - val_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7637 - accuracy: 0.62 - ETA: 0s - loss: 0.5802 - accuracy: 0.69 - 0s 7ms/step - loss: 0.5828 - accuracy: 0.7032 - val_loss: 0.4503 - val_accuracy: 0.8160\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7067 - accuracy: 0.59 - ETA: 0s - loss: 0.6186 - accuracy: 0.70 - ETA: 0s - loss: 0.6509 - accuracy: 0.69 - 0s 11ms/step - loss: 0.6442 - accuracy: 0.6912 - val_loss: 0.4622 - val_accuracy: 0.8080\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7988 - accuracy: 0.59 - ETA: 0s - loss: 0.6373 - accuracy: 0.69 - 0s 9ms/step - loss: 0.5871 - accuracy: 0.7072 - val_loss: 0.4615 - val_accuracy: 0.8080\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.65 - ETA: 0s - loss: 0.6050 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5844 - accuracy: 0.6912 - val_loss: 0.4444 - val_accuracy: 0.8160\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.68 - ETA: 0s - loss: 0.5554 - accuracy: 0.75 - 0s 10ms/step - loss: 0.5708 - accuracy: 0.7470 - val_loss: 0.4406 - val_accuracy: 0.8160\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.71 - ETA: 0s - loss: 0.5631 - accuracy: 0.73 - 0s 6ms/step - loss: 0.5668 - accuracy: 0.7331 - val_loss: 0.4190 - val_accuracy: 0.7920\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.68 - ETA: 0s - loss: 0.5799 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5736 - accuracy: 0.7510 - val_loss: 0.4256 - val_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7788 - accuracy: 0.59 - ETA: 0s - loss: 0.5932 - accuracy: 0.71 - 0s 7ms/step - loss: 0.5755 - accuracy: 0.7151 - val_loss: 0.4362 - val_accuracy: 0.8160\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6018 - accuracy: 0.75 - ETA: 0s - loss: 0.5383 - accuracy: 0.74 - 0s 9ms/step - loss: 0.5222 - accuracy: 0.7550 - val_loss: 0.4551 - val_accuracy: 0.8080\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.62 - ETA: 0s - loss: 0.6304 - accuracy: 0.67 - ETA: 0s - loss: 0.5991 - accuracy: 0.70 - 0s 10ms/step - loss: 0.5991 - accuracy: 0.7032 - val_loss: 0.5197 - val_accuracy: 0.7840\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5779 - accuracy: 0.78 - ETA: 0s - loss: 0.5451 - accuracy: 0.73 - 0s 10ms/step - loss: 0.5648 - accuracy: 0.7211 - val_loss: 0.4864 - val_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.62 - ETA: 0s - loss: 0.5958 - accuracy: 0.68 - 0s 9ms/step - loss: 0.5626 - accuracy: 0.7251 - val_loss: 0.4588 - val_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7451 - accuracy: 0.65 - ETA: 0s - loss: 0.5176 - accuracy: 0.75 - 0s 9ms/step - loss: 0.5262 - accuracy: 0.7390 - val_loss: 0.4544 - val_accuracy: 0.7840\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.78 - ETA: 0s - loss: 0.5358 - accuracy: 0.74 - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7490 - val_loss: 0.4477 - val_accuracy: 0.7840\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.78 - ETA: 0s - loss: 0.6009 - accuracy: 0.74 - 0s 6ms/step - loss: 0.5769 - accuracy: 0.7410 - val_loss: 0.4570 - val_accuracy: 0.7840\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.56 - ETA: 0s - loss: 0.5666 - accuracy: 0.74 - 0s 9ms/step - loss: 0.5809 - accuracy: 0.7530 - val_loss: 0.4759 - val_accuracy: 0.8080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 2ba15c6fc22a8490acc88c2a21ef7fd3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8240000009536743</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 1024</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 22s - loss: 0.7373 - accuracy: 0.562 - ETA: 1s - loss: 0.6890 - accuracy: 0.621 - 2s 128ms/step - loss: 0.7308 - accuracy: 0.6375 - val_loss: 0.7833 - val_accuracy: 0.3520\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8764 - accuracy: 0.50 - ETA: 0s - loss: 0.7920 - accuracy: 0.60 - 0s 19ms/step - loss: 0.7853 - accuracy: 0.6056 - val_loss: 0.7077 - val_accuracy: 0.3680\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7315 - accuracy: 0.56 - ETA: 0s - loss: 0.7174 - accuracy: 0.59 - ETA: 0s - loss: 0.6878 - accuracy: 0.65 - 0s 24ms/step - loss: 0.7112 - accuracy: 0.6394 - val_loss: 0.7578 - val_accuracy: 0.7200\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.62 - ETA: 0s - loss: 0.6149 - accuracy: 0.65 - ETA: 0s - loss: 0.6776 - accuracy: 0.65 - 0s 12ms/step - loss: 0.6846 - accuracy: 0.6574 - val_loss: 0.7998 - val_accuracy: 0.5280\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7086 - accuracy: 0.59 - ETA: 0s - loss: 0.6923 - accuracy: 0.61 - 0s 9ms/step - loss: 0.6673 - accuracy: 0.6534 - val_loss: 0.6175 - val_accuracy: 0.6880\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6792 - accuracy: 0.68 - ETA: 0s - loss: 0.7321 - accuracy: 0.65 - ETA: 0s - loss: 0.6899 - accuracy: 0.67 - 0s 23ms/step - loss: 0.7038 - accuracy: 0.6753 - val_loss: 0.5502 - val_accuracy: 0.7840\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.7076 - accuracy: 0.64 - ETA: 0s - loss: 0.6674 - accuracy: 0.68 - 0s 16ms/step - loss: 0.6613 - accuracy: 0.6932 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7491 - accuracy: 0.62 - ETA: 0s - loss: 0.6472 - accuracy: 0.68 - ETA: 0s - loss: 0.6277 - accuracy: 0.70 - 0s 11ms/step - loss: 0.6047 - accuracy: 0.7191 - val_loss: 0.5054 - val_accuracy: 0.7840\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6467 - accuracy: 0.59 - ETA: 0s - loss: 0.5814 - accuracy: 0.71 - 0s 27ms/step - loss: 0.5685 - accuracy: 0.7211 - val_loss: 0.4879 - val_accuracy: 0.8080\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.75 - ETA: 0s - loss: 0.5871 - accuracy: 0.70 - ETA: 0s - loss: 0.5934 - accuracy: 0.71 - 0s 13ms/step - loss: 0.5892 - accuracy: 0.7131 - val_loss: 0.4632 - val_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.71 - ETA: 0s - loss: 0.6430 - accuracy: 0.72 - ETA: 0s - loss: 0.6229 - accuracy: 0.73 - 1s 34ms/step - loss: 0.6219 - accuracy: 0.7331 - val_loss: 0.4545 - val_accuracy: 0.8400\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7543 - accuracy: 0.75 - ETA: 0s - loss: 0.6193 - accuracy: 0.76 - ETA: 0s - loss: 0.5913 - accuracy: 0.74 - ETA: 0s - loss: 0.5528 - accuracy: 0.75 - 0s 17ms/step - loss: 0.5510 - accuracy: 0.7550 - val_loss: 0.5736 - val_accuracy: 0.7760\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.81 - ETA: 0s - loss: 0.5881 - accuracy: 0.72 - ETA: 0s - loss: 0.5559 - accuracy: 0.75 - 0s 11ms/step - loss: 0.5428 - accuracy: 0.7570 - val_loss: 0.4641 - val_accuracy: 0.8080\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6503 - accuracy: 0.68 - ETA: 0s - loss: 0.6139 - accuracy: 0.71 - ETA: 0s - loss: 0.5651 - accuracy: 0.75 - 0s 12ms/step - loss: 0.5483 - accuracy: 0.7590 - val_loss: 0.4699 - val_accuracy: 0.7760\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.59 - ETA: 0s - loss: 0.5574 - accuracy: 0.74 - ETA: 0s - loss: 0.5506 - accuracy: 0.74 - 0s 10ms/step - loss: 0.5361 - accuracy: 0.7490 - val_loss: 0.4530 - val_accuracy: 0.7840\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.75 - ETA: 0s - loss: 0.5279 - accuracy: 0.75 - ETA: 0s - loss: 0.5085 - accuracy: 0.78 - 0s 11ms/step - loss: 0.5197 - accuracy: 0.7769 - val_loss: 0.4528 - val_accuracy: 0.8080\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.71 - ETA: 0s - loss: 0.5218 - accuracy: 0.78 - 0s 7ms/step - loss: 0.5115 - accuracy: 0.7809 - val_loss: 0.5066 - val_accuracy: 0.7760\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.81 - ETA: 0s - loss: 0.4957 - accuracy: 0.78 - 0s 9ms/step - loss: 0.5041 - accuracy: 0.7829 - val_loss: 0.4275 - val_accuracy: 0.8080\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.68 - ETA: 0s - loss: 0.5040 - accuracy: 0.75 - 0s 9ms/step - loss: 0.4726 - accuracy: 0.7689 - val_loss: 0.4573 - val_accuracy: 0.8080\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.84 - ETA: 0s - loss: 0.5517 - accuracy: 0.76 - ETA: 0s - loss: 0.5251 - accuracy: 0.78 - 0s 12ms/step - loss: 0.5013 - accuracy: 0.7968 - val_loss: 0.4470 - val_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.75 - ETA: 0s - loss: 0.5421 - accuracy: 0.75 - ETA: 0s - loss: 0.5337 - accuracy: 0.76 - 0s 12ms/step - loss: 0.5124 - accuracy: 0.7649 - val_loss: 0.4954 - val_accuracy: 0.8080\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.71 - ETA: 0s - loss: 0.4578 - accuracy: 0.78 - ETA: 0s - loss: 0.4890 - accuracy: 0.77 - 0s 12ms/step - loss: 0.4721 - accuracy: 0.7849 - val_loss: 0.4433 - val_accuracy: 0.8080\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.75 - ETA: 0s - loss: 0.5651 - accuracy: 0.74 - ETA: 0s - loss: 0.5312 - accuracy: 0.75 - 0s 12ms/step - loss: 0.5047 - accuracy: 0.7669 - val_loss: 0.4362 - val_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.81 - ETA: 0s - loss: 0.5273 - accuracy: 0.78 - ETA: 0s - loss: 0.4855 - accuracy: 0.79 - 0s 12ms/step - loss: 0.4879 - accuracy: 0.7928 - val_loss: 0.4469 - val_accuracy: 0.7920\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.68 - ETA: 0s - loss: 0.5220 - accuracy: 0.76 - ETA: 0s - loss: 0.5439 - accuracy: 0.77 - 0s 10ms/step - loss: 0.5357 - accuracy: 0.7749 - val_loss: 0.4272 - val_accuracy: 0.8160\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.65 - ETA: 0s - loss: 0.5068 - accuracy: 0.76 - 0s 9ms/step - loss: 0.4945 - accuracy: 0.7809 - val_loss: 0.3832 - val_accuracy: 0.8160\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.75 - ETA: 0s - loss: 0.5318 - accuracy: 0.77 - ETA: 0s - loss: 0.5066 - accuracy: 0.77 - 0s 10ms/step - loss: 0.5030 - accuracy: 0.7729 - val_loss: 0.3878 - val_accuracy: 0.8240\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.84 - ETA: 0s - loss: 0.5041 - accuracy: 0.79 - ETA: 0s - loss: 0.5006 - accuracy: 0.79 - 0s 11ms/step - loss: 0.4719 - accuracy: 0.7988 - val_loss: 0.3653 - val_accuracy: 0.8320\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.71 - ETA: 0s - loss: 0.5565 - accuracy: 0.73 - ETA: 0s - loss: 0.4981 - accuracy: 0.76 - 0s 12ms/step - loss: 0.4813 - accuracy: 0.7709 - val_loss: 0.3989 - val_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.78 - ETA: 0s - loss: 0.4645 - accuracy: 0.79 - ETA: 0s - loss: 0.4329 - accuracy: 0.80 - 0s 11ms/step - loss: 0.4232 - accuracy: 0.8147 - val_loss: 0.4386 - val_accuracy: 0.7840\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.75 - ETA: 0s - loss: 0.4731 - accuracy: 0.78 - 0s 9ms/step - loss: 0.4701 - accuracy: 0.7968 - val_loss: 0.3891 - val_accuracy: 0.8400\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.81 - ETA: 0s - loss: 0.5104 - accuracy: 0.78 - 0s 9ms/step - loss: 0.4786 - accuracy: 0.7829 - val_loss: 0.3638 - val_accuracy: 0.8240\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.81 - ETA: 0s - loss: 0.4658 - accuracy: 0.79 - ETA: 0s - loss: 0.4619 - accuracy: 0.81 - 0s 10ms/step - loss: 0.4756 - accuracy: 0.8088 - val_loss: 0.4143 - val_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.75 - ETA: 0s - loss: 0.4777 - accuracy: 0.76 - ETA: 0s - loss: 0.4924 - accuracy: 0.77 - 0s 10ms/step - loss: 0.4865 - accuracy: 0.7789 - val_loss: 0.4330 - val_accuracy: 0.7920\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.81 - ETA: 0s - loss: 0.4605 - accuracy: 0.79 - 0s 8ms/step - loss: 0.4561 - accuracy: 0.7968 - val_loss: 0.4117 - val_accuracy: 0.8080\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.75 - ETA: 0s - loss: 0.4539 - accuracy: 0.79 - 0s 9ms/step - loss: 0.4559 - accuracy: 0.8008 - val_loss: 0.4159 - val_accuracy: 0.8080\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6082 - accuracy: 0.78 - ETA: 0s - loss: 0.5207 - accuracy: 0.76 - 0s 9ms/step - loss: 0.4912 - accuracy: 0.7769 - val_loss: 0.4157 - val_accuracy: 0.8240\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4578 - accuracy: 0.78 - ETA: 0s - loss: 0.5219 - accuracy: 0.77 - 0s 17ms/step - loss: 0.4716 - accuracy: 0.8028 - val_loss: 0.3805 - val_accuracy: 0.8480\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.75 - ETA: 0s - loss: 0.5049 - accuracy: 0.77 - ETA: 0s - loss: 0.4976 - accuracy: 0.76 - 0s 12ms/step - loss: 0.4762 - accuracy: 0.7749 - val_loss: 0.3657 - val_accuracy: 0.8400\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5894 - accuracy: 0.84 - ETA: 0s - loss: 0.5403 - accuracy: 0.78 - ETA: 0s - loss: 0.5073 - accuracy: 0.79 - 0s 12ms/step - loss: 0.4825 - accuracy: 0.7988 - val_loss: 0.3716 - val_accuracy: 0.8160\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.78 - ETA: 0s - loss: 0.4576 - accuracy: 0.78 - 0s 9ms/step - loss: 0.4400 - accuracy: 0.8028 - val_loss: 0.3803 - val_accuracy: 0.8240\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.84 - ETA: 0s - loss: 0.4669 - accuracy: 0.77 - ETA: 0s - loss: 0.4519 - accuracy: 0.78 - 0s 10ms/step - loss: 0.4438 - accuracy: 0.7888 - val_loss: 0.4267 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 8087cfdd4f196954a6530090be789033</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8479999899864197</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 8s - loss: 4.3956 - accuracy: 0.59 - 1s 56ms/step - loss: 3.4976 - accuracy: 0.4880 - val_loss: 0.7243 - val_accuracy: 0.7120\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.1930 - accuracy: 0.46 - 0s 10ms/step - loss: 2.8100 - accuracy: 0.5578 - val_loss: 0.7185 - val_accuracy: 0.7200\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.2111 - accuracy: 0.53 - 0s 4ms/step - loss: 2.5138 - accuracy: 0.5478 - val_loss: 0.7115 - val_accuracy: 0.7120\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.9861 - accuracy: 0.62 - 0s 3ms/step - loss: 2.3797 - accuracy: 0.5916 - val_loss: 0.6798 - val_accuracy: 0.7200\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.2633 - accuracy: 0.40 - 0s 5ms/step - loss: 2.3033 - accuracy: 0.5757 - val_loss: 0.6599 - val_accuracy: 0.7200\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.8889 - accuracy: 0.50 - 0s 6ms/step - loss: 2.4609 - accuracy: 0.6036 - val_loss: 0.6533 - val_accuracy: 0.7200\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.5446 - accuracy: 0.56 - 0s 5ms/step - loss: 2.1488 - accuracy: 0.5896 - val_loss: 0.6172 - val_accuracy: 0.7120\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6831 - accuracy: 0.53 - 0s 6ms/step - loss: 1.9663 - accuracy: 0.5936 - val_loss: 0.5916 - val_accuracy: 0.7040\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.7841 - accuracy: 0.46 - 0s 5ms/step - loss: 1.8328 - accuracy: 0.5837 - val_loss: 0.6207 - val_accuracy: 0.7200\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.4656 - accuracy: 0.56 - 0s 6ms/step - loss: 1.8379 - accuracy: 0.5837 - val_loss: 0.6248 - val_accuracy: 0.7200\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.0933 - accuracy: 0.40 - 0s 15ms/step - loss: 1.9141 - accuracy: 0.5737 - val_loss: 0.6419 - val_accuracy: 0.7440\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5310 - accuracy: 0.50 - 0s 4ms/step - loss: 2.0516 - accuracy: 0.5558 - val_loss: 0.6667 - val_accuracy: 0.7360\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4784 - accuracy: 0.50 - 0s 5ms/step - loss: 1.5022 - accuracy: 0.6096 - val_loss: 0.6541 - val_accuracy: 0.7440\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1436 - accuracy: 0.59 - 0s 5ms/step - loss: 1.5831 - accuracy: 0.6096 - val_loss: 0.5987 - val_accuracy: 0.7360\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3200 - accuracy: 0.62 - 0s 12ms/step - loss: 1.3625 - accuracy: 0.6036 - val_loss: 0.5531 - val_accuracy: 0.7520\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7049 - accuracy: 0.53 - 0s 12ms/step - loss: 1.5161 - accuracy: 0.5797 - val_loss: 0.5572 - val_accuracy: 0.7600\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.0597 - accuracy: 0.46 - 0s 4ms/step - loss: 1.3399 - accuracy: 0.6036 - val_loss: 0.5713 - val_accuracy: 0.7200\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2776 - accuracy: 0.50 - 0s 5ms/step - loss: 1.4364 - accuracy: 0.6195 - val_loss: 0.5541 - val_accuracy: 0.7600\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.7565 - accuracy: 0.53 - 0s 6ms/step - loss: 1.3493 - accuracy: 0.6096 - val_loss: 0.5409 - val_accuracy: 0.7520\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3851 - accuracy: 0.53 - 0s 5ms/step - loss: 1.1597 - accuracy: 0.6195 - val_loss: 0.5711 - val_accuracy: 0.7200\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0872 - accuracy: 0.62 - 0s 4ms/step - loss: 1.1229 - accuracy: 0.6175 - val_loss: 0.5272 - val_accuracy: 0.7600\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8640 - accuracy: 0.65 - 0s 5ms/step - loss: 1.1048 - accuracy: 0.6235 - val_loss: 0.5297 - val_accuracy: 0.7360\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2932 - accuracy: 0.53 - 0s 6ms/step - loss: 0.9125 - accuracy: 0.6434 - val_loss: 0.5315 - val_accuracy: 0.7200\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6597 - accuracy: 0.65 - 0s 4ms/step - loss: 1.2143 - accuracy: 0.6394 - val_loss: 0.5232 - val_accuracy: 0.7520\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2108 - accuracy: 0.56 - 0s 5ms/step - loss: 0.9816 - accuracy: 0.6215 - val_loss: 0.5356 - val_accuracy: 0.7440\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.62 - 0s 5ms/step - loss: 1.0334 - accuracy: 0.6713 - val_loss: 0.5458 - val_accuracy: 0.7280\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8261 - accuracy: 0.65 - 0s 5ms/step - loss: 1.1208 - accuracy: 0.6494 - val_loss: 0.5244 - val_accuracy: 0.7600\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8259 - accuracy: 0.56 - 0s 3ms/step - loss: 1.1041 - accuracy: 0.6454 - val_loss: 0.5161 - val_accuracy: 0.7600\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8122 - accuracy: 0.68 - 0s 3ms/step - loss: 0.8742 - accuracy: 0.6494 - val_loss: 0.5009 - val_accuracy: 0.7520\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8554 - accuracy: 0.62 - 0s 5ms/step - loss: 0.8886 - accuracy: 0.6594 - val_loss: 0.5135 - val_accuracy: 0.7360\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9676 - accuracy: 0.68 - 0s 12ms/step - loss: 0.8828 - accuracy: 0.6753 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7979 - accuracy: 0.62 - 0s 4ms/step - loss: 0.8758 - accuracy: 0.6653 - val_loss: 0.4842 - val_accuracy: 0.7680\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8615 - accuracy: 0.68 - 0s 5ms/step - loss: 0.8627 - accuracy: 0.6853 - val_loss: 0.4864 - val_accuracy: 0.7680\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8901 - accuracy: 0.62 - 0s 5ms/step - loss: 0.8650 - accuracy: 0.6614 - val_loss: 0.4813 - val_accuracy: 0.7760\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.68 - 0s 4ms/step - loss: 0.8262 - accuracy: 0.6713 - val_loss: 0.4792 - val_accuracy: 0.7680\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6390 - accuracy: 0.62 - 0s 6ms/step - loss: 0.7242 - accuracy: 0.6952 - val_loss: 0.4723 - val_accuracy: 0.7680\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0218 - accuracy: 0.59 - 0s 15ms/step - loss: 0.7612 - accuracy: 0.6653 - val_loss: 0.4664 - val_accuracy: 0.8160\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7575 - accuracy: 0.56 - 0s 4ms/step - loss: 0.7485 - accuracy: 0.6653 - val_loss: 0.4667 - val_accuracy: 0.7920\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6146 - accuracy: 0.65 - 0s 5ms/step - loss: 0.7113 - accuracy: 0.7012 - val_loss: 0.4652 - val_accuracy: 0.7840\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7003 - accuracy: 0.59 - 0s 6ms/step - loss: 0.7226 - accuracy: 0.6912 - val_loss: 0.4653 - val_accuracy: 0.8080\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.71 - 0s 6ms/step - loss: 0.6631 - accuracy: 0.6853 - val_loss: 0.4597 - val_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5789 - accuracy: 0.65 - 0s 5ms/step - loss: 0.6989 - accuracy: 0.6873 - val_loss: 0.4570 - val_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9472 - accuracy: 0.59 - 0s 5ms/step - loss: 0.6925 - accuracy: 0.6813 - val_loss: 0.4534 - val_accuracy: 0.8160\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8285 - accuracy: 0.65 - 0s 5ms/step - loss: 0.7098 - accuracy: 0.6793 - val_loss: 0.4513 - val_accuracy: 0.8000\n",
      "Epoch 45/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.6094 - accuracy: 0.62 - 0s 5ms/step - loss: 0.8007 - accuracy: 0.6614 - val_loss: 0.4541 - val_accuracy: 0.8080\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8813 - accuracy: 0.40 - 0s 5ms/step - loss: 0.7106 - accuracy: 0.6633 - val_loss: 0.4571 - val_accuracy: 0.7840\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.53 - 0s 5ms/step - loss: 0.6597 - accuracy: 0.6873 - val_loss: 0.4528 - val_accuracy: 0.7840\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8269 - accuracy: 0.65 - 0s 5ms/step - loss: 0.6981 - accuracy: 0.7072 - val_loss: 0.4490 - val_accuracy: 0.8160\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9266 - accuracy: 0.59 - 0s 14ms/step - loss: 0.6751 - accuracy: 0.6773 - val_loss: 0.4478 - val_accuracy: 0.8320\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7078 - accuracy: 0.65 - 0s 11ms/step - loss: 0.6331 - accuracy: 0.6972 - val_loss: 0.4466 - val_accuracy: 0.8400\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9297 - accuracy: 0.68 - ETA: 0s - loss: 0.6620 - accuracy: 0.70 - 0s 6ms/step - loss: 0.6570 - accuracy: 0.7032 - val_loss: 0.4442 - val_accuracy: 0.8400\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.68 - 0s 13ms/step - loss: 0.7593 - accuracy: 0.6793 - val_loss: 0.4504 - val_accuracy: 0.8480\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.68 - 0s 6ms/step - loss: 0.7006 - accuracy: 0.6972 - val_loss: 0.4502 - val_accuracy: 0.8160\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.59 - 0s 5ms/step - loss: 0.6586 - accuracy: 0.7112 - val_loss: 0.4429 - val_accuracy: 0.8080\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.53 - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7390 - val_loss: 0.4436 - val_accuracy: 0.8080\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8551 - accuracy: 0.59 - 0s 5ms/step - loss: 0.6874 - accuracy: 0.7012 - val_loss: 0.4473 - val_accuracy: 0.8080\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5642 - accuracy: 0.71 - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6952 - val_loss: 0.4417 - val_accuracy: 0.8160\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6668 - accuracy: 0.62 - 0s 4ms/step - loss: 0.6416 - accuracy: 0.7012 - val_loss: 0.4403 - val_accuracy: 0.8160\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.59 - 0s 3ms/step - loss: 0.6094 - accuracy: 0.7112 - val_loss: 0.4362 - val_accuracy: 0.8160\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.65 - 0s 3ms/step - loss: 0.6078 - accuracy: 0.7231 - val_loss: 0.4361 - val_accuracy: 0.8240\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7772 - accuracy: 0.59 - 0s 3ms/step - loss: 0.6107 - accuracy: 0.7092 - val_loss: 0.4356 - val_accuracy: 0.8160\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7175 - accuracy: 0.53 - 0s 3ms/step - loss: 0.6093 - accuracy: 0.7072 - val_loss: 0.4365 - val_accuracy: 0.8240\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.65 - 0s 3ms/step - loss: 0.6531 - accuracy: 0.7271 - val_loss: 0.4344 - val_accuracy: 0.8320\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.59 - 0s 3ms/step - loss: 0.5823 - accuracy: 0.7231 - val_loss: 0.4318 - val_accuracy: 0.8240\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7378 - accuracy: 0.53 - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7191 - val_loss: 0.4317 - val_accuracy: 0.8240\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7331 - val_loss: 0.4353 - val_accuracy: 0.8480\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.62 - 0s 15ms/step - loss: 0.5715 - accuracy: 0.7171 - val_loss: 0.4341 - val_accuracy: 0.8560\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5889 - accuracy: 0.65 - 0s 6ms/step - loss: 0.5749 - accuracy: 0.7112 - val_loss: 0.4369 - val_accuracy: 0.8480\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.62 - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7390 - val_loss: 0.4332 - val_accuracy: 0.8400\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6451 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5851 - accuracy: 0.7450 - val_loss: 0.4451 - val_accuracy: 0.8400\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5965 - accuracy: 0.7291 - val_loss: 0.4415 - val_accuracy: 0.8400\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5718 - accuracy: 0.7231 - val_loss: 0.4417 - val_accuracy: 0.8320\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5596 - accuracy: 0.7351 - val_loss: 0.4349 - val_accuracy: 0.8240\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.46 - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7191 - val_loss: 0.4393 - val_accuracy: 0.8320\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.78 - 0s 6ms/step - loss: 0.5470 - accuracy: 0.7590 - val_loss: 0.4279 - val_accuracy: 0.8480\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.59 - 0s 5ms/step - loss: 0.6105 - accuracy: 0.7390 - val_loss: 0.4252 - val_accuracy: 0.8320\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5546 - accuracy: 0.7450 - val_loss: 0.4242 - val_accuracy: 0.8400\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.62 - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7390 - val_loss: 0.4308 - val_accuracy: 0.8560\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.71 - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7430 - val_loss: 0.4336 - val_accuracy: 0.8560\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7681 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5825 - accuracy: 0.7590 - val_loss: 0.4355 - val_accuracy: 0.8400\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5517 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5897 - accuracy: 0.7291 - val_loss: 0.4303 - val_accuracy: 0.8400\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.68 - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7530 - val_loss: 0.4285 - val_accuracy: 0.8480\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7490 - val_loss: 0.4276 - val_accuracy: 0.8560\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7450 - val_loss: 0.4290 - val_accuracy: 0.8560\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7757 - accuracy: 0.68 - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7590 - val_loss: 0.4292 - val_accuracy: 0.8480\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.68 - 0s 4ms/step - loss: 0.6040 - accuracy: 0.7271 - val_loss: 0.4253 - val_accuracy: 0.8480\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5795 - accuracy: 0.71 - 0s 6ms/step - loss: 0.5507 - accuracy: 0.7769 - val_loss: 0.4231 - val_accuracy: 0.8480\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5597 - accuracy: 0.7789 - val_loss: 0.4309 - val_accuracy: 0.8560\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5454 - accuracy: 0.7689 - val_loss: 0.4192 - val_accuracy: 0.8480\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6021 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5471 - accuracy: 0.7530 - val_loss: 0.4155 - val_accuracy: 0.8560\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6638 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7510 - val_loss: 0.4262 - val_accuracy: 0.8560\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5928 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7450 - val_loss: 0.4184 - val_accuracy: 0.8400\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.71 - 0s 20ms/step - loss: 0.5542 - accuracy: 0.7490 - val_loss: 0.4108 - val_accuracy: 0.8640\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.65 - ETA: 0s - loss: 0.5483 - accuracy: 0.73 - 0s 10ms/step - loss: 0.5453 - accuracy: 0.7371 - val_loss: 0.4174 - val_accuracy: 0.8480\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5567 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5621 - accuracy: 0.7430 - val_loss: 0.4255 - val_accuracy: 0.8480\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7430 - val_loss: 0.4082 - val_accuracy: 0.8560\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5805 - accuracy: 0.71 - 0s 17ms/step - loss: 0.5280 - accuracy: 0.7689 - val_loss: 0.4122 - val_accuracy: 0.8720\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.65 - ETA: 0s - loss: 0.5362 - accuracy: 0.75 - 0s 10ms/step - loss: 0.5279 - accuracy: 0.7610 - val_loss: 0.4177 - val_accuracy: 0.8560\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.78 - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7849 - val_loss: 0.4071 - val_accuracy: 0.8640\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5800 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5370 - accuracy: 0.7669 - val_loss: 0.3981 - val_accuracy: 0.8720\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.62 - 0s 21ms/step - loss: 0.5040 - accuracy: 0.7610 - val_loss: 0.4031 - val_accuracy: 0.8800\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.75 - ETA: 0s - loss: 0.5096 - accuracy: 0.76 - 0s 8ms/step - loss: 0.5226 - accuracy: 0.7649 - val_loss: 0.4129 - val_accuracy: 0.8640\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.75 - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7689 - val_loss: 0.4021 - val_accuracy: 0.8560\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6465 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7689 - val_loss: 0.4007 - val_accuracy: 0.8560\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7948 - val_loss: 0.4079 - val_accuracy: 0.8640\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5086 - accuracy: 0.78 - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7689 - val_loss: 0.4034 - val_accuracy: 0.8640\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6408 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5076 - accuracy: 0.7789 - val_loss: 0.4012 - val_accuracy: 0.8720\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5231 - accuracy: 0.7729 - val_loss: 0.3952 - val_accuracy: 0.8720\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7590 - val_loss: 0.3898 - val_accuracy: 0.8800\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.75 - 0s 18ms/step - loss: 0.4987 - accuracy: 0.7809 - val_loss: 0.3939 - val_accuracy: 0.8880\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5753 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5025 - accuracy: 0.7789 - val_loss: 0.3977 - val_accuracy: 0.8720\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7669 - val_loss: 0.3995 - val_accuracy: 0.8800\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.65 - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7689 - val_loss: 0.3933 - val_accuracy: 0.8880\n",
      "Epoch 114/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7550 - val_loss: 0.3869 - val_accuracy: 0.8800\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.81 - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7829 - val_loss: 0.3925 - val_accuracy: 0.8880\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4858 - accuracy: 0.84 - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7749 - val_loss: 0.3884 - val_accuracy: 0.8880\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5190 - accuracy: 0.71 - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7729 - val_loss: 0.3856 - val_accuracy: 0.8800\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.75 - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7689 - val_loss: 0.3879 - val_accuracy: 0.8880\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4939 - accuracy: 0.7749 - val_loss: 0.3841 - val_accuracy: 0.8720\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.81 - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7849 - val_loss: 0.3844 - val_accuracy: 0.8880\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6048 - accuracy: 0.68 - 0s 16ms/step - loss: 0.4984 - accuracy: 0.7749 - val_loss: 0.3842 - val_accuracy: 0.8960\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6154 - accuracy: 0.75 - ETA: 0s - loss: 0.4776 - accuracy: 0.81 - 0s 10ms/step - loss: 0.4879 - accuracy: 0.8088 - val_loss: 0.3846 - val_accuracy: 0.8880\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5462 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7928 - val_loss: 0.3864 - val_accuracy: 0.8800\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4763 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7928 - val_loss: 0.3851 - val_accuracy: 0.8880\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7789 - val_loss: 0.3847 - val_accuracy: 0.8880\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7908 - val_loss: 0.3824 - val_accuracy: 0.8880\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7849 - val_loss: 0.3840 - val_accuracy: 0.8880\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.81 - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7729 - val_loss: 0.3851 - val_accuracy: 0.8880\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5027 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7849 - val_loss: 0.3848 - val_accuracy: 0.8800\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.65 - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7769 - val_loss: 0.3780 - val_accuracy: 0.8800\n",
      "Epoch 131/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4930 - accuracy: 0.7649 - val_loss: 0.3813 - val_accuracy: 0.8720\n",
      "Epoch 132/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.5515 - accuracy: 0.78 - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7769 - val_loss: 0.3900 - val_accuracy: 0.8640\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4982 - accuracy: 0.7809 - val_loss: 0.3892 - val_accuracy: 0.8640\n",
      "Epoch 134/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7729 - val_loss: 0.3873 - val_accuracy: 0.8800\n",
      "Epoch 135/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4699 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7928 - val_loss: 0.3831 - val_accuracy: 0.8880\n",
      "Epoch 136/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5849 - accuracy: 0.71 - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7849 - val_loss: 0.3813 - val_accuracy: 0.8960\n",
      "Epoch 137/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7948 - val_loss: 0.3824 - val_accuracy: 0.8720\n",
      "Epoch 138/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7928 - val_loss: 0.3774 - val_accuracy: 0.8800\n",
      "Epoch 139/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.68 - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7928 - val_loss: 0.3795 - val_accuracy: 0.8800\n",
      "Epoch 140/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.81 - 0s 6ms/step - loss: 0.4816 - accuracy: 0.7869 - val_loss: 0.3790 - val_accuracy: 0.8800\n",
      "Epoch 141/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4509 - accuracy: 0.8127 - val_loss: 0.3829 - val_accuracy: 0.8720\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7968 - val_loss: 0.3734 - val_accuracy: 0.8800\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8008 - val_loss: 0.3754 - val_accuracy: 0.8640\n",
      "Epoch 144/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7869 - val_loss: 0.3757 - val_accuracy: 0.8640\n",
      "Epoch 145/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4825 - accuracy: 0.7928 - val_loss: 0.3750 - val_accuracy: 0.8800\n",
      "Epoch 146/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6011 - accuracy: 0.65 - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7908 - val_loss: 0.3746 - val_accuracy: 0.8800\n",
      "Epoch 147/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.87 - 0s 5ms/step - loss: 0.4763 - accuracy: 0.8028 - val_loss: 0.3830 - val_accuracy: 0.8640\n",
      "Epoch 148/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7988 - val_loss: 0.3772 - val_accuracy: 0.8560\n",
      "Epoch 149/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7809 - val_loss: 0.3786 - val_accuracy: 0.8640\n",
      "Epoch 150/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7829 - val_loss: 0.3747 - val_accuracy: 0.8720\n",
      "Epoch 151/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4778 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7988 - val_loss: 0.3777 - val_accuracy: 0.8640\n",
      "Epoch 152/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7888 - val_loss: 0.3728 - val_accuracy: 0.8560\n",
      "Epoch 153/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7869 - val_loss: 0.3758 - val_accuracy: 0.8560\n",
      "Epoch 154/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.75 - ETA: 0s - loss: 0.4997 - accuracy: 0.78 - 0s 8ms/step - loss: 0.4851 - accuracy: 0.7888 - val_loss: 0.3748 - val_accuracy: 0.8640\n",
      "Epoch 155/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7948 - val_loss: 0.3759 - val_accuracy: 0.8560\n",
      "Epoch 156/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7928 - val_loss: 0.3768 - val_accuracy: 0.8560\n",
      "Epoch 157/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4615 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7869 - val_loss: 0.3685 - val_accuracy: 0.8800\n",
      "Epoch 158/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5149 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8028 - val_loss: 0.3744 - val_accuracy: 0.8720\n",
      "Epoch 159/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7948 - val_loss: 0.3748 - val_accuracy: 0.8640\n",
      "Epoch 160/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.75 - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7908 - val_loss: 0.3723 - val_accuracy: 0.8720\n",
      "Epoch 161/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7869 - val_loss: 0.3722 - val_accuracy: 0.8640\n",
      "Epoch 162/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4601 - accuracy: 0.8068 - val_loss: 0.3694 - val_accuracy: 0.8720\n",
      "Epoch 163/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7869 - val_loss: 0.3705 - val_accuracy: 0.8560\n",
      "Epoch 164/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4608 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7968 - val_loss: 0.3675 - val_accuracy: 0.8480\n",
      "Epoch 165/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7968 - val_loss: 0.3691 - val_accuracy: 0.8560\n",
      "Epoch 166/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7869 - val_loss: 0.3695 - val_accuracy: 0.8720\n",
      "Epoch 167/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4589 - accuracy: 0.8048 - val_loss: 0.3722 - val_accuracy: 0.8560\n",
      "Epoch 168/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4218 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7988 - val_loss: 0.3687 - val_accuracy: 0.8640\n",
      "Epoch 169/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7988 - val_loss: 0.3668 - val_accuracy: 0.8560\n",
      "Epoch 170/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.78 - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7908 - val_loss: 0.3673 - val_accuracy: 0.8640\n",
      "Epoch 171/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.75 - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7888 - val_loss: 0.3641 - val_accuracy: 0.8640\n",
      "Epoch 172/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4664 - accuracy: 0.8028 - val_loss: 0.3667 - val_accuracy: 0.8560\n",
      "Epoch 173/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.78 - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8048 - val_loss: 0.3690 - val_accuracy: 0.8400\n",
      "Epoch 174/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7908 - val_loss: 0.3700 - val_accuracy: 0.8400\n",
      "Epoch 175/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4018 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8088 - val_loss: 0.3713 - val_accuracy: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5516 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7988 - val_loss: 0.3682 - val_accuracy: 0.8480\n",
      "Epoch 177/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8068 - val_loss: 0.3715 - val_accuracy: 0.8480\n",
      "Epoch 178/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7988 - val_loss: 0.3753 - val_accuracy: 0.8480\n",
      "Epoch 179/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7948 - val_loss: 0.3734 - val_accuracy: 0.8560\n",
      "Epoch 180/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7988 - val_loss: 0.3692 - val_accuracy: 0.8560\n",
      "Epoch 181/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7849 - val_loss: 0.3699 - val_accuracy: 0.8560\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 102de0e57157646fd179e43e03dfe668</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8960000276565552</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 12s - loss: 0.7178 - accuracy: 0.593 - 1s 81ms/step - loss: 0.7035 - accuracy: 0.6016 - val_loss: 0.5974 - val_accuracy: 0.7280\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6574 - val_loss: 0.6184 - val_accuracy: 0.7200\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7039 - accuracy: 0.56 - 0s 18ms/step - loss: 0.6368 - accuracy: 0.6753 - val_loss: 0.6150 - val_accuracy: 0.7360\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8020 - accuracy: 0.59 - ETA: 0s - loss: 0.6331 - accuracy: 0.68 - 0s 21ms/step - loss: 0.6361 - accuracy: 0.6813 - val_loss: 0.5858 - val_accuracy: 0.7440\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7076 - accuracy: 0.59 - 0s 5ms/step - loss: 0.6218 - accuracy: 0.6853 - val_loss: 0.5697 - val_accuracy: 0.7440\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6091 - accuracy: 0.6972 - val_loss: 0.5563 - val_accuracy: 0.7440\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.59 - 0s 12ms/step - loss: 0.5812 - accuracy: 0.7052 - val_loss: 0.5531 - val_accuracy: 0.7600\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.65 - 0s 6ms/step - loss: 0.5643 - accuracy: 0.7112 - val_loss: 0.5608 - val_accuracy: 0.7520\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7351 - accuracy: 0.62 - 0s 6ms/step - loss: 0.5540 - accuracy: 0.7251 - val_loss: 0.5464 - val_accuracy: 0.7600\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.65 - ETA: 0s - loss: 0.5380 - accuracy: 0.73 - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7410 - val_loss: 0.5435 - val_accuracy: 0.7600\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.62 - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7371 - val_loss: 0.5364 - val_accuracy: 0.7600\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6140 - accuracy: 0.68 - 0s 11ms/step - loss: 0.5388 - accuracy: 0.7450 - val_loss: 0.5202 - val_accuracy: 0.7840\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.59 - ETA: 0s - loss: 0.5300 - accuracy: 0.75 - 0s 16ms/step - loss: 0.5253 - accuracy: 0.7490 - val_loss: 0.4957 - val_accuracy: 0.7920\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.68 - 0s 15ms/step - loss: 0.5218 - accuracy: 0.7570 - val_loss: 0.4895 - val_accuracy: 0.8080\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.68 - 0s 12ms/step - loss: 0.5117 - accuracy: 0.7769 - val_loss: 0.4674 - val_accuracy: 0.8160\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7729 - val_loss: 0.4749 - val_accuracy: 0.8080\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7769 - val_loss: 0.4657 - val_accuracy: 0.8160\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4760 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7789 - val_loss: 0.4538 - val_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7968 - val_loss: 0.4443 - val_accuracy: 0.8080\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.65 - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7629 - val_loss: 0.4378 - val_accuracy: 0.8080\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7709 - val_loss: 0.4299 - val_accuracy: 0.8160\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.75 - 0s 13ms/step - loss: 0.4817 - accuracy: 0.7849 - val_loss: 0.4102 - val_accuracy: 0.8240\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5559 - accuracy: 0.71 - 0s 11ms/step - loss: 0.4762 - accuracy: 0.7709 - val_loss: 0.4204 - val_accuracy: 0.8320\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.78 - ETA: 0s - loss: 0.4766 - accuracy: 0.78 - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7849 - val_loss: 0.4035 - val_accuracy: 0.8240\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.78 - 0s 14ms/step - loss: 0.4655 - accuracy: 0.7948 - val_loss: 0.3905 - val_accuracy: 0.8480\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5095 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7869 - val_loss: 0.3877 - val_accuracy: 0.8480\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4982 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7888 - val_loss: 0.3938 - val_accuracy: 0.8240\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4595 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7988 - val_loss: 0.3794 - val_accuracy: 0.8400\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.78 - ETA: 0s - loss: 0.4379 - accuracy: 0.80 - 0s 6ms/step - loss: 0.4431 - accuracy: 0.8028 - val_loss: 0.3835 - val_accuracy: 0.8240\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4781 - accuracy: 0.71 - ETA: 0s - loss: 0.4667 - accuracy: 0.76 - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7689 - val_loss: 0.3774 - val_accuracy: 0.8240\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4751 - accuracy: 0.8008 - val_loss: 0.3802 - val_accuracy: 0.8320\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4539 - accuracy: 0.8008 - val_loss: 0.3791 - val_accuracy: 0.8320\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.78 - ETA: 0s - loss: 0.4605 - accuracy: 0.78 - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7888 - val_loss: 0.3838 - val_accuracy: 0.8400\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.78 - ETA: 0s - loss: 0.4451 - accuracy: 0.79 - 0s 6ms/step - loss: 0.4414 - accuracy: 0.7988 - val_loss: 0.3921 - val_accuracy: 0.8160\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4473 - accuracy: 0.78 - ETA: 0s - loss: 0.4719 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4721 - accuracy: 0.7888 - val_loss: 0.3857 - val_accuracy: 0.8160\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.84 - ETA: 0s - loss: 0.4323 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4318 - accuracy: 0.8068 - val_loss: 0.3812 - val_accuracy: 0.8400\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.75 - ETA: 0s - loss: 0.4468 - accuracy: 0.80 - 0s 6ms/step - loss: 0.4478 - accuracy: 0.8048 - val_loss: 0.3743 - val_accuracy: 0.8320\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.78 - ETA: 0s - loss: 0.4542 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7948 - val_loss: 0.4103 - val_accuracy: 0.8160\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.75 - ETA: 0s - loss: 0.4640 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4635 - accuracy: 0.7988 - val_loss: 0.3815 - val_accuracy: 0.8240\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5153 - accuracy: 0.81 - ETA: 0s - loss: 0.4630 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4590 - accuracy: 0.7869 - val_loss: 0.3814 - val_accuracy: 0.8320\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.78 - ETA: 0s - loss: 0.4535 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4522 - accuracy: 0.7968 - val_loss: 0.3801 - val_accuracy: 0.8320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.75 - ETA: 0s - loss: 0.4521 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4514 - accuracy: 0.7908 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.75 - ETA: 0s - loss: 0.4437 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7968 - val_loss: 0.3695 - val_accuracy: 0.8400\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.78 - ETA: 0s - loss: 0.4458 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4472 - accuracy: 0.7968 - val_loss: 0.3847 - val_accuracy: 0.8160\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.75 - ETA: 0s - loss: 0.4303 - accuracy: 0.81 - 0s 6ms/step - loss: 0.4300 - accuracy: 0.8167 - val_loss: 0.3639 - val_accuracy: 0.8400\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.71 - ETA: 0s - loss: 0.4467 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4481 - accuracy: 0.8008 - val_loss: 0.3667 - val_accuracy: 0.8320\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5118 - accuracy: 0.71 - ETA: 0s - loss: 0.4534 - accuracy: 0.79 - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7948 - val_loss: 0.3846 - val_accuracy: 0.8240\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.81 - 0s 6ms/step - loss: 0.4419 - accuracy: 0.8008 - val_loss: 0.3837 - val_accuracy: 0.8160\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.81 - ETA: 0s - loss: 0.4288 - accuracy: 0.80 - 0s 8ms/step - loss: 0.4326 - accuracy: 0.8008 - val_loss: 0.3803 - val_accuracy: 0.8240\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8068 - val_loss: 0.3581 - val_accuracy: 0.8320\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7988 - val_loss: 0.3813 - val_accuracy: 0.8320\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4434 - accuracy: 0.8008 - val_loss: 0.3688 - val_accuracy: 0.8480\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.78 - 0s 10ms/step - loss: 0.4418 - accuracy: 0.7928 - val_loss: 0.3662 - val_accuracy: 0.8560\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.71 - ETA: 0s - loss: 0.4442 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4467 - accuracy: 0.8088 - val_loss: 0.3928 - val_accuracy: 0.8400\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8068 - val_loss: 0.3822 - val_accuracy: 0.8240\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4207 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4260 - accuracy: 0.8127 - val_loss: 0.4361 - val_accuracy: 0.8320\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.78 - ETA: 0s - loss: 0.4379 - accuracy: 0.80 - 0s 6ms/step - loss: 0.4333 - accuracy: 0.8028 - val_loss: 0.3783 - val_accuracy: 0.8240\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8108 - val_loss: 0.3705 - val_accuracy: 0.8480\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4416 - accuracy: 0.8187 - val_loss: 0.3726 - val_accuracy: 0.8080\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.78 - ETA: 0s - loss: 0.4428 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4426 - accuracy: 0.8028 - val_loss: 0.3850 - val_accuracy: 0.8320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 37cbe41b6b2c8e7855d8e2c486105c89</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8560000061988831</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 10s - loss: 13.4403 - accuracy: 0.53 - 1s 65ms/step - loss: 8.3552 - accuracy: 0.4442 - val_loss: 2.9778 - val_accuracy: 0.3360\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.3298 - accuracy: 0.65 - 0s 12ms/step - loss: 5.3400 - accuracy: 0.4582 - val_loss: 0.7250 - val_accuracy: 0.6880\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.1171 - accuracy: 0.46 - 0s 10ms/step - loss: 4.1061 - accuracy: 0.5199 - val_loss: 0.6354 - val_accuracy: 0.7440\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 0.65 - 0s 4ms/step - loss: 3.5769 - accuracy: 0.5219 - val_loss: 0.6198 - val_accuracy: 0.7440\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.7853 - accuracy: 0.56 - 0s 6ms/step - loss: 3.0612 - accuracy: 0.5598 - val_loss: 0.5734 - val_accuracy: 0.7360\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.9591 - accuracy: 0.62 - 0s 6ms/step - loss: 2.3609 - accuracy: 0.5697 - val_loss: 0.5741 - val_accuracy: 0.7360\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3509 - accuracy: 0.65 - 0s 6ms/step - loss: 1.8415 - accuracy: 0.5817 - val_loss: 0.5557 - val_accuracy: 0.7280\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0396 - accuracy: 0.62 - 0s 14ms/step - loss: 1.7032 - accuracy: 0.5837 - val_loss: 0.5693 - val_accuracy: 0.7600\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.8663 - accuracy: 0.40 - 0s 6ms/step - loss: 1.5222 - accuracy: 0.5916 - val_loss: 0.5679 - val_accuracy: 0.7600\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6974 - accuracy: 0.50 - ETA: 0s - loss: 1.4540 - accuracy: 0.58 - 0s 7ms/step - loss: 1.4898 - accuracy: 0.5857 - val_loss: 0.5630 - val_accuracy: 0.7360\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.2952 - accuracy: 0.53 - 0s 5ms/step - loss: 1.6571 - accuracy: 0.5936 - val_loss: 0.5745 - val_accuracy: 0.7200\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1850 - accuracy: 0.53 - 0s 3ms/step - loss: 1.3268 - accuracy: 0.5777 - val_loss: 0.5851 - val_accuracy: 0.6880\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8118 - accuracy: 0.59 - 0s 5ms/step - loss: 1.2835 - accuracy: 0.6076 - val_loss: 0.5931 - val_accuracy: 0.6880\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6021 - accuracy: 0.56 - 0s 6ms/step - loss: 1.1600 - accuracy: 0.6016 - val_loss: 0.5978 - val_accuracy: 0.7040\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4832 - accuracy: 0.40 - ETA: 0s - loss: 0.9989 - accuracy: 0.58 - 0s 7ms/step - loss: 1.0589 - accuracy: 0.5876 - val_loss: 0.5999 - val_accuracy: 0.7040\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.4397 - accuracy: 0.53 - 0s 5ms/step - loss: 1.0964 - accuracy: 0.6036 - val_loss: 0.6089 - val_accuracy: 0.6960\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1564 - accuracy: 0.53 - 0s 4ms/step - loss: 0.9831 - accuracy: 0.6076 - val_loss: 0.6235 - val_accuracy: 0.6880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 010bb6f65b07ddcf9df5e3439d4e01b4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7599999904632568</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 18s - loss: 0.8810 - accuracy: 0.531 - ETA: 1s - loss: 0.8625 - accuracy: 0.541 - 2s 104ms/step - loss: 0.8575 - accuracy: 0.5737 - val_loss: 0.6980 - val_accuracy: 0.6880\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9759 - accuracy: 0.53 - ETA: 0s - loss: 0.7530 - accuracy: 0.61 - 0s 15ms/step - loss: 0.7880 - accuracy: 0.6175 - val_loss: 0.6741 - val_accuracy: 0.7200\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9621 - accuracy: 0.50 - ETA: 0s - loss: 0.7179 - accuracy: 0.64 - ETA: 0s - loss: 0.7673 - accuracy: 0.65 - 0s 22ms/step - loss: 0.7584 - accuracy: 0.6494 - val_loss: 0.6659 - val_accuracy: 0.7280\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.62 - ETA: 0s - loss: 0.7748 - accuracy: 0.61 - ETA: 0s - loss: 0.7358 - accuracy: 0.64 - 0s 10ms/step - loss: 0.7369 - accuracy: 0.6375 - val_loss: 0.5505 - val_accuracy: 0.7280\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.53 - ETA: 0s - loss: 0.6725 - accuracy: 0.64 - 0s 17ms/step - loss: 0.7040 - accuracy: 0.6434 - val_loss: 0.5012 - val_accuracy: 0.7440\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8178 - accuracy: 0.43 - ETA: 0s - loss: 0.7087 - accuracy: 0.65 - 0s 14ms/step - loss: 0.6798 - accuracy: 0.6673 - val_loss: 0.5071 - val_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.50 - ETA: 0s - loss: 0.6838 - accuracy: 0.64 - ETA: 0s - loss: 0.6509 - accuracy: 0.67 - 0s 11ms/step - loss: 0.6161 - accuracy: 0.6912 - val_loss: 0.4563 - val_accuracy: 0.7840\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.71 - ETA: 0s - loss: 0.6536 - accuracy: 0.71 - 0s 10ms/step - loss: 0.6218 - accuracy: 0.7371 - val_loss: 0.5292 - val_accuracy: 0.7840\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.62 - ETA: 0s - loss: 0.6176 - accuracy: 0.71 - ETA: 0s - loss: 0.6086 - accuracy: 0.71 - 0s 10ms/step - loss: 0.6124 - accuracy: 0.7112 - val_loss: 0.4763 - val_accuracy: 0.7840\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8417 - accuracy: 0.62 - ETA: 0s - loss: 0.6355 - accuracy: 0.69 - ETA: 0s - loss: 0.6225 - accuracy: 0.71 - 0s 10ms/step - loss: 0.6235 - accuracy: 0.7151 - val_loss: 0.4939 - val_accuracy: 0.7840\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.68 - ETA: 0s - loss: 0.5558 - accuracy: 0.74 - 0s 7ms/step - loss: 0.5663 - accuracy: 0.7351 - val_loss: 0.4591 - val_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.75 - ETA: 0s - loss: 0.5498 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7550 - val_loss: 0.4779 - val_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5650 - accuracy: 0.78 - ETA: 0s - loss: 0.6114 - accuracy: 0.74 - 0s 18ms/step - loss: 0.6014 - accuracy: 0.7550 - val_loss: 0.4516 - val_accuracy: 0.8160\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.68 - ETA: 0s - loss: 0.6509 - accuracy: 0.71 - ETA: 0s - loss: 0.6235 - accuracy: 0.73 - 0s 20ms/step - loss: 0.6084 - accuracy: 0.7390 - val_loss: 0.4212 - val_accuracy: 0.8320\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7767 - accuracy: 0.59 - ETA: 0s - loss: 0.6020 - accuracy: 0.70 - ETA: 0s - loss: 0.5794 - accuracy: 0.74 - 0s 11ms/step - loss: 0.5757 - accuracy: 0.7430 - val_loss: 0.4280 - val_accuracy: 0.8240\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.75 - ETA: 0s - loss: 0.5870 - accuracy: 0.75 - ETA: 0s - loss: 0.5481 - accuracy: 0.76 - 0s 10ms/step - loss: 0.5479 - accuracy: 0.7649 - val_loss: 0.4288 - val_accuracy: 0.8240\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.65 - ETA: 0s - loss: 0.5243 - accuracy: 0.77 - 0s 7ms/step - loss: 0.5351 - accuracy: 0.7629 - val_loss: 0.4074 - val_accuracy: 0.8160\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.71 - ETA: 0s - loss: 0.5515 - accuracy: 0.73 - 0s 8ms/step - loss: 0.5371 - accuracy: 0.7550 - val_loss: 0.4126 - val_accuracy: 0.8160\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.81 - ETA: 0s - loss: 0.5980 - accuracy: 0.76 - 0s 7ms/step - loss: 0.5895 - accuracy: 0.7610 - val_loss: 0.4039 - val_accuracy: 0.8160\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6555 - accuracy: 0.62 - ETA: 0s - loss: 0.5544 - accuracy: 0.74 - 0s 8ms/step - loss: 0.5393 - accuracy: 0.7450 - val_loss: 0.3975 - val_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6308 - accuracy: 0.71 - ETA: 0s - loss: 0.5336 - accuracy: 0.75 - ETA: 0s - loss: 0.5336 - accuracy: 0.75 - 0s 10ms/step - loss: 0.5350 - accuracy: 0.7510 - val_loss: 0.3845 - val_accuracy: 0.8160\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5989 - accuracy: 0.78 - ETA: 0s - loss: 0.5147 - accuracy: 0.77 - 0s 10ms/step - loss: 0.5320 - accuracy: 0.7689 - val_loss: 0.3692 - val_accuracy: 0.8160\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.68 - ETA: 0s - loss: 0.5454 - accuracy: 0.77 - 0s 7ms/step - loss: 0.5345 - accuracy: 0.7789 - val_loss: 0.4144 - val_accuracy: 0.8240\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.71 - ETA: 0s - loss: 0.5627 - accuracy: 0.75 - 0s 15ms/step - loss: 0.5365 - accuracy: 0.7530 - val_loss: 0.3837 - val_accuracy: 0.8400\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.62 - ETA: 0s - loss: 0.5375 - accuracy: 0.75 - ETA: 0s - loss: 0.4927 - accuracy: 0.77 - 0s 11ms/step - loss: 0.4924 - accuracy: 0.7769 - val_loss: 0.3970 - val_accuracy: 0.8080\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6481 - accuracy: 0.84 - ETA: 0s - loss: 0.5841 - accuracy: 0.74 - 0s 9ms/step - loss: 0.5583 - accuracy: 0.7570 - val_loss: 0.3806 - val_accuracy: 0.8400\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6124 - accuracy: 0.68 - ETA: 0s - loss: 0.6083 - accuracy: 0.70 - ETA: 0s - loss: 0.5331 - accuracy: 0.75 - 0s 10ms/step - loss: 0.5245 - accuracy: 0.7570 - val_loss: 0.3994 - val_accuracy: 0.8080\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.78 - ETA: 0s - loss: 0.5480 - accuracy: 0.79 - 0s 14ms/step - loss: 0.5767 - accuracy: 0.7829 - val_loss: 0.3809 - val_accuracy: 0.8560\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.68 - ETA: 0s - loss: 0.5223 - accuracy: 0.75 - 0s 7ms/step - loss: 0.5177 - accuracy: 0.7669 - val_loss: 0.3956 - val_accuracy: 0.8240\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.71 - ETA: 0s - loss: 0.5432 - accuracy: 0.76 - 0s 10ms/step - loss: 0.5209 - accuracy: 0.7749 - val_loss: 0.4331 - val_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.81 - ETA: 0s - loss: 0.4773 - accuracy: 0.79 - 0s 9ms/step - loss: 0.5252 - accuracy: 0.7948 - val_loss: 0.4160 - val_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.71 - ETA: 0s - loss: 0.5963 - accuracy: 0.73 - ETA: 0s - loss: 0.5603 - accuracy: 0.75 - 0s 10ms/step - loss: 0.5548 - accuracy: 0.7510 - val_loss: 0.4109 - val_accuracy: 0.7920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 9bfc7cce6e456798fb3d68f653842352</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8560000061988831</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 9s - loss: 0.9609 - accuracy: 0.50 - ETA: 0s - loss: 1.9056 - accuracy: 0.55 - 1s 65ms/step - loss: 1.8016 - accuracy: 0.5837 - val_loss: 0.7310 - val_accuracy: 0.7360\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7872 - accuracy: 0.53 - 0s 5ms/step - loss: 1.2235 - accuracy: 0.6135 - val_loss: 0.6747 - val_accuracy: 0.6400\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7589 - accuracy: 0.53 - ETA: 0s - loss: 0.9890 - accuracy: 0.62 - 0s 8ms/step - loss: 0.9005 - accuracy: 0.6454 - val_loss: 0.6088 - val_accuracy: 0.7280\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9120 - accuracy: 0.46 - 0s 5ms/step - loss: 0.9277 - accuracy: 0.6355 - val_loss: 0.5881 - val_accuracy: 0.7280\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.59 - ETA: 0s - loss: 0.7531 - accuracy: 0.63 - 0s 15ms/step - loss: 0.7380 - accuracy: 0.6434 - val_loss: 0.5994 - val_accuracy: 0.7440\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7368 - accuracy: 0.59 - ETA: 0s - loss: 0.7546 - accuracy: 0.65 - 0s 19ms/step - loss: 0.7433 - accuracy: 0.6614 - val_loss: 0.5621 - val_accuracy: 0.7520\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0143 - accuracy: 0.53 - ETA: 0s - loss: 0.7398 - accuracy: 0.64 - 0s 10ms/step - loss: 0.7037 - accuracy: 0.6753 - val_loss: 0.5184 - val_accuracy: 0.7520\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6582 - accuracy: 0.59 - ETA: 0s - loss: 0.6743 - accuracy: 0.67 - 0s 7ms/step - loss: 0.6657 - accuracy: 0.6793 - val_loss: 0.5408 - val_accuracy: 0.7440\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9201 - accuracy: 0.56 - ETA: 0s - loss: 0.6734 - accuracy: 0.65 - 0s 8ms/step - loss: 0.6451 - accuracy: 0.6653 - val_loss: 0.5504 - val_accuracy: 0.7520\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7199 - accuracy: 0.56 - ETA: 0s - loss: 0.6565 - accuracy: 0.65 - 0s 18ms/step - loss: 0.6470 - accuracy: 0.6773 - val_loss: 0.5057 - val_accuracy: 0.7600\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7591 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6282 - accuracy: 0.7052 - val_loss: 0.5065 - val_accuracy: 0.7440\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7813 - accuracy: 0.53 - 0s 12ms/step - loss: 0.5823 - accuracy: 0.7052 - val_loss: 0.4964 - val_accuracy: 0.7840\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.62 - ETA: 0s - loss: 0.5843 - accuracy: 0.71 - 0s 8ms/step - loss: 0.5736 - accuracy: 0.7191 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6284 - accuracy: 0.68 - ETA: 0s - loss: 0.5743 - accuracy: 0.71 - 0s 8ms/step - loss: 0.5590 - accuracy: 0.7271 - val_loss: 0.4969 - val_accuracy: 0.7600\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7005 - accuracy: 0.65 - ETA: 0s - loss: 0.5708 - accuracy: 0.73 - 0s 16ms/step - loss: 0.5559 - accuracy: 0.7410 - val_loss: 0.4715 - val_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.65 - 0s 13ms/step - loss: 0.5461 - accuracy: 0.7550 - val_loss: 0.4826 - val_accuracy: 0.8080\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6054 - accuracy: 0.65 - 0s 6ms/step - loss: 0.5540 - accuracy: 0.7410 - val_loss: 0.4694 - val_accuracy: 0.7920\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7263 - accuracy: 0.71 - ETA: 0s - loss: 0.5606 - accuracy: 0.75 - 0s 8ms/step - loss: 0.5500 - accuracy: 0.7510 - val_loss: 0.4590 - val_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6668 - accuracy: 0.71 - ETA: 0s - loss: 0.5484 - accuracy: 0.74 - 0s 7ms/step - loss: 0.5385 - accuracy: 0.7450 - val_loss: 0.4538 - val_accuracy: 0.8080\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.68 - ETA: 0s - loss: 0.5651 - accuracy: 0.75 - 0s 8ms/step - loss: 0.5425 - accuracy: 0.7610 - val_loss: 0.4664 - val_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6404 - accuracy: 0.71 - ETA: 0s - loss: 0.5490 - accuracy: 0.74 - 0s 8ms/step - loss: 0.5363 - accuracy: 0.7510 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.65 - ETA: 0s - loss: 0.5486 - accuracy: 0.75 - 0s 9ms/step - loss: 0.5294 - accuracy: 0.7610 - val_loss: 0.4752 - val_accuracy: 0.7920\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6052 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7450 - val_loss: 0.4735 - val_accuracy: 0.7920\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.62 - ETA: 0s - loss: 0.5404 - accuracy: 0.73 - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7390 - val_loss: 0.4684 - val_accuracy: 0.8080\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5485 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7610 - val_loss: 0.4527 - val_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7669 - val_loss: 0.4308 - val_accuracy: 0.8080\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.71 - ETA: 0s - loss: 0.5368 - accuracy: 0.76 - 0s 15ms/step - loss: 0.5326 - accuracy: 0.7629 - val_loss: 0.4228 - val_accuracy: 0.8320\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7709 - val_loss: 0.3934 - val_accuracy: 0.8160\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5779 - accuracy: 0.75 - ETA: 0s - loss: 0.4883 - accuracy: 0.77 - 0s 8ms/step - loss: 0.4815 - accuracy: 0.7809 - val_loss: 0.4112 - val_accuracy: 0.8160\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.71 - ETA: 0s - loss: 0.4833 - accuracy: 0.79 - 0s 8ms/step - loss: 0.4755 - accuracy: 0.7908 - val_loss: 0.4288 - val_accuracy: 0.8160\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5816 - accuracy: 0.68 - ETA: 0s - loss: 0.5148 - accuracy: 0.75 - 0s 8ms/step - loss: 0.5000 - accuracy: 0.7629 - val_loss: 0.4141 - val_accuracy: 0.8080\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.71 - ETA: 0s - loss: 0.4860 - accuracy: 0.78 - 0s 8ms/step - loss: 0.4737 - accuracy: 0.7888 - val_loss: 0.4043 - val_accuracy: 0.8160\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7849 - val_loss: 0.4712 - val_accuracy: 0.8080\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.68 - ETA: 0s - loss: 0.5098 - accuracy: 0.76 - 0s 7ms/step - loss: 0.4894 - accuracy: 0.7749 - val_loss: 0.4401 - val_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.68 - ETA: 0s - loss: 0.5107 - accuracy: 0.77 - 0s 8ms/step - loss: 0.4886 - accuracy: 0.7769 - val_loss: 0.4022 - val_accuracy: 0.8240\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5151 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7888 - val_loss: 0.3837 - val_accuracy: 0.8320\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7948 - val_loss: 0.4028 - val_accuracy: 0.8320\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.71 - ETA: 0s - loss: 0.4734 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7928 - val_loss: 0.3938 - val_accuracy: 0.8240\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7988 - val_loss: 0.4060 - val_accuracy: 0.8160\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7968 - val_loss: 0.4067 - val_accuracy: 0.8240\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4539 - accuracy: 0.8028 - val_loss: 0.3951 - val_accuracy: 0.8240\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7908 - val_loss: 0.3938 - val_accuracy: 0.8240\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.68 - 0s 15ms/step - loss: 0.4363 - accuracy: 0.7948 - val_loss: 0.3965 - val_accuracy: 0.8400\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.71 - ETA: 0s - loss: 0.4735 - accuracy: 0.79 - 0s 8ms/step - loss: 0.4657 - accuracy: 0.7988 - val_loss: 0.3693 - val_accuracy: 0.8400\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.81 - ETA: 0s - loss: 0.4677 - accuracy: 0.80 - 0s 8ms/step - loss: 0.4565 - accuracy: 0.8088 - val_loss: 0.3961 - val_accuracy: 0.8240\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6315 - accuracy: 0.71 - ETA: 0s - loss: 0.4926 - accuracy: 0.78 - 0s 8ms/step - loss: 0.4682 - accuracy: 0.7968 - val_loss: 0.4272 - val_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5837 - accuracy: 0.68 - ETA: 0s - loss: 0.4825 - accuracy: 0.80 - 0s 8ms/step - loss: 0.4679 - accuracy: 0.7928 - val_loss: 0.4071 - val_accuracy: 0.8400\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5220 - accuracy: 0.71 - ETA: 0s - loss: 0.4568 - accuracy: 0.78 - 0s 8ms/step - loss: 0.4499 - accuracy: 0.7948 - val_loss: 0.3815 - val_accuracy: 0.8400\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.75 - ETA: 0s - loss: 0.4489 - accuracy: 0.79 - 0s 8ms/step - loss: 0.4380 - accuracy: 0.8028 - val_loss: 0.3768 - val_accuracy: 0.8400\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8068 - val_loss: 0.3957 - val_accuracy: 0.8400\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.71 - 0s 12ms/step - loss: 0.4552 - accuracy: 0.8167 - val_loss: 0.3777 - val_accuracy: 0.8480\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4643 - accuracy: 0.81 - ETA: 0s - loss: 0.4586 - accuracy: 0.81 - 0s 7ms/step - loss: 0.4552 - accuracy: 0.8127 - val_loss: 0.3728 - val_accuracy: 0.8400\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5861 - accuracy: 0.78 - ETA: 0s - loss: 0.4462 - accuracy: 0.80 - 0s 8ms/step - loss: 0.4329 - accuracy: 0.8127 - val_loss: 0.4042 - val_accuracy: 0.8400\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.71 - ETA: 0s - loss: 0.4628 - accuracy: 0.81 - 0s 7ms/step - loss: 0.4441 - accuracy: 0.8167 - val_loss: 0.4055 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: dab0bdfa5497b700f0de27abbeb6583b</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8479999899864197</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 12s - loss: 0.8380 - accuracy: 0.468 - 1s 73ms/step - loss: 0.7847 - accuracy: 0.4562 - val_loss: 0.5529 - val_accuracy: 0.7600\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7233 - accuracy: 0.68 - 0s 11ms/step - loss: 0.6661 - accuracy: 0.6594 - val_loss: 0.5548 - val_accuracy: 0.7920\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.62 - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6574 - val_loss: 0.5648 - val_accuracy: 0.7840\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8327 - accuracy: 0.53 - 0s 4ms/step - loss: 0.6146 - accuracy: 0.6733 - val_loss: 0.5494 - val_accuracy: 0.7920\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7445 - accuracy: 0.56 - 0s 12ms/step - loss: 0.5928 - accuracy: 0.6932 - val_loss: 0.5261 - val_accuracy: 0.8160\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6692 - accuracy: 0.62 - ETA: 0s - loss: 0.5832 - accuracy: 0.73 - 0s 8ms/step - loss: 0.5692 - accuracy: 0.7371 - val_loss: 0.4972 - val_accuracy: 0.7920\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.59 - 0s 4ms/step - loss: 0.5698 - accuracy: 0.7191 - val_loss: 0.4892 - val_accuracy: 0.8080\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.62 - ETA: 0s - loss: 0.5724 - accuracy: 0.74 - 0s 6ms/step - loss: 0.5774 - accuracy: 0.7331 - val_loss: 0.4988 - val_accuracy: 0.8160\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5786 - accuracy: 0.71 - ETA: 0s - loss: 0.5589 - accuracy: 0.73 - 0s 7ms/step - loss: 0.5452 - accuracy: 0.7331 - val_loss: 0.4982 - val_accuracy: 0.8080\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6231 - accuracy: 0.68 - ETA: 0s - loss: 0.5360 - accuracy: 0.74 - 0s 18ms/step - loss: 0.5197 - accuracy: 0.7490 - val_loss: 0.4843 - val_accuracy: 0.8240\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.68 - 0s 5ms/step - loss: 0.5165 - accuracy: 0.7530 - val_loss: 0.4635 - val_accuracy: 0.8080\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7510 - val_loss: 0.4691 - val_accuracy: 0.7920\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.71 - ETA: 0s - loss: 0.5026 - accuracy: 0.77 - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7769 - val_loss: 0.4601 - val_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.81 - ETA: 0s - loss: 0.4639 - accuracy: 0.79 - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7928 - val_loss: 0.4454 - val_accuracy: 0.8160\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.68 - ETA: 0s - loss: 0.4748 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4811 - accuracy: 0.7769 - val_loss: 0.4303 - val_accuracy: 0.8080\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5998 - accuracy: 0.78 - ETA: 0s - loss: 0.5004 - accuracy: 0.76 - 0s 15ms/step - loss: 0.4964 - accuracy: 0.7649 - val_loss: 0.4128 - val_accuracy: 0.8400\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7888 - val_loss: 0.4112 - val_accuracy: 0.8240\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4821 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7869 - val_loss: 0.4028 - val_accuracy: 0.8240\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7869 - val_loss: 0.4112 - val_accuracy: 0.8240\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.78 - 0s 11ms/step - loss: 0.4671 - accuracy: 0.7948 - val_loss: 0.4059 - val_accuracy: 0.8480\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7888 - val_loss: 0.4215 - val_accuracy: 0.8080\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7888 - val_loss: 0.3980 - val_accuracy: 0.8160\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4548 - accuracy: 0.8048 - val_loss: 0.3889 - val_accuracy: 0.8480\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.78 - 0s 11ms/step - loss: 0.4640 - accuracy: 0.7928 - val_loss: 0.3751 - val_accuracy: 0.8560\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.81 - ETA: 0s - loss: 0.4674 - accuracy: 0.81 - 0s 7ms/step - loss: 0.4672 - accuracy: 0.8068 - val_loss: 0.3914 - val_accuracy: 0.8240\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.71 - ETA: 0s - loss: 0.4692 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4676 - accuracy: 0.7888 - val_loss: 0.3634 - val_accuracy: 0.8480\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.78 - ETA: 0s - loss: 0.4585 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4570 - accuracy: 0.7888 - val_loss: 0.3663 - val_accuracy: 0.8480\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.75 - ETA: 0s - loss: 0.4401 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4426 - accuracy: 0.7829 - val_loss: 0.3737 - val_accuracy: 0.8400\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.75 - ETA: 0s - loss: 0.4531 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7988 - val_loss: 0.3979 - val_accuracy: 0.8160\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4736 - accuracy: 0.75 - ETA: 0s - loss: 0.4390 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4320 - accuracy: 0.8008 - val_loss: 0.3737 - val_accuracy: 0.8560\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.78 - ETA: 0s - loss: 0.4411 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4309 - accuracy: 0.7968 - val_loss: 0.3670 - val_accuracy: 0.8560\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.78 - ETA: 0s - loss: 0.4398 - accuracy: 0.81 - 0s 7ms/step - loss: 0.4435 - accuracy: 0.8108 - val_loss: 0.3776 - val_accuracy: 0.8400\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.78 - ETA: 0s - loss: 0.4509 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4557 - accuracy: 0.7869 - val_loss: 0.3647 - val_accuracy: 0.8560\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.81 - ETA: 0s - loss: 0.4393 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7968 - val_loss: 0.3687 - val_accuracy: 0.8480\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.87 - ETA: 0s - loss: 0.4489 - accuracy: 0.79 - 0s 8ms/step - loss: 0.4486 - accuracy: 0.7869 - val_loss: 0.3676 - val_accuracy: 0.8480\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4660 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4375 - accuracy: 0.8048 - val_loss: 0.3735 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 47b7603c456df2afc7c11da0f8409641</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8560000061988831</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 1024</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 12s - loss: 1.8220 - accuracy: 0.531 - ETA: 1s - loss: 1.4317 - accuracy: 0.631 - ETA: 0s - loss: 1.9808 - accuracy: 0.56 - ETA: 0s - loss: 2.2768 - accuracy: 0.56 - 1s 94ms/step - loss: 2.2649 - accuracy: 0.5757 - val_loss: 0.7732 - val_accuracy: 0.7120\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.6241 - accuracy: 0.40 - ETA: 0s - loss: 1.8468 - accuracy: 0.56 - ETA: 0s - loss: 1.8328 - accuracy: 0.56 - ETA: 0s - loss: 1.7260 - accuracy: 0.54 - 1s 33ms/step - loss: 1.6490 - accuracy: 0.5518 - val_loss: 0.5617 - val_accuracy: 0.7440\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1990 - accuracy: 0.53 - ETA: 0s - loss: 0.8792 - accuracy: 0.67 - ETA: 0s - loss: 1.0108 - accuracy: 0.67 - ETA: 0s - loss: 1.1893 - accuracy: 0.64 - 0s 19ms/step - loss: 1.3212 - accuracy: 0.6295 - val_loss: 0.5879 - val_accuracy: 0.7280\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9900 - accuracy: 0.56 - ETA: 0s - loss: 1.3355 - accuracy: 0.58 - ETA: 0s - loss: 1.4173 - accuracy: 0.59 - ETA: 0s - loss: 1.3705 - accuracy: 0.60 - 0s 15ms/step - loss: 1.3545 - accuracy: 0.6076 - val_loss: 0.7144 - val_accuracy: 0.7040\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9282 - accuracy: 0.56 - ETA: 0s - loss: 1.1771 - accuracy: 0.60 - ETA: 0s - loss: 1.1837 - accuracy: 0.60 - ETA: 0s - loss: 1.1489 - accuracy: 0.60 - 0s 18ms/step - loss: 1.1329 - accuracy: 0.5956 - val_loss: 0.7077 - val_accuracy: 0.6640\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4963 - accuracy: 0.37 - ETA: 0s - loss: 1.0316 - accuracy: 0.52 - ETA: 0s - loss: 1.0503 - accuracy: 0.56 - ETA: 0s - loss: 1.0720 - accuracy: 0.56 - 0s 15ms/step - loss: 1.0064 - accuracy: 0.5797 - val_loss: 0.6060 - val_accuracy: 0.7200\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8461 - accuracy: 0.46 - ETA: 0s - loss: 1.1023 - accuracy: 0.44 - ETA: 0s - loss: 0.9301 - accuracy: 0.54 - ETA: 0s - loss: 0.9680 - accuracy: 0.55 - 0s 16ms/step - loss: 0.9376 - accuracy: 0.5697 - val_loss: 0.5580 - val_accuracy: 0.7120\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8925 - accuracy: 0.53 - ETA: 0s - loss: 0.8265 - accuracy: 0.58 - ETA: 0s - loss: 0.8623 - accuracy: 0.58 - ETA: 0s - loss: 0.8638 - accuracy: 0.58 - 0s 15ms/step - loss: 0.8979 - accuracy: 0.5916 - val_loss: 0.5634 - val_accuracy: 0.7120\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0612 - accuracy: 0.46 - ETA: 0s - loss: 0.9767 - accuracy: 0.55 - ETA: 0s - loss: 0.9513 - accuracy: 0.60 - ETA: 0s - loss: 0.9596 - accuracy: 0.59 - 0s 16ms/step - loss: 0.8942 - accuracy: 0.6135 - val_loss: 0.5867 - val_accuracy: 0.7360\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0091 - accuracy: 0.43 - ETA: 0s - loss: 0.8052 - accuracy: 0.59 - ETA: 0s - loss: 0.8660 - accuracy: 0.61 - ETA: 0s - loss: 0.8352 - accuracy: 0.62 - 0s 14ms/step - loss: 0.8259 - accuracy: 0.6255 - val_loss: 0.5767 - val_accuracy: 0.6880\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1342 - accuracy: 0.59 - ETA: 0s - loss: 0.8443 - accuracy: 0.61 - ETA: 0s - loss: 0.8791 - accuracy: 0.61 - ETA: 0s - loss: 0.9001 - accuracy: 0.62 - 0s 16ms/step - loss: 0.8644 - accuracy: 0.6394 - val_loss: 0.5787 - val_accuracy: 0.7280\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.62 - ETA: 0s - loss: 0.8011 - accuracy: 0.63 - ETA: 0s - loss: 0.8151 - accuracy: 0.65 - ETA: 0s - loss: 0.8666 - accuracy: 0.62 - 0s 16ms/step - loss: 0.8181 - accuracy: 0.6355 - val_loss: 0.5766 - val_accuracy: 0.7200\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2976 - accuracy: 0.50 - ETA: 0s - loss: 0.8793 - accuracy: 0.59 - ETA: 0s - loss: 0.9949 - accuracy: 0.60 - ETA: 0s - loss: 0.9372 - accuracy: 0.63 - 0s 16ms/step - loss: 0.8638 - accuracy: 0.6554 - val_loss: 0.5929 - val_accuracy: 0.7280\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1646 - accuracy: 0.46 - ETA: 0s - loss: 0.8818 - accuracy: 0.60 - ETA: 0s - loss: 0.7822 - accuracy: 0.64 - ETA: 0s - loss: 0.7949 - accuracy: 0.62 - 1s 35ms/step - loss: 0.7640 - accuracy: 0.6434 - val_loss: 0.5349 - val_accuracy: 0.7920\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8698 - accuracy: 0.43 - ETA: 0s - loss: 0.7403 - accuracy: 0.59 - ETA: 0s - loss: 0.7570 - accuracy: 0.62 - ETA: 0s - loss: 0.7685 - accuracy: 0.63 - 0s 19ms/step - loss: 0.7579 - accuracy: 0.6235 - val_loss: 0.5512 - val_accuracy: 0.7200\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9165 - accuracy: 0.65 - ETA: 0s - loss: 0.7339 - accuracy: 0.62 - ETA: 0s - loss: 0.7305 - accuracy: 0.62 - ETA: 0s - loss: 0.7387 - accuracy: 0.61 - 0s 14ms/step - loss: 0.7355 - accuracy: 0.6215 - val_loss: 0.5588 - val_accuracy: 0.7840\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9097 - accuracy: 0.50 - ETA: 0s - loss: 0.7185 - accuracy: 0.61 - ETA: 0s - loss: 0.6877 - accuracy: 0.64 - ETA: 0s - loss: 0.7054 - accuracy: 0.64 - 0s 16ms/step - loss: 0.6760 - accuracy: 0.6494 - val_loss: 0.5202 - val_accuracy: 0.7280\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2576 - accuracy: 0.53 - ETA: 0s - loss: 0.8042 - accuracy: 0.62 - ETA: 0s - loss: 0.7279 - accuracy: 0.64 - ETA: 0s - loss: 0.7038 - accuracy: 0.63 - 0s 15ms/step - loss: 0.6860 - accuracy: 0.6534 - val_loss: 0.5673 - val_accuracy: 0.7280\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6561 - accuracy: 0.59 - ETA: 0s - loss: 0.6950 - accuracy: 0.60 - ETA: 0s - loss: 0.6715 - accuracy: 0.62 - ETA: 0s - loss: 0.6869 - accuracy: 0.62 - ETA: 0s - loss: 0.6830 - accuracy: 0.63 - 0s 19ms/step - loss: 0.6780 - accuracy: 0.6394 - val_loss: 0.5351 - val_accuracy: 0.7200\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9461 - accuracy: 0.53 - ETA: 0s - loss: 0.7304 - accuracy: 0.63 - ETA: 0s - loss: 0.6984 - accuracy: 0.63 - ETA: 0s - loss: 0.7065 - accuracy: 0.63 - 0s 15ms/step - loss: 0.6973 - accuracy: 0.6355 - val_loss: 0.5613 - val_accuracy: 0.7680\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8865 - accuracy: 0.62 - ETA: 0s - loss: 0.6651 - accuracy: 0.63 - ETA: 0s - loss: 0.6646 - accuracy: 0.64 - ETA: 0s - loss: 0.6706 - accuracy: 0.62 - 0s 15ms/step - loss: 0.6541 - accuracy: 0.6355 - val_loss: 0.5585 - val_accuracy: 0.7200\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.53 - ETA: 0s - loss: 0.6678 - accuracy: 0.64 - ETA: 0s - loss: 0.6682 - accuracy: 0.64 - ETA: 0s - loss: 0.6455 - accuracy: 0.66 - 0s 15ms/step - loss: 0.6331 - accuracy: 0.6693 - val_loss: 0.5265 - val_accuracy: 0.7120\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7909 - accuracy: 0.53 - ETA: 0s - loss: 0.6236 - accuracy: 0.64 - ETA: 0s - loss: 0.6314 - accuracy: 0.64 - ETA: 0s - loss: 0.6273 - accuracy: 0.65 - 0s 15ms/step - loss: 0.6255 - accuracy: 0.6574 - val_loss: 0.5548 - val_accuracy: 0.7440\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8329 - accuracy: 0.46 - ETA: 0s - loss: 0.6538 - accuracy: 0.60 - ETA: 0s - loss: 0.6815 - accuracy: 0.61 - ETA: 0s - loss: 0.6827 - accuracy: 0.64 - 0s 14ms/step - loss: 0.6493 - accuracy: 0.6614 - val_loss: 0.5467 - val_accuracy: 0.7280\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.62 - ETA: 0s - loss: 0.6449 - accuracy: 0.62 - ETA: 0s - loss: 0.6410 - accuracy: 0.64 - ETA: 0s - loss: 0.6359 - accuracy: 0.65 - 0s 14ms/step - loss: 0.6322 - accuracy: 0.6494 - val_loss: 0.5370 - val_accuracy: 0.7520\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7366 - accuracy: 0.62 - ETA: 0s - loss: 0.6023 - accuracy: 0.67 - ETA: 0s - loss: 0.6104 - accuracy: 0.65 - ETA: 0s - loss: 0.6217 - accuracy: 0.64 - 0s 14ms/step - loss: 0.6737 - accuracy: 0.6394 - val_loss: 0.5286 - val_accuracy: 0.7200\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.62 - ETA: 0s - loss: 0.6609 - accuracy: 0.60 - ETA: 0s - loss: 0.6375 - accuracy: 0.64 - ETA: 0s - loss: 0.6529 - accuracy: 0.64 - 0s 16ms/step - loss: 0.6285 - accuracy: 0.6534 - val_loss: 0.5203 - val_accuracy: 0.7280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: a921de5028721866fd864a252c878224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7919999957084656</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 1024</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 11s - loss: 0.7729 - accuracy: 0.437 - 1s 69ms/step - loss: 0.8227 - accuracy: 0.4124 - val_loss: 0.7421 - val_accuracy: 0.3200\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6051 - accuracy: 0.62 - 0s 11ms/step - loss: 0.7109 - accuracy: 0.5398 - val_loss: 0.6315 - val_accuracy: 0.7200\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7414 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5857 - val_loss: 0.6237 - val_accuracy: 0.7200\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7892 - accuracy: 0.56 - 0s 3ms/step - loss: 0.6860 - accuracy: 0.6295 - val_loss: 0.6294 - val_accuracy: 0.7120\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8777 - accuracy: 0.56 - 0s 3ms/step - loss: 0.6471 - accuracy: 0.6414 - val_loss: 0.6207 - val_accuracy: 0.7120\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6408 - accuracy: 0.56 - 0s 12ms/step - loss: 0.6240 - accuracy: 0.6713 - val_loss: 0.6140 - val_accuracy: 0.7280\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.59 - 0s 12ms/step - loss: 0.6427 - accuracy: 0.6554 - val_loss: 0.5925 - val_accuracy: 0.7680\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6731 - accuracy: 0.62 - 0s 11ms/step - loss: 0.6189 - accuracy: 0.6653 - val_loss: 0.5755 - val_accuracy: 0.7760\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5886 - accuracy: 0.65 - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6813 - val_loss: 0.5612 - val_accuracy: 0.7680\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8023 - accuracy: 0.59 - 0s 3ms/step - loss: 0.5950 - accuracy: 0.6932 - val_loss: 0.5601 - val_accuracy: 0.7040\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.56 - 0s 3ms/step - loss: 0.6110 - accuracy: 0.6773 - val_loss: 0.5249 - val_accuracy: 0.7760\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5833 - accuracy: 0.68 - 0s 12ms/step - loss: 0.5853 - accuracy: 0.7072 - val_loss: 0.5116 - val_accuracy: 0.7920\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.53 - 0s 14ms/step - loss: 0.5648 - accuracy: 0.7131 - val_loss: 0.4933 - val_accuracy: 0.8320\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7793 - accuracy: 0.62 - ETA: 0s - loss: 0.5944 - accuracy: 0.70 - 0s 7ms/step - loss: 0.5879 - accuracy: 0.7012 - val_loss: 0.4705 - val_accuracy: 0.8240\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.59 - 0s 5ms/step - loss: 0.5692 - accuracy: 0.7390 - val_loss: 0.4628 - val_accuracy: 0.8160\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.59 - 0s 6ms/step - loss: 0.5467 - accuracy: 0.7311 - val_loss: 0.4625 - val_accuracy: 0.8240\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.68 - 0s 11ms/step - loss: 0.5320 - accuracy: 0.7430 - val_loss: 0.4619 - val_accuracy: 0.8480\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7028 - accuracy: 0.62 - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7371 - val_loss: 0.4589 - val_accuracy: 0.8320\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6744 - accuracy: 0.68 - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7430 - val_loss: 0.4504 - val_accuracy: 0.8240\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5283 - accuracy: 0.7390 - val_loss: 0.4486 - val_accuracy: 0.8480\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.71 - 0s 15ms/step - loss: 0.5225 - accuracy: 0.7570 - val_loss: 0.4359 - val_accuracy: 0.8560\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5533 - accuracy: 0.81 - ETA: 0s - loss: 0.5190 - accuracy: 0.75 - 0s 7ms/step - loss: 0.5218 - accuracy: 0.7550 - val_loss: 0.4329 - val_accuracy: 0.8560\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6730 - accuracy: 0.56 - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7550 - val_loss: 0.4257 - val_accuracy: 0.8560\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7490 - val_loss: 0.4437 - val_accuracy: 0.8480\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6058 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7629 - val_loss: 0.4699 - val_accuracy: 0.8240\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.62 - 0s 14ms/step - loss: 0.5130 - accuracy: 0.7371 - val_loss: 0.4124 - val_accuracy: 0.8720\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7649 - val_loss: 0.4096 - val_accuracy: 0.8560\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4817 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7749 - val_loss: 0.3967 - val_accuracy: 0.8640\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5748 - accuracy: 0.78 - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7809 - val_loss: 0.4133 - val_accuracy: 0.8160\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.75 - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7749 - val_loss: 0.3992 - val_accuracy: 0.8320\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.84 - 0s 7ms/step - loss: 0.4765 - accuracy: 0.7809 - val_loss: 0.3885 - val_accuracy: 0.8400\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.81 - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7669 - val_loss: 0.4025 - val_accuracy: 0.8400\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5868 - accuracy: 0.68 - ETA: 0s - loss: 0.5028 - accuracy: 0.77 - 0s 7ms/step - loss: 0.5028 - accuracy: 0.7749 - val_loss: 0.4010 - val_accuracy: 0.8480\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4305 - accuracy: 0.87 - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7928 - val_loss: 0.3845 - val_accuracy: 0.8320\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.62 - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7769 - val_loss: 0.4023 - val_accuracy: 0.8400\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5364 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4578 - accuracy: 0.8008 - val_loss: 0.3880 - val_accuracy: 0.8240\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7769 - val_loss: 0.4008 - val_accuracy: 0.8240\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.65 - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7749 - val_loss: 0.3970 - val_accuracy: 0.8400\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4813 - accuracy: 0.7729 - val_loss: 0.3860 - val_accuracy: 0.8400\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.78 - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7888 - val_loss: 0.3861 - val_accuracy: 0.8480\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7689 - val_loss: 0.4045 - val_accuracy: 0.8240\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.71 - ETA: 0s - loss: 0.4684 - accuracy: 0.76 - 0s 7ms/step - loss: 0.4689 - accuracy: 0.7709 - val_loss: 0.3836 - val_accuracy: 0.8320\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7829 - val_loss: 0.3797 - val_accuracy: 0.8560\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.75 - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7689 - val_loss: 0.3741 - val_accuracy: 0.8480\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4751 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7829 - val_loss: 0.3720 - val_accuracy: 0.8480\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7749 - val_loss: 0.3627 - val_accuracy: 0.8320\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.68 - ETA: 0s - loss: 0.4573 - accuracy: 0.78 - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7888 - val_loss: 0.3528 - val_accuracy: 0.8480\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5086 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7948 - val_loss: 0.3521 - val_accuracy: 0.8480\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7669 - val_loss: 0.3616 - val_accuracy: 0.8640\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4374 - accuracy: 0.7968 - val_loss: 0.3613 - val_accuracy: 0.8480\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.78 - 0s 6ms/step - loss: 0.4532 - accuracy: 0.8048 - val_loss: 0.3671 - val_accuracy: 0.8400\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5399 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7928 - val_loss: 0.3677 - val_accuracy: 0.8320\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.78 - 0s 6ms/step - loss: 0.4539 - accuracy: 0.8008 - val_loss: 0.3730 - val_accuracy: 0.8400\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.75 - ETA: 0s - loss: 0.4857 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4893 - accuracy: 0.7749 - val_loss: 0.3545 - val_accuracy: 0.8400\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.71 - ETA: 0s - loss: 0.4428 - accuracy: 0.79 - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7968 - val_loss: 0.3567 - val_accuracy: 0.8400\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7709 - val_loss: 0.3772 - val_accuracy: 0.8160\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7789 - val_loss: 0.3840 - val_accuracy: 0.8160\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5315 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7988 - val_loss: 0.3733 - val_accuracy: 0.8320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: edfb55fded12f9be2894e0abd39c7993</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.871999979019165</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 10s - loss: 2.8875 - accuracy: 0.437 - 1s 73ms/step - loss: 2.6598 - accuracy: 0.5518 - val_loss: 1.2813 - val_accuracy: 0.6560\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.2290 - accuracy: 0.43 - 0s 23ms/step - loss: 2.0837 - accuracy: 0.6096 - val_loss: 0.6854 - val_accuracy: 0.7280\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.3646 - accuracy: 0.46 - 0s 5ms/step - loss: 1.9997 - accuracy: 0.5538 - val_loss: 0.7728 - val_accuracy: 0.6640\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7259 - accuracy: 0.40 - ETA: 0s - loss: 1.4617 - accuracy: 0.58 - 0s 8ms/step - loss: 1.6692 - accuracy: 0.5797 - val_loss: 0.5508 - val_accuracy: 0.7280\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.7746 - accuracy: 0.53 - ETA: 0s - loss: 1.6336 - accuracy: 0.63 - 0s 7ms/step - loss: 1.6400 - accuracy: 0.6096 - val_loss: 0.7814 - val_accuracy: 0.7120\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.1272 - accuracy: 0.53 - 0s 5ms/step - loss: 1.5897 - accuracy: 0.5916 - val_loss: 0.6387 - val_accuracy: 0.7200\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3146 - accuracy: 0.40 - ETA: 0s - loss: 1.3655 - accuracy: 0.57 - 0s 7ms/step - loss: 1.3099 - accuracy: 0.5837 - val_loss: 0.7561 - val_accuracy: 0.7040\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5784 - accuracy: 0.50 - 0s 24ms/step - loss: 1.5171 - accuracy: 0.5618 - val_loss: 0.5218 - val_accuracy: 0.7600\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.8306 - accuracy: 0.59 - 0s 6ms/step - loss: 1.4216 - accuracy: 0.6135 - val_loss: 0.6169 - val_accuracy: 0.7280\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9601 - accuracy: 0.53 - 0s 4ms/step - loss: 1.2348 - accuracy: 0.5677 - val_loss: 0.5521 - val_accuracy: 0.7280\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3658 - accuracy: 0.56 - 0s 5ms/step - loss: 0.9376 - accuracy: 0.6335 - val_loss: 0.5667 - val_accuracy: 0.7120\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2131 - accuracy: 0.56 - ETA: 0s - loss: 1.2052 - accuracy: 0.55 - 0s 7ms/step - loss: 1.0750 - accuracy: 0.5936 - val_loss: 0.5522 - val_accuracy: 0.7280\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7424 - accuracy: 0.65 - ETA: 0s - loss: 0.8917 - accuracy: 0.63 - 0s 7ms/step - loss: 0.9325 - accuracy: 0.6235 - val_loss: 0.5639 - val_accuracy: 0.7200\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9407 - accuracy: 0.56 - ETA: 0s - loss: 0.9221 - accuracy: 0.63 - 0s 8ms/step - loss: 0.9074 - accuracy: 0.6355 - val_loss: 0.5734 - val_accuracy: 0.7200\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7704 - accuracy: 0.59 - ETA: 0s - loss: 0.8987 - accuracy: 0.61 - 0s 7ms/step - loss: 0.9028 - accuracy: 0.6315 - val_loss: 0.5479 - val_accuracy: 0.7280\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4480 - accuracy: 0.50 - 0s 4ms/step - loss: 1.0011 - accuracy: 0.5916 - val_loss: 0.5835 - val_accuracy: 0.7200\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0.56 - 0s 5ms/step - loss: 0.8578 - accuracy: 0.6016 - val_loss: 0.5753 - val_accuracy: 0.7200\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5397 - accuracy: 0.50 - ETA: 0s - loss: 0.7899 - accuracy: 0.64 - 0s 6ms/step - loss: 0.7985 - accuracy: 0.6414 - val_loss: 0.5539 - val_accuracy: 0.7120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 9b08d43bf5d3a27ff8a6ed760e7516ee</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7599999904632568</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 1024</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 8s - loss: 2.4588 - accuracy: 0.50 - 1s 54ms/step - loss: 1.7904 - accuracy: 0.5159 - val_loss: 0.6844 - val_accuracy: 0.6640\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3218 - accuracy: 0.46 - 0s 11ms/step - loss: 1.5202 - accuracy: 0.6215 - val_loss: 0.6585 - val_accuracy: 0.6800\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3669 - accuracy: 0.50 - 0s 12ms/step - loss: 1.5975 - accuracy: 0.5956 - val_loss: 0.5463 - val_accuracy: 0.7040\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.2282 - accuracy: 0.53 - 0s 11ms/step - loss: 1.4524 - accuracy: 0.5717 - val_loss: 0.6391 - val_accuracy: 0.7200\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4539 - accuracy: 0.46 - 0s 6ms/step - loss: 1.2468 - accuracy: 0.5757 - val_loss: 0.5371 - val_accuracy: 0.6960\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0626 - accuracy: 0.56 - 0s 6ms/step - loss: 1.1002 - accuracy: 0.6235 - val_loss: 0.5279 - val_accuracy: 0.7040\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5131 - accuracy: 0.40 - 0s 6ms/step - loss: 1.3126 - accuracy: 0.5797 - val_loss: 0.4839 - val_accuracy: 0.7200\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4418 - accuracy: 0.40 - 0s 4ms/step - loss: 1.1110 - accuracy: 0.6076 - val_loss: 0.5112 - val_accuracy: 0.7200\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9674 - accuracy: 0.56 - 0s 12ms/step - loss: 1.1470 - accuracy: 0.6175 - val_loss: 0.5367 - val_accuracy: 0.7360\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7376 - accuracy: 0.62 - 0s 14ms/step - loss: 1.1157 - accuracy: 0.6335 - val_loss: 0.4896 - val_accuracy: 0.7440\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.62 - 0s 15ms/step - loss: 1.0350 - accuracy: 0.6315 - val_loss: 0.4915 - val_accuracy: 0.7680\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0276 - accuracy: 0.56 - 0s 12ms/step - loss: 1.0026 - accuracy: 0.6175 - val_loss: 0.4498 - val_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2645 - accuracy: 0.50 - 0s 5ms/step - loss: 0.9779 - accuracy: 0.6474 - val_loss: 0.4594 - val_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3131 - accuracy: 0.43 - 0s 6ms/step - loss: 1.1022 - accuracy: 0.6096 - val_loss: 0.4793 - val_accuracy: 0.7440\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.56 - ETA: 0s - loss: 0.9943 - accuracy: 0.64 - 0s 7ms/step - loss: 1.0031 - accuracy: 0.6394 - val_loss: 0.4566 - val_accuracy: 0.7520\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3785 - accuracy: 0.65 - 0s 12ms/step - loss: 1.0135 - accuracy: 0.6753 - val_loss: 0.4386 - val_accuracy: 0.8080\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5142 - accuracy: 0.46 - 0s 5ms/step - loss: 0.8727 - accuracy: 0.6514 - val_loss: 0.4349 - val_accuracy: 0.7920\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1603 - accuracy: 0.40 - 0s 3ms/step - loss: 0.8640 - accuracy: 0.6574 - val_loss: 0.5064 - val_accuracy: 0.7440\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7178 - accuracy: 0.46 - 0s 3ms/step - loss: 0.8453 - accuracy: 0.6394 - val_loss: 0.4352 - val_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3773 - accuracy: 0.56 - 0s 6ms/step - loss: 0.9256 - accuracy: 0.6713 - val_loss: 0.4464 - val_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7344 - accuracy: 0.56 - ETA: 0s - loss: 0.7471 - accuracy: 0.68 - 0s 5ms/step - loss: 0.7640 - accuracy: 0.6853 - val_loss: 0.4360 - val_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.65 - 0s 4ms/step - loss: 0.7706 - accuracy: 0.6873 - val_loss: 0.4537 - val_accuracy: 0.7760\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0774 - accuracy: 0.59 - 0s 5ms/step - loss: 0.8041 - accuracy: 0.6633 - val_loss: 0.4447 - val_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7495 - accuracy: 0.62 - 0s 6ms/step - loss: 0.7797 - accuracy: 0.6833 - val_loss: 0.4262 - val_accuracy: 0.7840\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.65 - 0s 4ms/step - loss: 0.7754 - accuracy: 0.6793 - val_loss: 0.4250 - val_accuracy: 0.7840\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.56 - 0s 14ms/step - loss: 0.8177 - accuracy: 0.6813 - val_loss: 0.4183 - val_accuracy: 0.8160\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7591 - accuracy: 0.56 - 0s 6ms/step - loss: 0.8061 - accuracy: 0.7032 - val_loss: 0.4658 - val_accuracy: 0.7600\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0343 - accuracy: 0.59 - 0s 4ms/step - loss: 0.7495 - accuracy: 0.7052 - val_loss: 0.4000 - val_accuracy: 0.8160\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2442 - accuracy: 0.62 - 0s 6ms/step - loss: 0.6797 - accuracy: 0.7131 - val_loss: 0.4189 - val_accuracy: 0.8080\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2732 - accuracy: 0.46 - 0s 6ms/step - loss: 0.7408 - accuracy: 0.7231 - val_loss: 0.4205 - val_accuracy: 0.7840\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8969 - accuracy: 0.50 - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6972 - val_loss: 0.4218 - val_accuracy: 0.7760\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.65 - 0s 9ms/step - loss: 0.6794 - accuracy: 0.7191 - val_loss: 0.3999 - val_accuracy: 0.8320\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9586 - accuracy: 0.71 - 0s 4ms/step - loss: 0.6448 - accuracy: 0.7251 - val_loss: 0.4192 - val_accuracy: 0.7920\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.68 - 0s 4ms/step - loss: 0.6484 - accuracy: 0.7171 - val_loss: 0.4086 - val_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7570 - accuracy: 0.62 - 0s 3ms/step - loss: 0.6603 - accuracy: 0.7371 - val_loss: 0.4069 - val_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8093 - accuracy: 0.59 - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7311 - val_loss: 0.4035 - val_accuracy: 0.7920\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0257 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6354 - accuracy: 0.7291 - val_loss: 0.4091 - val_accuracy: 0.8080\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7628 - accuracy: 0.53 - 0s 6ms/step - loss: 0.5853 - accuracy: 0.7390 - val_loss: 0.4167 - val_accuracy: 0.8080\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9349 - accuracy: 0.56 - 0s 6ms/step - loss: 0.6379 - accuracy: 0.7251 - val_loss: 0.4082 - val_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7590 - val_loss: 0.4048 - val_accuracy: 0.7840\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5749 - accuracy: 0.7311 - val_loss: 0.3902 - val_accuracy: 0.8160\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1078 - accuracy: 0.75 - 0s 6ms/step - loss: 0.6543 - accuracy: 0.7510 - val_loss: 0.3919 - val_accuracy: 0.8160\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7656 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7789 - val_loss: 0.3948 - val_accuracy: 0.8080\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7696 - accuracy: 0.68 - 0s 6ms/step - loss: 0.5788 - accuracy: 0.7331 - val_loss: 0.3872 - val_accuracy: 0.8320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9803 - accuracy: 0.75 - 0s 6ms/step - loss: 0.6453 - accuracy: 0.7490 - val_loss: 0.4050 - val_accuracy: 0.8240\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5781 - accuracy: 0.68 - 0s 6ms/step - loss: 0.6251 - accuracy: 0.7351 - val_loss: 0.3820 - val_accuracy: 0.8240\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7729 - val_loss: 0.3829 - val_accuracy: 0.8160\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.75 - 0s 16ms/step - loss: 0.5446 - accuracy: 0.7490 - val_loss: 0.3890 - val_accuracy: 0.8400\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7769 - val_loss: 0.3819 - val_accuracy: 0.8240\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6339 - accuracy: 0.78 - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7590 - val_loss: 0.3787 - val_accuracy: 0.8400\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7709 - val_loss: 0.3911 - val_accuracy: 0.8320\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8305 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7550 - val_loss: 0.3903 - val_accuracy: 0.8320\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.75 - 0s 10ms/step - loss: 0.5425 - accuracy: 0.7570 - val_loss: 0.3738 - val_accuracy: 0.8480\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7948 - val_loss: 0.3948 - val_accuracy: 0.8240\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5541 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7510 - val_loss: 0.3805 - val_accuracy: 0.8400\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7613 - accuracy: 0.68 - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7729 - val_loss: 0.3861 - val_accuracy: 0.8400\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5218 - accuracy: 0.78 - 0s 5ms/step - loss: 0.5113 - accuracy: 0.7629 - val_loss: 0.3797 - val_accuracy: 0.8480\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.78 - ETA: 0s - loss: 0.4877 - accuracy: 0.78 - 0s 15ms/step - loss: 0.4791 - accuracy: 0.7928 - val_loss: 0.3727 - val_accuracy: 0.8560\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5235 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7809 - val_loss: 0.3905 - val_accuracy: 0.8320\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7689 - val_loss: 0.3755 - val_accuracy: 0.8480\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.81 - ETA: 0s - loss: 0.4816 - accuracy: 0.79 - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7888 - val_loss: 0.3717 - val_accuracy: 0.8480\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7709 - val_loss: 0.3831 - val_accuracy: 0.8320\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6277 - accuracy: 0.68 - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7849 - val_loss: 0.3853 - val_accuracy: 0.8400\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9106 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5934 - accuracy: 0.7669 - val_loss: 0.3756 - val_accuracy: 0.8400\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6476 - accuracy: 0.62 - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7709 - val_loss: 0.3792 - val_accuracy: 0.8400\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6398 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7849 - val_loss: 0.3824 - val_accuracy: 0.8400\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7968 - val_loss: 0.3777 - val_accuracy: 0.8400\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.81 - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7888 - val_loss: 0.3754 - val_accuracy: 0.8400\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5730 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7689 - val_loss: 0.3777 - val_accuracy: 0.8480\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7789 - val_loss: 0.3725 - val_accuracy: 0.8480\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7988 - val_loss: 0.3806 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 49b58388aec251a05a48fb08f898a98e</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8560000061988831</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 7s - loss: 6.3519 - accuracy: 0.50 - 1s 51ms/step - loss: 7.3724 - accuracy: 0.5558 - val_loss: 7.0249 - val_accuracy: 0.4960\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.1890 - accuracy: 0.50 - 0s 5ms/step - loss: 5.3446 - accuracy: 0.4084 - val_loss: 5.3137 - val_accuracy: 0.3280\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.9948 - accuracy: 0.53 - 0s 5ms/step - loss: 3.9014 - accuracy: 0.4024 - val_loss: 3.7075 - val_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.1024 - accuracy: 0.50 - 0s 10ms/step - loss: 2.5788 - accuracy: 0.5020 - val_loss: 2.3268 - val_accuracy: 0.5920\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4096 - accuracy: 0.50 - 0s 12ms/step - loss: 1.5028 - accuracy: 0.6056 - val_loss: 1.3142 - val_accuracy: 0.6240\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9679 - accuracy: 0.50 - 0s 15ms/step - loss: 0.8669 - accuracy: 0.6295 - val_loss: 0.7633 - val_accuracy: 0.7040\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8306 - accuracy: 0.59 - 0s 5ms/step - loss: 0.7348 - accuracy: 0.6514 - val_loss: 0.6294 - val_accuracy: 0.6960\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8835 - accuracy: 0.56 - 0s 4ms/step - loss: 0.7124 - accuracy: 0.6554 - val_loss: 0.6216 - val_accuracy: 0.6880\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8175 - accuracy: 0.62 - 0s 3ms/step - loss: 0.6747 - accuracy: 0.6713 - val_loss: 0.6151 - val_accuracy: 0.6880\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7685 - accuracy: 0.56 - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6653 - val_loss: 0.5906 - val_accuracy: 0.6800\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7471 - accuracy: 0.62 - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6813 - val_loss: 0.5684 - val_accuracy: 0.7040\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7280 - accuracy: 0.62 - 0s 10ms/step - loss: 0.6141 - accuracy: 0.6813 - val_loss: 0.5547 - val_accuracy: 0.7120\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.62 - 0s 3ms/step - loss: 0.5979 - accuracy: 0.6892 - val_loss: 0.5424 - val_accuracy: 0.7120\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.62 - 0s 14ms/step - loss: 0.5852 - accuracy: 0.6932 - val_loss: 0.5301 - val_accuracy: 0.7200\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.62 - 0s 6ms/step - loss: 0.5741 - accuracy: 0.6952 - val_loss: 0.5204 - val_accuracy: 0.7200\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6509 - accuracy: 0.65 - 0s 15ms/step - loss: 0.5647 - accuracy: 0.7012 - val_loss: 0.5120 - val_accuracy: 0.7440\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.68 - 0s 13ms/step - loss: 0.5565 - accuracy: 0.7052 - val_loss: 0.5047 - val_accuracy: 0.7520\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.68 - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7032 - val_loss: 0.4985 - val_accuracy: 0.7520\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.68 - 0s 10ms/step - loss: 0.5440 - accuracy: 0.7072 - val_loss: 0.4925 - val_accuracy: 0.7600\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.65 - 0s 10ms/step - loss: 0.5389 - accuracy: 0.7171 - val_loss: 0.4874 - val_accuracy: 0.7680\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6001 - accuracy: 0.68 - 0s 11ms/step - loss: 0.5346 - accuracy: 0.7251 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5932 - accuracy: 0.68 - 0s 10ms/step - loss: 0.5307 - accuracy: 0.7311 - val_loss: 0.4788 - val_accuracy: 0.7920\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5869 - accuracy: 0.68 - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7390 - val_loss: 0.4754 - val_accuracy: 0.7920\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5812 - accuracy: 0.65 - 0s 12ms/step - loss: 0.5242 - accuracy: 0.7410 - val_loss: 0.4717 - val_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5760 - accuracy: 0.65 - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7450 - val_loss: 0.4687 - val_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5185 - accuracy: 0.7490 - val_loss: 0.4659 - val_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7590 - val_loss: 0.4626 - val_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7590 - val_loss: 0.4600 - val_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.65 - 0s 6ms/step - loss: 0.5114 - accuracy: 0.7649 - val_loss: 0.4576 - val_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5546 - accuracy: 0.65 - 0s 6ms/step - loss: 0.5094 - accuracy: 0.7689 - val_loss: 0.4547 - val_accuracy: 0.7920\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7689 - val_loss: 0.4525 - val_accuracy: 0.7920\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7629 - val_loss: 0.4504 - val_accuracy: 0.7920\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7649 - val_loss: 0.4479 - val_accuracy: 0.7840\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7649 - val_loss: 0.4460 - val_accuracy: 0.7840\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7669 - val_loss: 0.4439 - val_accuracy: 0.7840\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.65 - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7669 - val_loss: 0.4420 - val_accuracy: 0.7840\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5340 - accuracy: 0.65 - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7729 - val_loss: 0.4401 - val_accuracy: 0.7920\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.65 - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7729 - val_loss: 0.4382 - val_accuracy: 0.7920\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.65 - 0s 5ms/step - loss: 0.4939 - accuracy: 0.7749 - val_loss: 0.4367 - val_accuracy: 0.7920\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.65 - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7729 - val_loss: 0.4349 - val_accuracy: 0.7920\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.65 - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7729 - val_loss: 0.4333 - val_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.65 - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7769 - val_loss: 0.4317 - val_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7789 - val_loss: 0.4301 - val_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7789 - val_loss: 0.4286 - val_accuracy: 0.8000\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.68 - 0s 5ms/step - loss: 0.4861 - accuracy: 0.7789 - val_loss: 0.4270 - val_accuracy: 0.7920\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.75 - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7809 - val_loss: 0.4258 - val_accuracy: 0.7920\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.75 - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7789 - val_loss: 0.4243 - val_accuracy: 0.7920\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5121 - accuracy: 0.81 - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7869 - val_loss: 0.4228 - val_accuracy: 0.7920\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5105 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7849 - val_loss: 0.4219 - val_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7869 - val_loss: 0.4204 - val_accuracy: 0.8000\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7869 - val_loss: 0.4193 - val_accuracy: 0.7920\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7908 - val_loss: 0.4181 - val_accuracy: 0.7920\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7908 - val_loss: 0.4171 - val_accuracy: 0.8000\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.84 - 0s 9ms/step - loss: 0.4767 - accuracy: 0.7928 - val_loss: 0.4159 - val_accuracy: 0.8080\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7928 - val_loss: 0.4149 - val_accuracy: 0.8080\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7928 - val_loss: 0.4142 - val_accuracy: 0.8080\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7928 - val_loss: 0.4130 - val_accuracy: 0.8000\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7908 - val_loss: 0.4124 - val_accuracy: 0.8000\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7908 - val_loss: 0.4113 - val_accuracy: 0.8000\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4956 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7968 - val_loss: 0.4106 - val_accuracy: 0.8000\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7968 - val_loss: 0.4097 - val_accuracy: 0.8000\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4933 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7988 - val_loss: 0.4090 - val_accuracy: 0.8000\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4700 - accuracy: 0.8008 - val_loss: 0.4082 - val_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7988 - val_loss: 0.4074 - val_accuracy: 0.8000\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4902 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7988 - val_loss: 0.4067 - val_accuracy: 0.8000\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7948 - val_loss: 0.4062 - val_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7968 - val_loss: 0.4056 - val_accuracy: 0.8080\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7968 - val_loss: 0.4051 - val_accuracy: 0.8080\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7948 - val_loss: 0.4044 - val_accuracy: 0.8080\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7968 - val_loss: 0.4040 - val_accuracy: 0.8080\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.84 - ETA: 0s - loss: 0.4598 - accuracy: 0.80 - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7968 - val_loss: 0.4033 - val_accuracy: 0.8080\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7968 - val_loss: 0.4029 - val_accuracy: 0.8080\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7968 - val_loss: 0.4023 - val_accuracy: 0.8080\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4821 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7968 - val_loss: 0.4021 - val_accuracy: 0.8080\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7968 - val_loss: 0.4013 - val_accuracy: 0.8080\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4808 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7968 - val_loss: 0.4011 - val_accuracy: 0.8080\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7968 - val_loss: 0.4006 - val_accuracy: 0.8080\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7948 - val_loss: 0.4002 - val_accuracy: 0.8080\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7948 - val_loss: 0.3997 - val_accuracy: 0.8080\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4775 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7948 - val_loss: 0.3993 - val_accuracy: 0.8080\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4763 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7948 - val_loss: 0.3986 - val_accuracy: 0.8080\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4754 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7948 - val_loss: 0.3984 - val_accuracy: 0.8080\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7948 - val_loss: 0.3977 - val_accuracy: 0.8080\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7968 - val_loss: 0.3975 - val_accuracy: 0.8080\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.84 - 0s 9ms/step - loss: 0.4597 - accuracy: 0.7968 - val_loss: 0.3971 - val_accuracy: 0.8160\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.84 - 0s 10ms/step - loss: 0.4593 - accuracy: 0.7968 - val_loss: 0.3967 - val_accuracy: 0.8240\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7968 - val_loss: 0.3965 - val_accuracy: 0.8240\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7968 - val_loss: 0.3961 - val_accuracy: 0.8240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7968 - val_loss: 0.3956 - val_accuracy: 0.8240\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7968 - val_loss: 0.3956 - val_accuracy: 0.8240\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7988 - val_loss: 0.3951 - val_accuracy: 0.8240\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7988 - val_loss: 0.3948 - val_accuracy: 0.8240\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7988 - val_loss: 0.3945 - val_accuracy: 0.8240\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7988 - val_loss: 0.3945 - val_accuracy: 0.8240\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7988 - val_loss: 0.3938 - val_accuracy: 0.8240\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4566 - accuracy: 0.8008 - val_loss: 0.3938 - val_accuracy: 0.8240\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4564 - accuracy: 0.8008 - val_loss: 0.3937 - val_accuracy: 0.8240\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4563 - accuracy: 0.8008 - val_loss: 0.3934 - val_accuracy: 0.8240\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4560 - accuracy: 0.8028 - val_loss: 0.3933 - val_accuracy: 0.8240\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4558 - accuracy: 0.8028 - val_loss: 0.3932 - val_accuracy: 0.8240\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4556 - accuracy: 0.8028 - val_loss: 0.3931 - val_accuracy: 0.8240\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4555 - accuracy: 0.8028 - val_loss: 0.3928 - val_accuracy: 0.8240\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4656 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4553 - accuracy: 0.8008 - val_loss: 0.3928 - val_accuracy: 0.8240\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4653 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8008 - val_loss: 0.3925 - val_accuracy: 0.8240\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4549 - accuracy: 0.8008 - val_loss: 0.3923 - val_accuracy: 0.8240\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8028 - val_loss: 0.3924 - val_accuracy: 0.8240\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4547 - accuracy: 0.8008 - val_loss: 0.3920 - val_accuracy: 0.8240\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4544 - accuracy: 0.8008 - val_loss: 0.3920 - val_accuracy: 0.8240\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4543 - accuracy: 0.8008 - val_loss: 0.3918 - val_accuracy: 0.8240\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4637 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4541 - accuracy: 0.8008 - val_loss: 0.3917 - val_accuracy: 0.8240\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4540 - accuracy: 0.8008 - val_loss: 0.3915 - val_accuracy: 0.8240\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4631 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4538 - accuracy: 0.8008 - val_loss: 0.3913 - val_accuracy: 0.8240\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4536 - accuracy: 0.8008 - val_loss: 0.3914 - val_accuracy: 0.8240\n",
      "Epoch 114/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4626 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8008 - val_loss: 0.3911 - val_accuracy: 0.8240\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4534 - accuracy: 0.8028 - val_loss: 0.3909 - val_accuracy: 0.8240\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4532 - accuracy: 0.8028 - val_loss: 0.3909 - val_accuracy: 0.8240\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4619 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8028 - val_loss: 0.3909 - val_accuracy: 0.8240\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4530 - accuracy: 0.8028 - val_loss: 0.3906 - val_accuracy: 0.8240\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4528 - accuracy: 0.8028 - val_loss: 0.3907 - val_accuracy: 0.8240\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4615 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4528 - accuracy: 0.8028 - val_loss: 0.3904 - val_accuracy: 0.8240\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4614 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8028 - val_loss: 0.3904 - val_accuracy: 0.8240\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8028 - val_loss: 0.3904 - val_accuracy: 0.8240\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8028 - val_loss: 0.3902 - val_accuracy: 0.8240\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4522 - accuracy: 0.8008 - val_loss: 0.3902 - val_accuracy: 0.8240\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4607 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4521 - accuracy: 0.8008 - val_loss: 0.3902 - val_accuracy: 0.8240\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8008 - val_loss: 0.3902 - val_accuracy: 0.8240\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4520 - accuracy: 0.8008 - val_loss: 0.3900 - val_accuracy: 0.8240\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8008 - val_loss: 0.3900 - val_accuracy: 0.8240\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8008 - val_loss: 0.3900 - val_accuracy: 0.8240\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4599 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4516 - accuracy: 0.8008 - val_loss: 0.3901 - val_accuracy: 0.8240\n",
      "Epoch 131/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4516 - accuracy: 0.8008 - val_loss: 0.3899 - val_accuracy: 0.8240\n",
      "Epoch 132/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4596 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8008 - val_loss: 0.3897 - val_accuracy: 0.8240\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4595 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4513 - accuracy: 0.8008 - val_loss: 0.3899 - val_accuracy: 0.8240\n",
      "Epoch 134/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4593 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4513 - accuracy: 0.8028 - val_loss: 0.3899 - val_accuracy: 0.8240\n",
      "Epoch 135/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4591 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4512 - accuracy: 0.8028 - val_loss: 0.3898 - val_accuracy: 0.8240\n",
      "Epoch 136/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4591 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4510 - accuracy: 0.8028 - val_loss: 0.3897 - val_accuracy: 0.8240\n",
      "Epoch 137/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8028 - val_loss: 0.3899 - val_accuracy: 0.8240\n",
      "Epoch 138/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4588 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4509 - accuracy: 0.8028 - val_loss: 0.3897 - val_accuracy: 0.8240\n",
      "Epoch 139/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4586 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4508 - accuracy: 0.8028 - val_loss: 0.3896 - val_accuracy: 0.8240\n",
      "Epoch 140/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4506 - accuracy: 0.8028 - val_loss: 0.3898 - val_accuracy: 0.8160\n",
      "Epoch 141/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4506 - accuracy: 0.8028 - val_loss: 0.3896 - val_accuracy: 0.8160\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4505 - accuracy: 0.8028 - val_loss: 0.3897 - val_accuracy: 0.8160\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4581 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4504 - accuracy: 0.8048 - val_loss: 0.3896 - val_accuracy: 0.8160\n",
      "Epoch 144/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4502 - accuracy: 0.8048 - val_loss: 0.3898 - val_accuracy: 0.8160\n",
      "Epoch 145/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4503 - accuracy: 0.8048 - val_loss: 0.3896 - val_accuracy: 0.8160\n",
      "Epoch 146/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8048 - val_loss: 0.3897 - val_accuracy: 0.8160\n",
      "Epoch 147/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8048 - val_loss: 0.3897 - val_accuracy: 0.8160\n",
      "Epoch 148/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8048 - val_loss: 0.3895 - val_accuracy: 0.8160\n",
      "Epoch 149/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4574 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4499 - accuracy: 0.8048 - val_loss: 0.3896 - val_accuracy: 0.8160\n",
      "Epoch 150/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8048 - val_loss: 0.3897 - val_accuracy: 0.8160\n",
      "Epoch 151/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8048 - val_loss: 0.3897 - val_accuracy: 0.8160\n",
      "Epoch 152/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8048 - val_loss: 0.3896 - val_accuracy: 0.8160\n",
      "Epoch 153/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4497 - accuracy: 0.8048 - val_loss: 0.3895 - val_accuracy: 0.8160\n",
      "Epoch 154/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.84 - 0s 6ms/step - loss: 0.4495 - accuracy: 0.8048 - val_loss: 0.3898 - val_accuracy: 0.8160\n",
      "Epoch 155/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4496 - accuracy: 0.8048 - val_loss: 0.3896 - val_accuracy: 0.8160\n",
      "Epoch 156/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4495 - accuracy: 0.8048 - val_loss: 0.3897 - val_accuracy: 0.8160\n",
      "Epoch 157/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8048 - val_loss: 0.3895 - val_accuracy: 0.8160\n",
      "Epoch 158/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4492 - accuracy: 0.8048 - val_loss: 0.3898 - val_accuracy: 0.8160\n",
      "Epoch 159/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4492 - accuracy: 0.8048 - val_loss: 0.3897 - val_accuracy: 0.8160\n",
      "Epoch 160/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4560 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4491 - accuracy: 0.8048 - val_loss: 0.3897 - val_accuracy: 0.8160\n",
      "Epoch 161/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8048 - val_loss: 0.3896 - val_accuracy: 0.8160\n",
      "Epoch 162/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8068 - val_loss: 0.3898 - val_accuracy: 0.8160\n",
      "Epoch 163/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4556 - accuracy: 0.84 - 0s 5ms/step - loss: 0.4490 - accuracy: 0.8068 - val_loss: 0.3897 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d001b3d58cec2c56871666f1c82d8ab3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8240000009536743</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 16</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 9s - loss: 0.7549 - accuracy: 0.59 - ETA: 0s - loss: 4.0455 - accuracy: 0.58 - 1s 75ms/step - loss: 3.2094 - accuracy: 0.5757 - val_loss: 0.8700 - val_accuracy: 0.7360\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.8667 - accuracy: 0.56 - ETA: 0s - loss: 1.8727 - accuracy: 0.63 - ETA: 0s - loss: 1.6030 - accuracy: 0.58 - 0s 10ms/step - loss: 1.5634 - accuracy: 0.5896 - val_loss: 0.6871 - val_accuracy: 0.6800\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5842 - accuracy: 0.46 - ETA: 0s - loss: 1.1468 - accuracy: 0.63 - ETA: 0s - loss: 1.0964 - accuracy: 0.64 - 0s 10ms/step - loss: 1.0867 - accuracy: 0.6375 - val_loss: 0.6655 - val_accuracy: 0.7200\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2800 - accuracy: 0.59 - ETA: 0s - loss: 1.0112 - accuracy: 0.63 - ETA: 0s - loss: 1.0327 - accuracy: 0.63 - 0s 12ms/step - loss: 0.9693 - accuracy: 0.6335 - val_loss: 0.6394 - val_accuracy: 0.7200\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3284 - accuracy: 0.50 - ETA: 0s - loss: 0.8771 - accuracy: 0.63 - ETA: 0s - loss: 0.8487 - accuracy: 0.64 - 0s 10ms/step - loss: 0.8340 - accuracy: 0.6494 - val_loss: 0.5983 - val_accuracy: 0.7200\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7512 - accuracy: 0.56 - ETA: 0s - loss: 0.7498 - accuracy: 0.62 - 0s 10ms/step - loss: 0.7512 - accuracy: 0.6534 - val_loss: 0.5837 - val_accuracy: 0.7280\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2800 - accuracy: 0.53 - ETA: 0s - loss: 0.8315 - accuracy: 0.62 - ETA: 0s - loss: 0.8129 - accuracy: 0.62 - 0s 11ms/step - loss: 0.7681 - accuracy: 0.6494 - val_loss: 0.6410 - val_accuracy: 0.6880\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9511 - accuracy: 0.62 - ETA: 0s - loss: 0.7480 - accuracy: 0.63 - 0s 16ms/step - loss: 0.7102 - accuracy: 0.6693 - val_loss: 0.5341 - val_accuracy: 0.7440\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8533 - accuracy: 0.56 - ETA: 0s - loss: 0.6723 - accuracy: 0.66 - ETA: 0s - loss: 0.6651 - accuracy: 0.66 - 0s 24ms/step - loss: 0.6484 - accuracy: 0.6813 - val_loss: 0.5235 - val_accuracy: 0.7600\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.53 - ETA: 0s - loss: 0.6507 - accuracy: 0.63 - ETA: 0s - loss: 0.6900 - accuracy: 0.65 - 0s 12ms/step - loss: 0.6808 - accuracy: 0.6574 - val_loss: 0.5287 - val_accuracy: 0.7600\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0473 - accuracy: 0.53 - ETA: 0s - loss: 0.7323 - accuracy: 0.62 - ETA: 0s - loss: 0.7112 - accuracy: 0.66 - 0s 20ms/step - loss: 0.6767 - accuracy: 0.6793 - val_loss: 0.4957 - val_accuracy: 0.7680\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.66 - 0s 8ms/step - loss: 0.6397 - accuracy: 0.7012 - val_loss: 0.5088 - val_accuracy: 0.7600\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6192 - accuracy: 0.71 - ETA: 0s - loss: 0.6061 - accuracy: 0.67 - ETA: 0s - loss: 0.6095 - accuracy: 0.70 - 0s 20ms/step - loss: 0.6036 - accuracy: 0.7131 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7231 - accuracy: 0.68 - ETA: 0s - loss: 0.6137 - accuracy: 0.69 - ETA: 0s - loss: 0.6097 - accuracy: 0.71 - 0s 23ms/step - loss: 0.6049 - accuracy: 0.7151 - val_loss: 0.4839 - val_accuracy: 0.7920\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.71 - ETA: 0s - loss: 0.5919 - accuracy: 0.70 - ETA: 0s - loss: 0.5846 - accuracy: 0.72 - 0s 10ms/step - loss: 0.5793 - accuracy: 0.7291 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6678 - accuracy: 0.68 - ETA: 0s - loss: 0.5865 - accuracy: 0.71 - ETA: 0s - loss: 0.5945 - accuracy: 0.72 - 0s 11ms/step - loss: 0.5716 - accuracy: 0.7390 - val_loss: 0.4824 - val_accuracy: 0.7680\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8089 - accuracy: 0.62 - ETA: 0s - loss: 0.6034 - accuracy: 0.68 - ETA: 0s - loss: 0.5704 - accuracy: 0.72 - 0s 9ms/step - loss: 0.5634 - accuracy: 0.7291 - val_loss: 0.5034 - val_accuracy: 0.7840\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5578 - accuracy: 0.68 - ETA: 0s - loss: 0.5309 - accuracy: 0.72 - ETA: 0s - loss: 0.5532 - accuracy: 0.72 - 0s 12ms/step - loss: 0.5359 - accuracy: 0.7390 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.68 - ETA: 0s - loss: 0.5516 - accuracy: 0.73 - 0s 9ms/step - loss: 0.5405 - accuracy: 0.7470 - val_loss: 0.4824 - val_accuracy: 0.7840\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.75 - ETA: 0s - loss: 0.5861 - accuracy: 0.72 - ETA: 0s - loss: 0.5774 - accuracy: 0.75 - 0s 10ms/step - loss: 0.5512 - accuracy: 0.7610 - val_loss: 0.4550 - val_accuracy: 0.7760\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6621 - accuracy: 0.65 - ETA: 0s - loss: 0.5559 - accuracy: 0.72 - ETA: 0s - loss: 0.5322 - accuracy: 0.75 - 0s 10ms/step - loss: 0.5275 - accuracy: 0.7590 - val_loss: 0.4679 - val_accuracy: 0.7840\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.62 - ETA: 0s - loss: 0.5599 - accuracy: 0.73 - ETA: 0s - loss: 0.5460 - accuracy: 0.75 - 0s 19ms/step - loss: 0.5355 - accuracy: 0.7570 - val_loss: 0.4634 - val_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.71 - ETA: 0s - loss: 0.5203 - accuracy: 0.75 - ETA: 0s - loss: 0.5291 - accuracy: 0.75 - 0s 23ms/step - loss: 0.5083 - accuracy: 0.7709 - val_loss: 0.4102 - val_accuracy: 0.8160\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.75 - ETA: 0s - loss: 0.5095 - accuracy: 0.78 - ETA: 0s - loss: 0.5141 - accuracy: 0.78 - 0s 12ms/step - loss: 0.4966 - accuracy: 0.7908 - val_loss: 0.4170 - val_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.75 - ETA: 0s - loss: 0.4948 - accuracy: 0.77 - ETA: 0s - loss: 0.4869 - accuracy: 0.77 - 0s 10ms/step - loss: 0.4798 - accuracy: 0.7829 - val_loss: 0.4346 - val_accuracy: 0.8080\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.71 - ETA: 0s - loss: 0.5177 - accuracy: 0.75 - ETA: 0s - loss: 0.5066 - accuracy: 0.76 - 0s 11ms/step - loss: 0.4876 - accuracy: 0.7769 - val_loss: 0.4353 - val_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6481 - accuracy: 0.71 - ETA: 0s - loss: 0.5259 - accuracy: 0.75 - 0s 10ms/step - loss: 0.5003 - accuracy: 0.7789 - val_loss: 0.4292 - val_accuracy: 0.8080\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6638 - accuracy: 0.68 - ETA: 0s - loss: 0.5135 - accuracy: 0.77 - 0s 9ms/step - loss: 0.4957 - accuracy: 0.7789 - val_loss: 0.4222 - val_accuracy: 0.8160\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5725 - accuracy: 0.75 - ETA: 0s - loss: 0.5259 - accuracy: 0.76 - ETA: 0s - loss: 0.4960 - accuracy: 0.78 - 0s 10ms/step - loss: 0.4887 - accuracy: 0.7849 - val_loss: 0.4360 - val_accuracy: 0.8080\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.71 - ETA: 0s - loss: 0.4951 - accuracy: 0.77 - ETA: 0s - loss: 0.4934 - accuracy: 0.77 - 0s 11ms/step - loss: 0.4822 - accuracy: 0.7789 - val_loss: 0.4745 - val_accuracy: 0.8080\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.68 - ETA: 0s - loss: 0.5088 - accuracy: 0.75 - ETA: 0s - loss: 0.5012 - accuracy: 0.75 - 0s 11ms/step - loss: 0.4927 - accuracy: 0.7649 - val_loss: 0.4332 - val_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5477 - accuracy: 0.71 - ETA: 0s - loss: 0.5009 - accuracy: 0.76 - ETA: 0s - loss: 0.4794 - accuracy: 0.80 - 0s 12ms/step - loss: 0.4642 - accuracy: 0.8048 - val_loss: 0.4185 - val_accuracy: 0.8160\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.71 - ETA: 0s - loss: 0.5036 - accuracy: 0.76 - ETA: 0s - loss: 0.4892 - accuracy: 0.78 - 0s 11ms/step - loss: 0.4800 - accuracy: 0.7849 - val_loss: 0.4174 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 6b0ccb2ff8f5268eba4152ec35e7e8ae</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8159999847412109</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 1024</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 22s - loss: 0.8680 - accuracy: 0.562 - ETA: 0s - loss: 0.7848 - accuracy: 0.568 - 2s 118ms/step - loss: 0.7765 - accuracy: 0.5777 - val_loss: 0.8544 - val_accuracy: 0.3440\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8578 - accuracy: 0.53 - ETA: 0s - loss: 0.7692 - accuracy: 0.61 - 0s 13ms/step - loss: 0.7671 - accuracy: 0.6155 - val_loss: 0.6284 - val_accuracy: 0.6800\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8811 - accuracy: 0.46 - ETA: 0s - loss: 0.6777 - accuracy: 0.65 - 0s 12ms/step - loss: 0.6751 - accuracy: 0.6594 - val_loss: 0.6456 - val_accuracy: 0.7280\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8836 - accuracy: 0.59 - ETA: 0s - loss: 0.6792 - accuracy: 0.64 - 0s 6ms/step - loss: 0.6735 - accuracy: 0.6434 - val_loss: 0.6072 - val_accuracy: 0.7280\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6318 - accuracy: 0.71 - ETA: 0s - loss: 0.6354 - accuracy: 0.67 - 0s 18ms/step - loss: 0.6526 - accuracy: 0.6614 - val_loss: 0.5785 - val_accuracy: 0.7520\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.59 - ETA: 0s - loss: 0.6712 - accuracy: 0.67 - 0s 6ms/step - loss: 0.6470 - accuracy: 0.6873 - val_loss: 0.5697 - val_accuracy: 0.7520\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7733 - accuracy: 0.65 - ETA: 0s - loss: 0.6622 - accuracy: 0.64 - 0s 7ms/step - loss: 0.6590 - accuracy: 0.6474 - val_loss: 0.6106 - val_accuracy: 0.7200\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.53 - ETA: 0s - loss: 0.6537 - accuracy: 0.64 - ETA: 0s - loss: 0.6333 - accuracy: 0.66 - 0s 19ms/step - loss: 0.6316 - accuracy: 0.6653 - val_loss: 0.5515 - val_accuracy: 0.7600\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8146 - accuracy: 0.46 - ETA: 0s - loss: 0.6584 - accuracy: 0.65 - ETA: 0s - loss: 0.6113 - accuracy: 0.67 - 0s 10ms/step - loss: 0.6105 - accuracy: 0.6813 - val_loss: 0.5319 - val_accuracy: 0.7600\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.56 - ETA: 0s - loss: 0.6183 - accuracy: 0.69 - 0s 14ms/step - loss: 0.6034 - accuracy: 0.7052 - val_loss: 0.5537 - val_accuracy: 0.7680\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.71 - ETA: 0s - loss: 0.5858 - accuracy: 0.69 - 0s 17ms/step - loss: 0.6261 - accuracy: 0.7032 - val_loss: 0.5082 - val_accuracy: 0.8160\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6226 - accuracy: 0.65 - ETA: 0s - loss: 0.6155 - accuracy: 0.70 - 0s 8ms/step - loss: 0.5944 - accuracy: 0.7151 - val_loss: 0.5074 - val_accuracy: 0.7920\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.65 - ETA: 0s - loss: 0.5828 - accuracy: 0.71 - 0s 7ms/step - loss: 0.5834 - accuracy: 0.7112 - val_loss: 0.5271 - val_accuracy: 0.7600\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7364 - accuracy: 0.62 - ETA: 0s - loss: 0.5879 - accuracy: 0.71 - 0s 8ms/step - loss: 0.5683 - accuracy: 0.7271 - val_loss: 0.5026 - val_accuracy: 0.7920\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.59 - ETA: 0s - loss: 0.5633 - accuracy: 0.71 - 0s 9ms/step - loss: 0.5593 - accuracy: 0.7211 - val_loss: 0.5146 - val_accuracy: 0.7840\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7477 - accuracy: 0.65 - ETA: 0s - loss: 0.6223 - accuracy: 0.71 - 0s 9ms/step - loss: 0.5750 - accuracy: 0.7191 - val_loss: 0.4835 - val_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.71 - ETA: 0s - loss: 0.5637 - accuracy: 0.72 - ETA: 0s - loss: 0.5762 - accuracy: 0.73 - 0s 11ms/step - loss: 0.5719 - accuracy: 0.7331 - val_loss: 0.4577 - val_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6161 - accuracy: 0.68 - ETA: 0s - loss: 0.5388 - accuracy: 0.73 - 0s 10ms/step - loss: 0.5486 - accuracy: 0.7490 - val_loss: 0.4554 - val_accuracy: 0.7920\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.75 - ETA: 0s - loss: 0.5340 - accuracy: 0.75 - 0s 9ms/step - loss: 0.5050 - accuracy: 0.7689 - val_loss: 0.4558 - val_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7441 - accuracy: 0.68 - ETA: 0s - loss: 0.5558 - accuracy: 0.75 - 0s 9ms/step - loss: 0.5344 - accuracy: 0.7610 - val_loss: 0.4247 - val_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.62 - ETA: 0s - loss: 0.5153 - accuracy: 0.77 - 0s 16ms/step - loss: 0.5130 - accuracy: 0.7610 - val_loss: 0.4205 - val_accuracy: 0.8400\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5189 - accuracy: 0.68 - ETA: 0s - loss: 0.5174 - accuracy: 0.76 - 0s 9ms/step - loss: 0.5132 - accuracy: 0.7629 - val_loss: 0.4545 - val_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.75 - ETA: 0s - loss: 0.5206 - accuracy: 0.78 - 0s 8ms/step - loss: 0.5119 - accuracy: 0.7829 - val_loss: 0.4098 - val_accuracy: 0.8320\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6601 - accuracy: 0.71 - ETA: 0s - loss: 0.5032 - accuracy: 0.78 - 0s 10ms/step - loss: 0.5097 - accuracy: 0.7669 - val_loss: 0.4329 - val_accuracy: 0.8240\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.78 - ETA: 0s - loss: 0.5021 - accuracy: 0.77 - 0s 9ms/step - loss: 0.5043 - accuracy: 0.7769 - val_loss: 0.4834 - val_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7088 - accuracy: 0.71 - ETA: 0s - loss: 0.5176 - accuracy: 0.77 - 0s 9ms/step - loss: 0.5034 - accuracy: 0.7769 - val_loss: 0.4981 - val_accuracy: 0.7680\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.65 - ETA: 0s - loss: 0.5823 - accuracy: 0.73 - 0s 10ms/step - loss: 0.5507 - accuracy: 0.7450 - val_loss: 0.4987 - val_accuracy: 0.7760\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7241 - accuracy: 0.62 - ETA: 0s - loss: 0.5720 - accuracy: 0.73 - 0s 9ms/step - loss: 0.5067 - accuracy: 0.7649 - val_loss: 0.5025 - val_accuracy: 0.7840\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.75 - ETA: 0s - loss: 0.5174 - accuracy: 0.77 - ETA: 0s - loss: 0.4960 - accuracy: 0.77 - 0s 11ms/step - loss: 0.4980 - accuracy: 0.7789 - val_loss: 0.4902 - val_accuracy: 0.7920\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.75 - ETA: 0s - loss: 0.5142 - accuracy: 0.76 - 0s 10ms/step - loss: 0.4800 - accuracy: 0.7749 - val_loss: 0.4874 - val_accuracy: 0.8080\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.81 - ETA: 0s - loss: 0.4944 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4941 - accuracy: 0.7948 - val_loss: 0.3885 - val_accuracy: 0.8400\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.71 - ETA: 0s - loss: 0.4980 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4920 - accuracy: 0.7829 - val_loss: 0.3977 - val_accuracy: 0.8320\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.81 - ETA: 0s - loss: 0.4915 - accuracy: 0.77 - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7749 - val_loss: 0.3947 - val_accuracy: 0.8320\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.78 - ETA: 0s - loss: 0.4559 - accuracy: 0.81 - 0s 6ms/step - loss: 0.4395 - accuracy: 0.8227 - val_loss: 0.3841 - val_accuracy: 0.8320\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.68 - ETA: 0s - loss: 0.5014 - accuracy: 0.79 - 0s 9ms/step - loss: 0.4748 - accuracy: 0.8008 - val_loss: 0.4048 - val_accuracy: 0.8320\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.84 - ETA: 0s - loss: 0.4465 - accuracy: 0.80 - 0s 8ms/step - loss: 0.4494 - accuracy: 0.7988 - val_loss: 0.4282 - val_accuracy: 0.8400\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.71 - ETA: 0s - loss: 0.4891 - accuracy: 0.77 - 0s 9ms/step - loss: 0.4801 - accuracy: 0.7988 - val_loss: 0.4047 - val_accuracy: 0.8320\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.68 - ETA: 0s - loss: 0.4773 - accuracy: 0.76 - 0s 9ms/step - loss: 0.4686 - accuracy: 0.7888 - val_loss: 0.3932 - val_accuracy: 0.8320\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.81 - ETA: 0s - loss: 0.4726 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4540 - accuracy: 0.8068 - val_loss: 0.3720 - val_accuracy: 0.8400\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.84 - ETA: 0s - loss: 0.4728 - accuracy: 0.80 - 0s 9ms/step - loss: 0.4662 - accuracy: 0.8028 - val_loss: 0.3752 - val_accuracy: 0.8400\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.78 - ETA: 0s - loss: 0.4602 - accuracy: 0.79 - 0s 10ms/step - loss: 0.4426 - accuracy: 0.8008 - val_loss: 0.3995 - val_accuracy: 0.8240\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.84 - ETA: 0s - loss: 0.4446 - accuracy: 0.80 - 0s 10ms/step - loss: 0.4562 - accuracy: 0.7928 - val_loss: 0.4151 - val_accuracy: 0.8240\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.75 - ETA: 0s - loss: 0.4502 - accuracy: 0.80 - 0s 10ms/step - loss: 0.4348 - accuracy: 0.8028 - val_loss: 0.3846 - val_accuracy: 0.8240\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.84 - ETA: 0s - loss: 0.4714 - accuracy: 0.78 - 0s 10ms/step - loss: 0.4592 - accuracy: 0.7789 - val_loss: 0.3820 - val_accuracy: 0.8080\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.65 - ETA: 0s - loss: 0.4954 - accuracy: 0.78 - 0s 10ms/step - loss: 0.4796 - accuracy: 0.7809 - val_loss: 0.4079 - val_accuracy: 0.8160\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4778 - accuracy: 0.75 - ETA: 0s - loss: 0.4637 - accuracy: 0.78 - 0s 10ms/step - loss: 0.4497 - accuracy: 0.7888 - val_loss: 0.4047 - val_accuracy: 0.8240\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.75 - ETA: 0s - loss: 0.4574 - accuracy: 0.80 - 0s 6ms/step - loss: 0.4544 - accuracy: 0.8108 - val_loss: 0.4040 - val_accuracy: 0.8320\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5152 - accuracy: 0.78 - ETA: 0s - loss: 0.4743 - accuracy: 0.78 - 0s 9ms/step - loss: 0.4650 - accuracy: 0.7948 - val_loss: 0.4313 - val_accuracy: 0.8320\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.78 - ETA: 0s - loss: 0.4921 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4645 - accuracy: 0.7928 - val_loss: 0.3942 - val_accuracy: 0.8240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: bfe0cce65e7fa0bf3cdaea0c8581d979</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8399999737739563</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_2: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/use_batchnorm: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Train for 20 steps, validate for 4 steps\n",
      "Epoch 1/1000\n",
      "20/20 [==============================] - ETA: 10s - loss: 4.5926 - accuracy: 0.312 - 1s 37ms/step - loss: 2.6470 - accuracy: 0.5183 - val_loss: 0.6972 - val_accuracy: 0.7120\n",
      "Epoch 2/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.1827 - accuracy: 0.37 - 0s 3ms/step - loss: 2.5455 - accuracy: 0.5375 - val_loss: 0.6862 - val_accuracy: 0.7040\n",
      "Epoch 3/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.2035 - accuracy: 0.56 - 0s 3ms/step - loss: 2.2693 - accuracy: 0.5646 - val_loss: 0.6990 - val_accuracy: 0.7040\n",
      "Epoch 4/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.5266 - accuracy: 0.43 - 0s 3ms/step - loss: 2.2245 - accuracy: 0.6156 - val_loss: 0.7515 - val_accuracy: 0.6880\n",
      "Epoch 5/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.5264 - accuracy: 0.50 - 0s 3ms/step - loss: 1.7610 - accuracy: 0.6029 - val_loss: 0.6632 - val_accuracy: 0.7280\n",
      "Epoch 6/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.1711 - accuracy: 0.59 - 0s 4ms/step - loss: 2.4133 - accuracy: 0.6013 - val_loss: 0.6557 - val_accuracy: 0.7120\n",
      "Epoch 7/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.4009 - accuracy: 0.43 - ETA: 0s - loss: 2.1153 - accuracy: 0.56 - 0s 5ms/step - loss: 2.0177 - accuracy: 0.5710 - val_loss: 0.5779 - val_accuracy: 0.7360\n",
      "Epoch 8/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.9308 - accuracy: 0.46 - ETA: 0s - loss: 1.9587 - accuracy: 0.58 - 0s 5ms/step - loss: 1.8657 - accuracy: 0.5949 - val_loss: 0.5625 - val_accuracy: 0.7280\n",
      "Epoch 9/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0320 - accuracy: 0.46 - ETA: 0s - loss: 1.8889 - accuracy: 0.58 - 0s 6ms/step - loss: 1.8710 - accuracy: 0.5821 - val_loss: 0.5274 - val_accuracy: 0.7280\n",
      "Epoch 10/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.3775 - accuracy: 0.59 - ETA: 0s - loss: 1.3740 - accuracy: 0.62 - 0s 5ms/step - loss: 1.3566 - accuracy: 0.6284 - val_loss: 0.5545 - val_accuracy: 0.6880\n",
      "Epoch 11/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.9641 - accuracy: 0.43 - 0s 5ms/step - loss: 1.6829 - accuracy: 0.5821 - val_loss: 0.5691 - val_accuracy: 0.7120\n",
      "Epoch 12/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.4659 - accuracy: 0.65 - ETA: 0s - loss: 1.7006 - accuracy: 0.63 - 0s 5ms/step - loss: 1.6373 - accuracy: 0.6316 - val_loss: 0.5396 - val_accuracy: 0.7200\n",
      "Epoch 13/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.4122 - accuracy: 0.43 - 0s 5ms/step - loss: 1.3260 - accuracy: 0.6364 - val_loss: 0.5188 - val_accuracy: 0.7520\n",
      "Epoch 14/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.5242 - accuracy: 0.43 - 0s 5ms/step - loss: 1.3079 - accuracy: 0.6124 - val_loss: 0.5456 - val_accuracy: 0.7280\n",
      "Epoch 15/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2978 - accuracy: 0.53 - 0s 5ms/step - loss: 1.1459 - accuracy: 0.6603 - val_loss: 0.5016 - val_accuracy: 0.7440\n",
      "Epoch 16/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.4317 - accuracy: 0.50 - 0s 4ms/step - loss: 1.1956 - accuracy: 0.6029 - val_loss: 0.4941 - val_accuracy: 0.7680\n",
      "Epoch 17/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.6685 - accuracy: 0.46 - 0s 3ms/step - loss: 1.1373 - accuracy: 0.6411 - val_loss: 0.4983 - val_accuracy: 0.7680\n",
      "Epoch 18/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0352 - accuracy: 0.59 - 0s 4ms/step - loss: 1.2035 - accuracy: 0.6491 - val_loss: 0.4823 - val_accuracy: 0.7760\n",
      "Epoch 19/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.9789 - accuracy: 0.53 - 0s 5ms/step - loss: 1.0746 - accuracy: 0.6619 - val_loss: 0.4933 - val_accuracy: 0.7680\n",
      "Epoch 20/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1808 - accuracy: 0.53 - 0s 4ms/step - loss: 0.9128 - accuracy: 0.6794 - val_loss: 0.4672 - val_accuracy: 0.7840\n",
      "Epoch 21/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.6377 - accuracy: 0.46 - ETA: 0s - loss: 0.9669 - accuracy: 0.65 - 0s 5ms/step - loss: 0.9451 - accuracy: 0.6587 - val_loss: 0.4594 - val_accuracy: 0.7920\n",
      "Epoch 22/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.56 - ETA: 0s - loss: 0.9893 - accuracy: 0.64 - 0s 6ms/step - loss: 0.9405 - accuracy: 0.6571 - val_loss: 0.4923 - val_accuracy: 0.7600\n",
      "Epoch 23/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9704 - accuracy: 0.53 - 0s 5ms/step - loss: 0.8785 - accuracy: 0.6778 - val_loss: 0.4571 - val_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6157 - accuracy: 0.62 - 0s 3ms/step - loss: 0.8382 - accuracy: 0.6762 - val_loss: 0.4444 - val_accuracy: 0.8320\n",
      "Epoch 25/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7960 - accuracy: 0.53 - 0s 3ms/step - loss: 0.8754 - accuracy: 0.6715 - val_loss: 0.4381 - val_accuracy: 0.8240\n",
      "Epoch 26/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.62 - 0s 3ms/step - loss: 0.7736 - accuracy: 0.7097 - val_loss: 0.4466 - val_accuracy: 0.8240\n",
      "Epoch 27/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7433 - accuracy: 0.62 - 0s 4ms/step - loss: 0.9285 - accuracy: 0.6890 - val_loss: 0.4515 - val_accuracy: 0.8080\n",
      "Epoch 28/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.65 - 0s 3ms/step - loss: 0.7141 - accuracy: 0.7002 - val_loss: 0.4506 - val_accuracy: 0.8080\n",
      "Epoch 29/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.3302 - accuracy: 0.68 - 0s 3ms/step - loss: 0.7993 - accuracy: 0.7097 - val_loss: 0.4378 - val_accuracy: 0.8320\n",
      "Epoch 30/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.5001 - accuracy: 0.56 - 0s 3ms/step - loss: 0.8818 - accuracy: 0.7018 - val_loss: 0.4365 - val_accuracy: 0.8320\n",
      "Epoch 31/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.3843 - accuracy: 0.62 - 0s 4ms/step - loss: 0.7598 - accuracy: 0.7161 - val_loss: 0.4584 - val_accuracy: 0.7920\n",
      "Epoch 32/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.8464 - accuracy: 0.50 - ETA: 0s - loss: 0.7728 - accuracy: 0.68 - 0s 6ms/step - loss: 0.7403 - accuracy: 0.7002 - val_loss: 0.4179 - val_accuracy: 0.8560\n",
      "Epoch 33/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.3350 - accuracy: 0.68 - ETA: 0s - loss: 0.7233 - accuracy: 0.72 - 0s 6ms/step - loss: 0.7026 - accuracy: 0.7305 - val_loss: 0.4292 - val_accuracy: 0.8560\n",
      "Epoch 34/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.5843 - accuracy: 0.59 - ETA: 0s - loss: 0.7441 - accuracy: 0.71 - 0s 5ms/step - loss: 0.7289 - accuracy: 0.7129 - val_loss: 0.4462 - val_accuracy: 0.8080\n",
      "Epoch 35/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.3629 - accuracy: 0.56 - 0s 3ms/step - loss: 0.7855 - accuracy: 0.7081 - val_loss: 0.4160 - val_accuracy: 0.8640\n",
      "Epoch 36/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7831 - accuracy: 0.59 - 0s 4ms/step - loss: 0.6537 - accuracy: 0.7081 - val_loss: 0.4328 - val_accuracy: 0.8480\n",
      "Epoch 37/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7705 - accuracy: 0.56 - ETA: 0s - loss: 0.6365 - accuracy: 0.73 - 0s 5ms/step - loss: 0.6299 - accuracy: 0.7368 - val_loss: 0.4275 - val_accuracy: 0.8560\n",
      "Epoch 38/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7569 - accuracy: 0.50 - ETA: 0s - loss: 0.6709 - accuracy: 0.70 - 0s 5ms/step - loss: 0.6586 - accuracy: 0.7018 - val_loss: 0.4248 - val_accuracy: 0.8400\n",
      "Epoch 39/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9502 - accuracy: 0.65 - ETA: 0s - loss: 0.6652 - accuracy: 0.71 - 0s 5ms/step - loss: 0.6559 - accuracy: 0.7209 - val_loss: 0.4388 - val_accuracy: 0.8400\n",
      "Epoch 40/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5554 - accuracy: 0.75 - ETA: 0s - loss: 0.6277 - accuracy: 0.72 - 0s 5ms/step - loss: 0.6164 - accuracy: 0.7257 - val_loss: 0.4197 - val_accuracy: 0.8640\n",
      "Epoch 41/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.8098 - accuracy: 0.65 - ETA: 0s - loss: 0.7108 - accuracy: 0.73 - 0s 5ms/step - loss: 0.6978 - accuracy: 0.7416 - val_loss: 0.4117 - val_accuracy: 0.8640\n",
      "Epoch 42/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9781 - accuracy: 0.53 - ETA: 0s - loss: 0.6506 - accuracy: 0.72 - 0s 6ms/step - loss: 0.6380 - accuracy: 0.7257 - val_loss: 0.4298 - val_accuracy: 0.8560\n",
      "Epoch 43/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5903 - accuracy: 0.62 - 0s 5ms/step - loss: 0.6273 - accuracy: 0.7225 - val_loss: 0.4058 - val_accuracy: 0.8720\n",
      "Epoch 44/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6347 - accuracy: 0.56 - ETA: 0s - loss: 0.5915 - accuracy: 0.73 - 0s 5ms/step - loss: 0.5759 - accuracy: 0.7416 - val_loss: 0.4122 - val_accuracy: 0.8480\n",
      "Epoch 45/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.59 - ETA: 0s - loss: 0.5907 - accuracy: 0.72 - 0s 5ms/step - loss: 0.5803 - accuracy: 0.7321 - val_loss: 0.4128 - val_accuracy: 0.8480\n",
      "Epoch 46/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0286 - accuracy: 0.59 - 0s 5ms/step - loss: 0.6258 - accuracy: 0.7337 - val_loss: 0.4018 - val_accuracy: 0.8640\n",
      "Epoch 47/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.1457 - accuracy: 0.62 - 0s 5ms/step - loss: 0.6043 - accuracy: 0.7767 - val_loss: 0.4053 - val_accuracy: 0.8480\n",
      "Epoch 48/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.3310 - accuracy: 0.65 - ETA: 0s - loss: 0.5937 - accuracy: 0.76 - 0s 5ms/step - loss: 0.5855 - accuracy: 0.7624 - val_loss: 0.3917 - val_accuracy: 0.8960\n",
      "Epoch 49/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0436 - accuracy: 0.56 - 0s 4ms/step - loss: 0.6963 - accuracy: 0.7512 - val_loss: 0.4181 - val_accuracy: 0.8400\n",
      "Epoch 50/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9802 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6172 - accuracy: 0.7416 - val_loss: 0.3889 - val_accuracy: 0.8880\n",
      "Epoch 51/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7320 - accuracy: 0.62 - 0s 5ms/step - loss: 0.6253 - accuracy: 0.7400 - val_loss: 0.4027 - val_accuracy: 0.8560\n",
      "Epoch 52/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7464 - val_loss: 0.3942 - val_accuracy: 0.8720\n",
      "Epoch 53/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7640 - val_loss: 0.3944 - val_accuracy: 0.8640\n",
      "Epoch 54/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6529 - accuracy: 0.68 - ETA: 0s - loss: 0.5723 - accuracy: 0.73 - 0s 5ms/step - loss: 0.5512 - accuracy: 0.7448 - val_loss: 0.3852 - val_accuracy: 0.8880\n",
      "Epoch 55/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.1929 - accuracy: 0.71 - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7767 - val_loss: 0.3954 - val_accuracy: 0.8640\n",
      "Epoch 56/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9539 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7751 - val_loss: 0.3898 - val_accuracy: 0.8640\n",
      "Epoch 57/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.65 - ETA: 0s - loss: 0.5458 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7624 - val_loss: 0.3793 - val_accuracy: 0.8800\n",
      "Epoch 58/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.8321 - accuracy: 0.56 - ETA: 0s - loss: 0.5706 - accuracy: 0.73 - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7496 - val_loss: 0.3847 - val_accuracy: 0.8640\n",
      "Epoch 59/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5693 - accuracy: 0.65 - ETA: 0s - loss: 0.5220 - accuracy: 0.77 - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7735 - val_loss: 0.3809 - val_accuracy: 0.8800\n",
      "Epoch 60/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7537 - accuracy: 0.65 - ETA: 0s - loss: 0.5163 - accuracy: 0.77 - 0s 5ms/step - loss: 0.5046 - accuracy: 0.7863 - val_loss: 0.3822 - val_accuracy: 0.8640\n",
      "Epoch 61/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.71 - ETA: 0s - loss: 0.5452 - accuracy: 0.77 - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7783 - val_loss: 0.3817 - val_accuracy: 0.8560\n",
      "Epoch 62/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7303 - accuracy: 0.75 - ETA: 0s - loss: 0.5877 - accuracy: 0.77 - 0s 6ms/step - loss: 0.5620 - accuracy: 0.7703 - val_loss: 0.3882 - val_accuracy: 0.8640\n",
      "Epoch 63/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.78 - ETA: 0s - loss: 0.5747 - accuracy: 0.77 - 0s 5ms/step - loss: 0.5680 - accuracy: 0.7751 - val_loss: 0.3822 - val_accuracy: 0.8640\n",
      "Epoch 64/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6647 - accuracy: 0.65 - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7656 - val_loss: 0.3753 - val_accuracy: 0.8720\n",
      "Epoch 65/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7409 - accuracy: 0.71 - ETA: 0s - loss: 0.5150 - accuracy: 0.77 - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7847 - val_loss: 0.3898 - val_accuracy: 0.8640\n",
      "Epoch 66/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5781 - accuracy: 0.71 - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7624 - val_loss: 0.3790 - val_accuracy: 0.8640\n",
      "Epoch 67/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5889 - accuracy: 0.75 - ETA: 0s - loss: 0.5422 - accuracy: 0.75 - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7751 - val_loss: 0.3747 - val_accuracy: 0.8720\n",
      "Epoch 68/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.62 - ETA: 0s - loss: 0.4950 - accuracy: 0.79 - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7943 - val_loss: 0.3672 - val_accuracy: 0.8720\n",
      "Epoch 69/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.68 - ETA: 0s - loss: 0.5172 - accuracy: 0.76 - 0s 5ms/step - loss: 0.5110 - accuracy: 0.7703 - val_loss: 0.3889 - val_accuracy: 0.8400\n",
      "Epoch 70/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.75 - ETA: 0s - loss: 0.5387 - accuracy: 0.79 - 0s 5ms/step - loss: 0.5235 - accuracy: 0.8006 - val_loss: 0.3658 - val_accuracy: 0.8720\n",
      "Epoch 71/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.71 - ETA: 0s - loss: 0.5315 - accuracy: 0.76 - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7735 - val_loss: 0.3885 - val_accuracy: 0.8480\n",
      "Epoch 72/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.71 - ETA: 0s - loss: 0.5065 - accuracy: 0.76 - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7799 - val_loss: 0.3685 - val_accuracy: 0.8800\n",
      "Epoch 73/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5887 - accuracy: 0.68 - ETA: 0s - loss: 0.5162 - accuracy: 0.77 - 0s 5ms/step - loss: 0.5042 - accuracy: 0.7831 - val_loss: 0.3658 - val_accuracy: 0.8720\n",
      "Epoch 74/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7198 - accuracy: 0.75 - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7895 - val_loss: 0.3704 - val_accuracy: 0.8720\n",
      "Epoch 75/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.8299 - accuracy: 0.78 - ETA: 0s - loss: 0.5581 - accuracy: 0.78 - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7879 - val_loss: 0.3954 - val_accuracy: 0.8240\n",
      "Epoch 76/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0754 - accuracy: 0.65 - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7576 - val_loss: 0.3629 - val_accuracy: 0.8800\n",
      "Epoch 77/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9396 - accuracy: 0.62 - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7783 - val_loss: 0.3723 - val_accuracy: 0.8800\n",
      "Epoch 78/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5689 - accuracy: 0.68 - ETA: 0s - loss: 0.4847 - accuracy: 0.79 - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7974 - val_loss: 0.3631 - val_accuracy: 0.8800\n",
      "Epoch 79/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.68 - ETA: 0s - loss: 0.5076 - accuracy: 0.77 - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7815 - val_loss: 0.3673 - val_accuracy: 0.8720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7997 - accuracy: 0.59 - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7735 - val_loss: 0.3624 - val_accuracy: 0.8720\n",
      "Epoch 81/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.65 - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7767 - val_loss: 0.3749 - val_accuracy: 0.8720\n",
      "Epoch 82/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.62 - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7847 - val_loss: 0.3658 - val_accuracy: 0.8720\n",
      "Epoch 83/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.81 - ETA: 0s - loss: 0.5158 - accuracy: 0.77 - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7815 - val_loss: 0.3657 - val_accuracy: 0.8640\n",
      "Epoch 84/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.75 - ETA: 0s - loss: 0.4789 - accuracy: 0.77 - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7815 - val_loss: 0.3579 - val_accuracy: 0.8640\n",
      "Epoch 85/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.71 - ETA: 0s - loss: 0.4905 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7927 - val_loss: 0.3675 - val_accuracy: 0.8560\n",
      "Epoch 86/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.84 - ETA: 0s - loss: 0.4921 - accuracy: 0.77 - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7799 - val_loss: 0.3635 - val_accuracy: 0.8560\n",
      "Epoch 87/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7144 - accuracy: 0.75 - ETA: 0s - loss: 0.4840 - accuracy: 0.79 - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7959 - val_loss: 0.3570 - val_accuracy: 0.8560\n",
      "Epoch 88/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5717 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4629 - accuracy: 0.8038 - val_loss: 0.3656 - val_accuracy: 0.8560\n",
      "Epoch 89/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5988 - accuracy: 0.71 - ETA: 0s - loss: 0.4761 - accuracy: 0.80 - 0s 5ms/step - loss: 0.4726 - accuracy: 0.8054 - val_loss: 0.3614 - val_accuracy: 0.8560\n",
      "Epoch 90/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.68 - ETA: 0s - loss: 0.5063 - accuracy: 0.76 - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7863 - val_loss: 0.3614 - val_accuracy: 0.8800\n",
      "Epoch 91/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5766 - accuracy: 0.71 - ETA: 0s - loss: 0.4957 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7943 - val_loss: 0.3625 - val_accuracy: 0.8640\n",
      "Epoch 92/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.65 - ETA: 0s - loss: 0.4855 - accuracy: 0.80 - 0s 5ms/step - loss: 0.4738 - accuracy: 0.8118 - val_loss: 0.3652 - val_accuracy: 0.8720\n",
      "Epoch 93/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.75 - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7974 - val_loss: 0.3626 - val_accuracy: 0.8640\n",
      "Epoch 94/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.81 - ETA: 0s - loss: 0.4918 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7959 - val_loss: 0.3600 - val_accuracy: 0.8640\n",
      "Epoch 95/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4759 - accuracy: 0.8150 - val_loss: 0.3580 - val_accuracy: 0.8640\n",
      "Epoch 96/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7911 - val_loss: 0.3626 - val_accuracy: 0.8560\n",
      "Epoch 97/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7974 - val_loss: 0.3579 - val_accuracy: 0.8640\n",
      "9/9 [==============================] - ETA: 1s - loss: 0.5083 - accuracy: 0.68 - 0s 22ms/step - loss: 0.5179 - accuracy: 0.7462\n",
      "Accuracy: [0.5179292294714186, 0.7462121]\n"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "# Initialize the classifier.\n",
    "clf = ak.StructuredDataClassifier(max_trials=30)\n",
    "# x is the path to the csv file. y is the column name of the column to predict.\n",
    "clf.fit(x='train.csv', y='survived')\n",
    "# Evaluate the accuracy of the found model.\n",
    "print('Accuracy: {accuracy}'.format(\n",
    "    accuracy=clf.evaluate(x='eval.csv', y='survived')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "a=clf.predict(x='train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= df.survived.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1786f72ae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=a-b\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1786f7ac208>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.plot(a[1:150], color='red')\n",
    "plt.plot(b[1:150], color='blue')\n",
    "plt.grid()\n",
    "plt.title('TITANIC SURVIVAL: MODEL(RED) VS. REALITY(BLUE)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = clf.evaluate(x='eval.csv', y='survived', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7462121"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TEXT CLASSIFIER: THE IMDB DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMDB Movie reviews sentiment classification**\n",
    "\n",
    "Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 20,000 most common words, but eliminate the top 20 most common words\".\n",
    "\n",
    "As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Returns:**\n",
    "\n",
    "> - 2 tuples: x_train, x_test: list of sequences, which are lists of indexes (integers). If the num_words argument was specific, the maximum possible index value is num_words-1. If the maxlen argument was specified, the largest possible sequence length is maxlen.\n",
    "> - y_train, y_test: list of integer labels (1 or 0).\n",
    "\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "> - path: if you do not have the data locally (at '~/.keras/datasets/' + path), it will be downloaded to this location.\n",
    "> - num_words: integer or None. Top most frequent words to consider. Any less frequent word will appear as oov_char value in the sequence data.\n",
    "> - skip_top: integer. Top most frequent words to ignore (they will appear as oov_char value in the sequence data).\n",
    "> - maxlen: int. Maximum sequence length. Any longer sequence will be truncated.\n",
    "> - seed: int. Seed for reproducible data shuffling.\n",
    "> - start_char: int. The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.\n",
    "> - oov_char: int. words that were cut out because of the num_words or skip_top limit will be replaced with this character.\n",
    "> - index_from: int. Index actual words with this index and higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000, 1)\n",
      "<START> this film was just brilliant casting locat\n",
      "Train for 625 steps, validate for 157 steps\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/625 [=======>......................] - ETA: 10:37 - loss: 0.6820 - accuracy: 0.593 - ETA: 5:52 - loss: 0.6800 - accuracy: 0.609 - ETA: 4:17 - loss: 0.6820 - accuracy: 0.58 - ETA: 3:32 - loss: 0.6836 - accuracy: 0.57 - ETA: 3:03 - loss: 0.6833 - accuracy: 0.58 - ETA: 2:44 - loss: 0.6835 - accuracy: 0.57 - ETA: 2:31 - loss: 0.6865 - accuracy: 0.56 - ETA: 2:20 - loss: 0.6973 - accuracy: 0.54 - ETA: 2:12 - loss: 0.7043 - accuracy: 0.52 - ETA: 2:06 - loss: 0.7027 - accuracy: 0.52 - ETA: 2:01 - loss: 0.7036 - accuracy: 0.50 - ETA: 1:57 - loss: 0.7027 - accuracy: 0.51 - ETA: 1:53 - loss: 0.7013 - accuracy: 0.53 - ETA: 1:49 - loss: 0.6998 - accuracy: 0.53 - ETA: 1:46 - loss: 0.6982 - accuracy: 0.54 - ETA: 1:44 - loss: 0.6988 - accuracy: 0.54 - ETA: 1:42 - loss: 0.6995 - accuracy: 0.53 - ETA: 1:40 - loss: 0.6995 - accuracy: 0.53 - ETA: 1:38 - loss: 0.6979 - accuracy: 0.54 - ETA: 1:37 - loss: 0.6987 - accuracy: 0.53 - ETA: 1:36 - loss: 0.6985 - accuracy: 0.53 - ETA: 1:34 - loss: 0.6988 - accuracy: 0.53 - ETA: 1:33 - loss: 0.6989 - accuracy: 0.53 - ETA: 1:31 - loss: 0.7002 - accuracy: 0.52 - ETA: 1:30 - loss: 0.6993 - accuracy: 0.52 - ETA: 1:29 - loss: 0.6996 - accuracy: 0.52 - ETA: 1:28 - loss: 0.6996 - accuracy: 0.52 - ETA: 1:27 - loss: 0.6992 - accuracy: 0.52 - ETA: 1:26 - loss: 0.6998 - accuracy: 0.51 - ETA: 1:26 - loss: 0.6998 - accuracy: 0.51 - ETA: 1:25 - loss: 0.6999 - accuracy: 0.50 - ETA: 1:24 - loss: 0.7001 - accuracy: 0.50 - ETA: 1:24 - loss: 0.7002 - accuracy: 0.50 - ETA: 1:23 - loss: 0.6999 - accuracy: 0.50 - ETA: 1:22 - loss: 0.6998 - accuracy: 0.50 - ETA: 1:22 - loss: 0.6995 - accuracy: 0.50 - ETA: 1:21 - loss: 0.6994 - accuracy: 0.50 - ETA: 1:21 - loss: 0.6992 - accuracy: 0.50 - ETA: 1:21 - loss: 0.6982 - accuracy: 0.50 - ETA: 1:21 - loss: 0.6979 - accuracy: 0.51 - ETA: 1:20 - loss: 0.6979 - accuracy: 0.50 - ETA: 1:20 - loss: 0.6977 - accuracy: 0.51 - ETA: 1:20 - loss: 0.6978 - accuracy: 0.50 - ETA: 1:20 - loss: 0.6982 - accuracy: 0.50 - ETA: 1:19 - loss: 0.6983 - accuracy: 0.50 - ETA: 1:19 - loss: 0.6988 - accuracy: 0.50 - ETA: 1:18 - loss: 0.6987 - accuracy: 0.50 - ETA: 1:18 - loss: 0.6984 - accuracy: 0.50 - ETA: 1:17 - loss: 0.6986 - accuracy: 0.50 - ETA: 1:17 - loss: 0.6986 - accuracy: 0.50 - ETA: 1:17 - loss: 0.6985 - accuracy: 0.50 - ETA: 1:16 - loss: 0.6984 - accuracy: 0.50 - ETA: 1:16 - loss: 0.6980 - accuracy: 0.50 - ETA: 1:16 - loss: 0.6979 - accuracy: 0.50 - ETA: 1:15 - loss: 0.6980 - accuracy: 0.50 - ETA: 1:15 - loss: 0.6980 - accuracy: 0.50 - ETA: 1:14 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:14 - loss: 0.6983 - accuracy: 0.50 - ETA: 1:14 - loss: 0.6990 - accuracy: 0.50 - ETA: 1:13 - loss: 0.6985 - accuracy: 0.50 - ETA: 1:13 - loss: 0.6979 - accuracy: 0.50 - ETA: 1:13 - loss: 0.6978 - accuracy: 0.50 - ETA: 1:12 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:12 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:12 - loss: 0.6985 - accuracy: 0.50 - ETA: 1:12 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:11 - loss: 0.6977 - accuracy: 0.50 - ETA: 1:11 - loss: 0.6974 - accuracy: 0.50 - ETA: 1:11 - loss: 0.6972 - accuracy: 0.51 - ETA: 1:10 - loss: 0.6974 - accuracy: 0.50 - ETA: 1:10 - loss: 0.6970 - accuracy: 0.50 - ETA: 1:10 - loss: 0.6973 - accuracy: 0.50 - ETA: 1:09 - loss: 0.6972 - accuracy: 0.50 - ETA: 1:09 - loss: 0.6970 - accuracy: 0.50 - ETA: 1:09 - loss: 0.6972 - accuracy: 0.50 - ETA: 1:08 - loss: 0.6973 - accuracy: 0.50 - ETA: 1:08 - loss: 0.6975 - accuracy: 0.50 - ETA: 1:08 - loss: 0.6972 - accuracy: 0.50 - ETA: 1:08 - loss: 0.6976 - accuracy: 0.50 - ETA: 1:07 - loss: 0.6975 - accuracy: 0.50 - ETA: 1:07 - loss: 0.6974 - accuracy: 0.50 - ETA: 1:07 - loss: 0.6975 - accuracy: 0.50 - ETA: 1:07 - loss: 0.6973 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6973 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6973 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6971 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:05 - loss: 0.6971 - accuracy: 0.50 - ETA: 1:05 - loss: 0.6970 - accuracy: 0.50 - ETA: 1:05 - loss: 0.6970 - accuracy: 0.50 - ETA: 1:05 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:04 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:04 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:04 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:04 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:04 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:03 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:03 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:03 - loss: 0.6966 - accuracy: 0.50 - ETA: 1:03 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:03 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:02 - loss: 0.6965 - accuracy: 0.50 - ETA: 1:02 - loss: 0.6964 - accuracy: 0.50 - ETA: 1:02 - loss: 0.6963 - accuracy: 0.50 - ETA: 1:02 - loss: 0.6964 - accuracy: 0.50 - ETA: 1:02 - loss: 0.6963 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6963 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6963 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6961 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6960 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6959 - accuracy: 0.51 - ETA: 1:01 - loss: 0.6958 - accuracy: 0.51 - ETA: 1:01 - loss: 0.6958 - accuracy: 0.51 - ETA: 1:00 - loss: 0.6957 - accuracy: 0.51 - ETA: 1:00 - loss: 0.6957 - accuracy: 0.51 - ETA: 1:00 - loss: 0.6956 - accuracy: 0.51 - ETA: 1:00 - loss: 0.6954 - accuracy: 0.51 - ETA: 1:00 - loss: 0.6953 - accuracy: 0.51 - ETA: 1:00 - loss: 0.6954 - accuracy: 0.51 - ETA: 1:00 - loss: 0.6953 - accuracy: 0.51 - ETA: 1:00 - loss: 0.6951 - accuracy: 0.51 - ETA: 59s - loss: 0.6949 - accuracy: 0.5132 - ETA: 59s - loss: 0.6949 - accuracy: 0.513 - ETA: 59s - loss: 0.6948 - accuracy: 0.514 - ETA: 59s - loss: 0.6946 - accuracy: 0.515 - ETA: 59s - loss: 0.6946 - accuracy: 0.514 - ETA: 59s - loss: 0.6944 - accuracy: 0.514 - ETA: 59s - loss: 0.6941 - accuracy: 0.515 - ETA: 59s - loss: 0.6939 - accuracy: 0.516 - ETA: 58s - loss: 0.6939 - accuracy: 0.516 - ETA: 58s - loss: 0.6937 - accuracy: 0.515 - ETA: 58s - loss: 0.6934 - accuracy: 0.516 - ETA: 58s - loss: 0.6931 - accuracy: 0.517 - ETA: 58s - loss: 0.6930 - accuracy: 0.516 - ETA: 58s - loss: 0.6928 - accuracy: 0.518 - ETA: 58s - loss: 0.6926 - accuracy: 0.518 - ETA: 57s - loss: 0.6926 - accuracy: 0.518 - ETA: 57s - loss: 0.6923 - accuracy: 0.519 - ETA: 57s - loss: 0.6919 - accuracy: 0.520 - ETA: 57s - loss: 0.6916 - accuracy: 0.522 - ETA: 57s - loss: 0.6914 - accuracy: 0.522 - ETA: 57s - loss: 0.6910 - accuracy: 0.523 - ETA: 57s - loss: 0.6907 - accuracy: 0.524 - ETA: 57s - loss: 0.6906 - accuracy: 0.525 - ETA: 56s - loss: 0.6904 - accuracy: 0.525 - ETA: 56s - loss: 0.6902 - accuracy: 0.525 - ETA: 56s - loss: 0.6898 - accuracy: 0.526 - ETA: 56s - loss: 0.6897 - accuracy: 0.526 - ETA: 56s - loss: 0.6894 - accuracy: 0.527 - ETA: 56s - loss: 0.6890 - accuracy: 0.527 - ETA: 56s - loss: 0.6884 - accuracy: 0.528 - ETA: 55s - loss: 0.6883 - accuracy: 0.529 - ETA: 55s - loss: 0.6884 - accuracy: 0.529 - ETA: 55s - loss: 0.6880 - accuracy: 0.530 - ETA: 55s - loss: 0.6877 - accuracy: 0.530 - ETA: 55s - loss: 0.6871 - accuracy: 0.532 - ETA: 55s - loss: 0.6868 - accuracy: 0.533 - ETA: 55s - loss: 0.6862 - accuracy: 0.534 - ETA: 55s - loss: 0.6859 - accuracy: 0.534 - ETA: 54s - loss: 0.6855 - accuracy: 0.535 - ETA: 54s - loss: 0.6849 - accuracy: 0.536 - ETA: 54s - loss: 0.6847 - accuracy: 0.537 - ETA: 54s - loss: 0.6844 - accuracy: 0.538 - ETA: 54s - loss: 0.6840 - accuracy: 0.539 - ETA: 54s - loss: 0.6833 - accuracy: 0.540 - ETA: 54s - loss: 0.6832 - accuracy: 0.541 - ETA: 54s - loss: 0.6830 - accuracy: 0.542 - ETA: 53s - loss: 0.6825 - accuracy: 0.543 - ETA: 53s - loss: 0.6820 - accuracy: 0.544 - ETA: 53s - loss: 0.6819 - accuracy: 0.545 - ETA: 53s - loss: 0.6817 - accuracy: 0.545 - ETA: 53s - loss: 0.6805 - accuracy: 0.547 - ETA: 53s - loss: 0.6800 - accuracy: 0.548 - ETA: 53s - loss: 0.6795 - accuracy: 0.548 - ETA: 52s - loss: 0.6794 - accuracy: 0.549 - ETA: 52s - loss: 0.6794 - accuracy: 0.549 - ETA: 52s - loss: 0.6792 - accuracy: 0.549 - ETA: 52s - loss: 0.6784 - accuracy: 0.550 - ETA: 52s - loss: 0.6778 - accuracy: 0.551 - ETA: 52s - loss: 0.6773 - accuracy: 0.553 - ETA: 52s - loss: 0.6770 - accuracy: 0.553 - ETA: 52s - loss: 0.6760 - accuracy: 0.555 - ETA: 51s - loss: 0.6754 - accuracy: 0.555 - ETA: 51s - loss: 0.6747 - accuracy: 0.556 - ETA: 51s - loss: 0.6737 - accuracy: 0.5583"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/625 [================>.............] - ETA: 51s - loss: 0.6732 - accuracy: 0.559 - ETA: 51s - loss: 0.6725 - accuracy: 0.560 - ETA: 51s - loss: 0.6719 - accuracy: 0.560 - ETA: 51s - loss: 0.6719 - accuracy: 0.561 - ETA: 51s - loss: 0.6720 - accuracy: 0.561 - ETA: 50s - loss: 0.6719 - accuracy: 0.562 - ETA: 50s - loss: 0.6713 - accuracy: 0.563 - ETA: 50s - loss: 0.6709 - accuracy: 0.563 - ETA: 50s - loss: 0.6711 - accuracy: 0.563 - ETA: 50s - loss: 0.6704 - accuracy: 0.564 - ETA: 50s - loss: 0.6693 - accuracy: 0.566 - ETA: 50s - loss: 0.6687 - accuracy: 0.567 - ETA: 50s - loss: 0.6679 - accuracy: 0.568 - ETA: 49s - loss: 0.6673 - accuracy: 0.568 - ETA: 49s - loss: 0.6672 - accuracy: 0.569 - ETA: 49s - loss: 0.6662 - accuracy: 0.570 - ETA: 49s - loss: 0.6650 - accuracy: 0.572 - ETA: 49s - loss: 0.6639 - accuracy: 0.573 - ETA: 49s - loss: 0.6635 - accuracy: 0.574 - ETA: 49s - loss: 0.6626 - accuracy: 0.575 - ETA: 49s - loss: 0.6616 - accuracy: 0.576 - ETA: 48s - loss: 0.6605 - accuracy: 0.578 - ETA: 48s - loss: 0.6602 - accuracy: 0.578 - ETA: 48s - loss: 0.6596 - accuracy: 0.578 - ETA: 48s - loss: 0.6589 - accuracy: 0.579 - ETA: 48s - loss: 0.6587 - accuracy: 0.580 - ETA: 48s - loss: 0.6576 - accuracy: 0.581 - ETA: 48s - loss: 0.6570 - accuracy: 0.581 - ETA: 48s - loss: 0.6561 - accuracy: 0.582 - ETA: 47s - loss: 0.6551 - accuracy: 0.584 - ETA: 47s - loss: 0.6538 - accuracy: 0.585 - ETA: 47s - loss: 0.6528 - accuracy: 0.586 - ETA: 47s - loss: 0.6521 - accuracy: 0.587 - ETA: 47s - loss: 0.6516 - accuracy: 0.587 - ETA: 47s - loss: 0.6516 - accuracy: 0.588 - ETA: 47s - loss: 0.6502 - accuracy: 0.589 - ETA: 47s - loss: 0.6493 - accuracy: 0.590 - ETA: 47s - loss: 0.6484 - accuracy: 0.591 - ETA: 46s - loss: 0.6478 - accuracy: 0.591 - ETA: 46s - loss: 0.6470 - accuracy: 0.592 - ETA: 46s - loss: 0.6459 - accuracy: 0.593 - ETA: 46s - loss: 0.6456 - accuracy: 0.594 - ETA: 46s - loss: 0.6442 - accuracy: 0.595 - ETA: 46s - loss: 0.6439 - accuracy: 0.595 - ETA: 46s - loss: 0.6430 - accuracy: 0.596 - ETA: 46s - loss: 0.6421 - accuracy: 0.598 - ETA: 46s - loss: 0.6407 - accuracy: 0.599 - ETA: 45s - loss: 0.6400 - accuracy: 0.599 - ETA: 45s - loss: 0.6392 - accuracy: 0.600 - ETA: 45s - loss: 0.6381 - accuracy: 0.601 - ETA: 45s - loss: 0.6373 - accuracy: 0.602 - ETA: 45s - loss: 0.6372 - accuracy: 0.602 - ETA: 45s - loss: 0.6369 - accuracy: 0.602 - ETA: 45s - loss: 0.6363 - accuracy: 0.603 - ETA: 45s - loss: 0.6361 - accuracy: 0.603 - ETA: 44s - loss: 0.6361 - accuracy: 0.603 - ETA: 44s - loss: 0.6352 - accuracy: 0.604 - ETA: 44s - loss: 0.6347 - accuracy: 0.605 - ETA: 44s - loss: 0.6336 - accuracy: 0.606 - ETA: 44s - loss: 0.6326 - accuracy: 0.607 - ETA: 44s - loss: 0.6316 - accuracy: 0.608 - ETA: 44s - loss: 0.6313 - accuracy: 0.608 - ETA: 44s - loss: 0.6302 - accuracy: 0.609 - ETA: 43s - loss: 0.6290 - accuracy: 0.610 - ETA: 43s - loss: 0.6284 - accuracy: 0.611 - ETA: 43s - loss: 0.6274 - accuracy: 0.611 - ETA: 43s - loss: 0.6265 - accuracy: 0.612 - ETA: 43s - loss: 0.6259 - accuracy: 0.613 - ETA: 43s - loss: 0.6256 - accuracy: 0.614 - ETA: 43s - loss: 0.6250 - accuracy: 0.614 - ETA: 43s - loss: 0.6247 - accuracy: 0.615 - ETA: 42s - loss: 0.6238 - accuracy: 0.615 - ETA: 42s - loss: 0.6230 - accuracy: 0.616 - ETA: 42s - loss: 0.6225 - accuracy: 0.616 - ETA: 42s - loss: 0.6216 - accuracy: 0.617 - ETA: 42s - loss: 0.6212 - accuracy: 0.618 - ETA: 42s - loss: 0.6208 - accuracy: 0.619 - ETA: 42s - loss: 0.6198 - accuracy: 0.620 - ETA: 42s - loss: 0.6191 - accuracy: 0.620 - ETA: 41s - loss: 0.6189 - accuracy: 0.621 - ETA: 41s - loss: 0.6180 - accuracy: 0.621 - ETA: 41s - loss: 0.6171 - accuracy: 0.622 - ETA: 41s - loss: 0.6162 - accuracy: 0.623 - ETA: 41s - loss: 0.6156 - accuracy: 0.623 - ETA: 41s - loss: 0.6148 - accuracy: 0.624 - ETA: 41s - loss: 0.6143 - accuracy: 0.625 - ETA: 41s - loss: 0.6135 - accuracy: 0.626 - ETA: 40s - loss: 0.6125 - accuracy: 0.627 - ETA: 40s - loss: 0.6121 - accuracy: 0.627 - ETA: 40s - loss: 0.6119 - accuracy: 0.627 - ETA: 40s - loss: 0.6110 - accuracy: 0.628 - ETA: 40s - loss: 0.6104 - accuracy: 0.628 - ETA: 40s - loss: 0.6100 - accuracy: 0.629 - ETA: 40s - loss: 0.6087 - accuracy: 0.630 - ETA: 40s - loss: 0.6075 - accuracy: 0.631 - ETA: 40s - loss: 0.6067 - accuracy: 0.631 - ETA: 39s - loss: 0.6055 - accuracy: 0.633 - ETA: 39s - loss: 0.6044 - accuracy: 0.633 - ETA: 39s - loss: 0.6037 - accuracy: 0.634 - ETA: 39s - loss: 0.6031 - accuracy: 0.634 - ETA: 39s - loss: 0.6026 - accuracy: 0.635 - ETA: 39s - loss: 0.6017 - accuracy: 0.636 - ETA: 39s - loss: 0.6004 - accuracy: 0.637 - ETA: 39s - loss: 0.6001 - accuracy: 0.637 - ETA: 38s - loss: 0.5996 - accuracy: 0.638 - ETA: 38s - loss: 0.5989 - accuracy: 0.638 - ETA: 38s - loss: 0.5984 - accuracy: 0.639 - ETA: 38s - loss: 0.5982 - accuracy: 0.639 - ETA: 38s - loss: 0.5971 - accuracy: 0.640 - ETA: 38s - loss: 0.5970 - accuracy: 0.640 - ETA: 38s - loss: 0.5958 - accuracy: 0.641 - ETA: 38s - loss: 0.5954 - accuracy: 0.641 - ETA: 37s - loss: 0.5949 - accuracy: 0.642 - ETA: 37s - loss: 0.5946 - accuracy: 0.642 - ETA: 37s - loss: 0.5939 - accuracy: 0.643 - ETA: 37s - loss: 0.5932 - accuracy: 0.643 - ETA: 37s - loss: 0.5921 - accuracy: 0.644 - ETA: 37s - loss: 0.5919 - accuracy: 0.645 - ETA: 37s - loss: 0.5905 - accuracy: 0.646 - ETA: 37s - loss: 0.5897 - accuracy: 0.646 - ETA: 37s - loss: 0.5890 - accuracy: 0.647 - ETA: 36s - loss: 0.5887 - accuracy: 0.647 - ETA: 36s - loss: 0.5882 - accuracy: 0.648 - ETA: 36s - loss: 0.5879 - accuracy: 0.648 - ETA: 36s - loss: 0.5875 - accuracy: 0.649 - ETA: 36s - loss: 0.5867 - accuracy: 0.649 - ETA: 36s - loss: 0.5860 - accuracy: 0.650 - ETA: 36s - loss: 0.5854 - accuracy: 0.650 - ETA: 36s - loss: 0.5853 - accuracy: 0.650 - ETA: 35s - loss: 0.5858 - accuracy: 0.651 - ETA: 35s - loss: 0.5854 - accuracy: 0.651 - ETA: 35s - loss: 0.5849 - accuracy: 0.651 - ETA: 35s - loss: 0.5840 - accuracy: 0.652 - ETA: 35s - loss: 0.5834 - accuracy: 0.653 - ETA: 35s - loss: 0.5828 - accuracy: 0.653 - ETA: 35s - loss: 0.5823 - accuracy: 0.654 - ETA: 35s - loss: 0.5818 - accuracy: 0.654 - ETA: 34s - loss: 0.5813 - accuracy: 0.655 - ETA: 34s - loss: 0.5806 - accuracy: 0.655 - ETA: 34s - loss: 0.5801 - accuracy: 0.656 - ETA: 34s - loss: 0.5797 - accuracy: 0.656 - ETA: 34s - loss: 0.5792 - accuracy: 0.656 - ETA: 34s - loss: 0.5788 - accuracy: 0.657 - ETA: 34s - loss: 0.5784 - accuracy: 0.657 - ETA: 34s - loss: 0.5778 - accuracy: 0.658 - ETA: 33s - loss: 0.5773 - accuracy: 0.658 - ETA: 33s - loss: 0.5762 - accuracy: 0.659 - ETA: 33s - loss: 0.5754 - accuracy: 0.660 - ETA: 33s - loss: 0.5749 - accuracy: 0.660 - ETA: 33s - loss: 0.5738 - accuracy: 0.661 - ETA: 33s - loss: 0.5733 - accuracy: 0.662 - ETA: 33s - loss: 0.5732 - accuracy: 0.662 - ETA: 33s - loss: 0.5728 - accuracy: 0.662 - ETA: 33s - loss: 0.5719 - accuracy: 0.663 - ETA: 32s - loss: 0.5716 - accuracy: 0.663 - ETA: 32s - loss: 0.5708 - accuracy: 0.664 - ETA: 32s - loss: 0.5701 - accuracy: 0.665 - ETA: 32s - loss: 0.5697 - accuracy: 0.665 - ETA: 32s - loss: 0.5690 - accuracy: 0.666 - ETA: 32s - loss: 0.5681 - accuracy: 0.667 - ETA: 32s - loss: 0.5680 - accuracy: 0.667 - ETA: 32s - loss: 0.5675 - accuracy: 0.668 - ETA: 31s - loss: 0.5665 - accuracy: 0.668 - ETA: 31s - loss: 0.5658 - accuracy: 0.669 - ETA: 31s - loss: 0.5652 - accuracy: 0.669 - ETA: 31s - loss: 0.5644 - accuracy: 0.670 - ETA: 31s - loss: 0.5638 - accuracy: 0.670 - ETA: 31s - loss: 0.5633 - accuracy: 0.671 - ETA: 31s - loss: 0.5624 - accuracy: 0.672 - ETA: 31s - loss: 0.5622 - accuracy: 0.672 - ETA: 31s - loss: 0.5618 - accuracy: 0.673 - ETA: 30s - loss: 0.5612 - accuracy: 0.673 - ETA: 30s - loss: 0.5604 - accuracy: 0.674 - ETA: 30s - loss: 0.5598 - accuracy: 0.674 - ETA: 30s - loss: 0.5591 - accuracy: 0.675 - ETA: 30s - loss: 0.5586 - accuracy: 0.675 - ETA: 30s - loss: 0.5583 - accuracy: 0.676 - ETA: 30s - loss: 0.5579 - accuracy: 0.676 - ETA: 30s - loss: 0.5578 - accuracy: 0.676 - ETA: 30s - loss: 0.5579 - accuracy: 0.677 - ETA: 29s - loss: 0.5571 - accuracy: 0.677 - ETA: 29s - loss: 0.5568 - accuracy: 0.678 - ETA: 29s - loss: 0.5563 - accuracy: 0.678 - ETA: 29s - loss: 0.5562 - accuracy: 0.678 - ETA: 29s - loss: 0.5558 - accuracy: 0.679 - ETA: 29s - loss: 0.5554 - accuracy: 0.6796"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559/625 [=========================>....] - ETA: 29s - loss: 0.5548 - accuracy: 0.680 - ETA: 29s - loss: 0.5542 - accuracy: 0.680 - ETA: 28s - loss: 0.5541 - accuracy: 0.680 - ETA: 28s - loss: 0.5537 - accuracy: 0.680 - ETA: 28s - loss: 0.5532 - accuracy: 0.681 - ETA: 28s - loss: 0.5526 - accuracy: 0.681 - ETA: 28s - loss: 0.5520 - accuracy: 0.682 - ETA: 28s - loss: 0.5513 - accuracy: 0.683 - ETA: 28s - loss: 0.5515 - accuracy: 0.683 - ETA: 28s - loss: 0.5514 - accuracy: 0.683 - ETA: 28s - loss: 0.5507 - accuracy: 0.684 - ETA: 27s - loss: 0.5505 - accuracy: 0.684 - ETA: 27s - loss: 0.5499 - accuracy: 0.684 - ETA: 27s - loss: 0.5499 - accuracy: 0.684 - ETA: 27s - loss: 0.5500 - accuracy: 0.684 - ETA: 27s - loss: 0.5496 - accuracy: 0.685 - ETA: 27s - loss: 0.5491 - accuracy: 0.685 - ETA: 27s - loss: 0.5489 - accuracy: 0.685 - ETA: 27s - loss: 0.5487 - accuracy: 0.686 - ETA: 26s - loss: 0.5486 - accuracy: 0.686 - ETA: 26s - loss: 0.5482 - accuracy: 0.686 - ETA: 26s - loss: 0.5479 - accuracy: 0.686 - ETA: 26s - loss: 0.5473 - accuracy: 0.687 - ETA: 26s - loss: 0.5468 - accuracy: 0.687 - ETA: 26s - loss: 0.5468 - accuracy: 0.687 - ETA: 26s - loss: 0.5464 - accuracy: 0.688 - ETA: 26s - loss: 0.5460 - accuracy: 0.688 - ETA: 25s - loss: 0.5453 - accuracy: 0.689 - ETA: 25s - loss: 0.5452 - accuracy: 0.689 - ETA: 25s - loss: 0.5445 - accuracy: 0.690 - ETA: 25s - loss: 0.5441 - accuracy: 0.690 - ETA: 25s - loss: 0.5435 - accuracy: 0.691 - ETA: 25s - loss: 0.5432 - accuracy: 0.691 - ETA: 25s - loss: 0.5430 - accuracy: 0.691 - ETA: 25s - loss: 0.5424 - accuracy: 0.692 - ETA: 25s - loss: 0.5420 - accuracy: 0.692 - ETA: 24s - loss: 0.5413 - accuracy: 0.693 - ETA: 24s - loss: 0.5411 - accuracy: 0.693 - ETA: 24s - loss: 0.5404 - accuracy: 0.693 - ETA: 24s - loss: 0.5399 - accuracy: 0.693 - ETA: 24s - loss: 0.5395 - accuracy: 0.694 - ETA: 24s - loss: 0.5388 - accuracy: 0.695 - ETA: 24s - loss: 0.5383 - accuracy: 0.695 - ETA: 24s - loss: 0.5378 - accuracy: 0.695 - ETA: 23s - loss: 0.5371 - accuracy: 0.696 - ETA: 23s - loss: 0.5368 - accuracy: 0.696 - ETA: 23s - loss: 0.5363 - accuracy: 0.697 - ETA: 23s - loss: 0.5358 - accuracy: 0.697 - ETA: 23s - loss: 0.5352 - accuracy: 0.697 - ETA: 23s - loss: 0.5345 - accuracy: 0.698 - ETA: 23s - loss: 0.5339 - accuracy: 0.698 - ETA: 23s - loss: 0.5331 - accuracy: 0.699 - ETA: 23s - loss: 0.5328 - accuracy: 0.699 - ETA: 22s - loss: 0.5323 - accuracy: 0.699 - ETA: 22s - loss: 0.5320 - accuracy: 0.699 - ETA: 22s - loss: 0.5314 - accuracy: 0.700 - ETA: 22s - loss: 0.5311 - accuracy: 0.700 - ETA: 22s - loss: 0.5309 - accuracy: 0.700 - ETA: 22s - loss: 0.5304 - accuracy: 0.701 - ETA: 22s - loss: 0.5299 - accuracy: 0.701 - ETA: 22s - loss: 0.5298 - accuracy: 0.701 - ETA: 22s - loss: 0.5295 - accuracy: 0.702 - ETA: 21s - loss: 0.5292 - accuracy: 0.702 - ETA: 21s - loss: 0.5285 - accuracy: 0.702 - ETA: 21s - loss: 0.5286 - accuracy: 0.703 - ETA: 21s - loss: 0.5280 - accuracy: 0.703 - ETA: 21s - loss: 0.5276 - accuracy: 0.703 - ETA: 21s - loss: 0.5276 - accuracy: 0.703 - ETA: 21s - loss: 0.5271 - accuracy: 0.704 - ETA: 21s - loss: 0.5268 - accuracy: 0.704 - ETA: 20s - loss: 0.5270 - accuracy: 0.704 - ETA: 20s - loss: 0.5266 - accuracy: 0.705 - ETA: 20s - loss: 0.5262 - accuracy: 0.705 - ETA: 20s - loss: 0.5258 - accuracy: 0.706 - ETA: 20s - loss: 0.5253 - accuracy: 0.706 - ETA: 20s - loss: 0.5245 - accuracy: 0.707 - ETA: 20s - loss: 0.5240 - accuracy: 0.707 - ETA: 20s - loss: 0.5238 - accuracy: 0.707 - ETA: 20s - loss: 0.5238 - accuracy: 0.707 - ETA: 19s - loss: 0.5233 - accuracy: 0.708 - ETA: 19s - loss: 0.5230 - accuracy: 0.708 - ETA: 19s - loss: 0.5227 - accuracy: 0.708 - ETA: 19s - loss: 0.5222 - accuracy: 0.708 - ETA: 19s - loss: 0.5215 - accuracy: 0.709 - ETA: 19s - loss: 0.5212 - accuracy: 0.709 - ETA: 19s - loss: 0.5210 - accuracy: 0.709 - ETA: 19s - loss: 0.5204 - accuracy: 0.710 - ETA: 19s - loss: 0.5201 - accuracy: 0.710 - ETA: 18s - loss: 0.5196 - accuracy: 0.711 - ETA: 18s - loss: 0.5189 - accuracy: 0.711 - ETA: 18s - loss: 0.5187 - accuracy: 0.711 - ETA: 18s - loss: 0.5183 - accuracy: 0.711 - ETA: 18s - loss: 0.5179 - accuracy: 0.712 - ETA: 18s - loss: 0.5177 - accuracy: 0.712 - ETA: 18s - loss: 0.5174 - accuracy: 0.712 - ETA: 18s - loss: 0.5168 - accuracy: 0.712 - ETA: 17s - loss: 0.5163 - accuracy: 0.713 - ETA: 17s - loss: 0.5165 - accuracy: 0.713 - ETA: 17s - loss: 0.5161 - accuracy: 0.713 - ETA: 17s - loss: 0.5159 - accuracy: 0.713 - ETA: 17s - loss: 0.5157 - accuracy: 0.713 - ETA: 17s - loss: 0.5154 - accuracy: 0.713 - ETA: 17s - loss: 0.5148 - accuracy: 0.714 - ETA: 17s - loss: 0.5143 - accuracy: 0.714 - ETA: 17s - loss: 0.5139 - accuracy: 0.715 - ETA: 16s - loss: 0.5143 - accuracy: 0.715 - ETA: 16s - loss: 0.5139 - accuracy: 0.715 - ETA: 16s - loss: 0.5134 - accuracy: 0.715 - ETA: 16s - loss: 0.5127 - accuracy: 0.716 - ETA: 16s - loss: 0.5123 - accuracy: 0.716 - ETA: 16s - loss: 0.5118 - accuracy: 0.717 - ETA: 16s - loss: 0.5111 - accuracy: 0.717 - ETA: 16s - loss: 0.5107 - accuracy: 0.718 - ETA: 16s - loss: 0.5102 - accuracy: 0.718 - ETA: 15s - loss: 0.5099 - accuracy: 0.718 - ETA: 15s - loss: 0.5096 - accuracy: 0.718 - ETA: 15s - loss: 0.5093 - accuracy: 0.719 - ETA: 15s - loss: 0.5088 - accuracy: 0.719 - ETA: 15s - loss: 0.5082 - accuracy: 0.719 - ETA: 15s - loss: 0.5079 - accuracy: 0.720 - ETA: 15s - loss: 0.5075 - accuracy: 0.720 - ETA: 15s - loss: 0.5071 - accuracy: 0.720 - ETA: 14s - loss: 0.5068 - accuracy: 0.720 - ETA: 14s - loss: 0.5065 - accuracy: 0.721 - ETA: 14s - loss: 0.5059 - accuracy: 0.721 - ETA: 14s - loss: 0.5056 - accuracy: 0.722 - ETA: 14s - loss: 0.5053 - accuracy: 0.722 - ETA: 14s - loss: 0.5051 - accuracy: 0.722 - ETA: 14s - loss: 0.5050 - accuracy: 0.722 - ETA: 14s - loss: 0.5046 - accuracy: 0.722 - ETA: 14s - loss: 0.5040 - accuracy: 0.723 - ETA: 13s - loss: 0.5033 - accuracy: 0.723 - ETA: 13s - loss: 0.5031 - accuracy: 0.723 - ETA: 13s - loss: 0.5029 - accuracy: 0.724 - ETA: 13s - loss: 0.5025 - accuracy: 0.724 - ETA: 13s - loss: 0.5025 - accuracy: 0.724 - ETA: 13s - loss: 0.5021 - accuracy: 0.725 - ETA: 13s - loss: 0.5018 - accuracy: 0.725 - ETA: 13s - loss: 0.5017 - accuracy: 0.725 - ETA: 12s - loss: 0.5012 - accuracy: 0.725 - ETA: 12s - loss: 0.5010 - accuracy: 0.725 - ETA: 12s - loss: 0.5009 - accuracy: 0.726 - ETA: 12s - loss: 0.5006 - accuracy: 0.726 - ETA: 12s - loss: 0.5004 - accuracy: 0.726 - ETA: 12s - loss: 0.5000 - accuracy: 0.726 - ETA: 12s - loss: 0.4999 - accuracy: 0.726 - ETA: 12s - loss: 0.4996 - accuracy: 0.727 - ETA: 12s - loss: 0.4990 - accuracy: 0.727 - ETA: 11s - loss: 0.4987 - accuracy: 0.727 - ETA: 11s - loss: 0.4982 - accuracy: 0.728 - ETA: 11s - loss: 0.4978 - accuracy: 0.728 - ETA: 11s - loss: 0.4974 - accuracy: 0.728 - ETA: 11s - loss: 0.4973 - accuracy: 0.729 - ETA: 11s - loss: 0.4969 - accuracy: 0.729 - ETA: 11s - loss: 0.4967 - accuracy: 0.729 - ETA: 11s - loss: 0.4962 - accuracy: 0.729 - ETA: 11s - loss: 0.4961 - accuracy: 0.730 - ETA: 10s - loss: 0.4957 - accuracy: 0.730 - ETA: 10s - loss: 0.4953 - accuracy: 0.730 - ETA: 10s - loss: 0.4950 - accuracy: 0.730 - ETA: 10s - loss: 0.4946 - accuracy: 0.730 - ETA: 10s - loss: 0.4942 - accuracy: 0.731 - ETA: 10s - loss: 0.4937 - accuracy: 0.731 - ETA: 10s - loss: 0.4934 - accuracy: 0.731 - ETA: 10s - loss: 0.4931 - accuracy: 0.731 - ETA: 10s - loss: 0.4932 - accuracy: 0.731 - ETA: 9s - loss: 0.4928 - accuracy: 0.732 - ETA: 9s - loss: 0.4923 - accuracy: 0.73 - ETA: 9s - loss: 0.4924 - accuracy: 0.73 - ETA: 9s - loss: 0.4919 - accuracy: 0.73 - ETA: 9s - loss: 0.4917 - accuracy: 0.73 - ETA: 9s - loss: 0.4914 - accuracy: 0.73 - ETA: 9s - loss: 0.4913 - accuracy: 0.73 - ETA: 9s - loss: 0.4909 - accuracy: 0.73 - ETA: 8s - loss: 0.4907 - accuracy: 0.73 - ETA: 8s - loss: 0.4906 - accuracy: 0.73 - ETA: 8s - loss: 0.4904 - accuracy: 0.73 - ETA: 8s - loss: 0.4898 - accuracy: 0.73 - ETA: 8s - loss: 0.4897 - accuracy: 0.73 - ETA: 8s - loss: 0.4893 - accuracy: 0.73 - ETA: 8s - loss: 0.4891 - accuracy: 0.73 - ETA: 8s - loss: 0.4886 - accuracy: 0.73 - ETA: 8s - loss: 0.4883 - accuracy: 0.73 - ETA: 7s - loss: 0.4879 - accuracy: 0.73 - ETA: 7s - loss: 0.4876 - accuracy: 0.73 - ETA: 7s - loss: 0.4871 - accuracy: 0.73 - ETA: 7s - loss: 0.4867 - accuracy: 0.7370"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 7s - loss: 0.4862 - accuracy: 0.73 - ETA: 7s - loss: 0.4861 - accuracy: 0.73 - ETA: 7s - loss: 0.4858 - accuracy: 0.73 - ETA: 7s - loss: 0.4854 - accuracy: 0.73 - ETA: 7s - loss: 0.4851 - accuracy: 0.73 - ETA: 6s - loss: 0.4845 - accuracy: 0.73 - ETA: 6s - loss: 0.4841 - accuracy: 0.73 - ETA: 6s - loss: 0.4836 - accuracy: 0.73 - ETA: 6s - loss: 0.4832 - accuracy: 0.73 - ETA: 6s - loss: 0.4829 - accuracy: 0.73 - ETA: 6s - loss: 0.4825 - accuracy: 0.74 - ETA: 6s - loss: 0.4822 - accuracy: 0.74 - ETA: 6s - loss: 0.4819 - accuracy: 0.74 - ETA: 5s - loss: 0.4817 - accuracy: 0.74 - ETA: 5s - loss: 0.4814 - accuracy: 0.74 - ETA: 5s - loss: 0.4811 - accuracy: 0.74 - ETA: 5s - loss: 0.4807 - accuracy: 0.74 - ETA: 5s - loss: 0.4805 - accuracy: 0.74 - ETA: 5s - loss: 0.4799 - accuracy: 0.74 - ETA: 5s - loss: 0.4796 - accuracy: 0.74 - ETA: 5s - loss: 0.4792 - accuracy: 0.74 - ETA: 5s - loss: 0.4788 - accuracy: 0.74 - ETA: 4s - loss: 0.4786 - accuracy: 0.74 - ETA: 4s - loss: 0.4783 - accuracy: 0.74 - ETA: 4s - loss: 0.4778 - accuracy: 0.74 - ETA: 4s - loss: 0.4777 - accuracy: 0.74 - ETA: 4s - loss: 0.4776 - accuracy: 0.74 - ETA: 4s - loss: 0.4771 - accuracy: 0.74 - ETA: 4s - loss: 0.4769 - accuracy: 0.74 - ETA: 4s - loss: 0.4767 - accuracy: 0.74 - ETA: 4s - loss: 0.4764 - accuracy: 0.74 - ETA: 3s - loss: 0.4762 - accuracy: 0.74 - ETA: 3s - loss: 0.4761 - accuracy: 0.74 - ETA: 3s - loss: 0.4760 - accuracy: 0.74 - ETA: 3s - loss: 0.4755 - accuracy: 0.74 - ETA: 3s - loss: 0.4757 - accuracy: 0.74 - ETA: 3s - loss: 0.4755 - accuracy: 0.74 - ETA: 3s - loss: 0.4752 - accuracy: 0.74 - ETA: 3s - loss: 0.4750 - accuracy: 0.74 - ETA: 2s - loss: 0.4747 - accuracy: 0.74 - ETA: 2s - loss: 0.4743 - accuracy: 0.74 - ETA: 2s - loss: 0.4742 - accuracy: 0.74 - ETA: 2s - loss: 0.4740 - accuracy: 0.74 - ETA: 2s - loss: 0.4735 - accuracy: 0.74 - ETA: 2s - loss: 0.4731 - accuracy: 0.74 - ETA: 2s - loss: 0.4728 - accuracy: 0.74 - ETA: 2s - loss: 0.4723 - accuracy: 0.74 - ETA: 2s - loss: 0.4722 - accuracy: 0.74 - ETA: 1s - loss: 0.4717 - accuracy: 0.74 - ETA: 1s - loss: 0.4714 - accuracy: 0.74 - ETA: 1s - loss: 0.4709 - accuracy: 0.74 - ETA: 1s - loss: 0.4705 - accuracy: 0.74 - ETA: 1s - loss: 0.4699 - accuracy: 0.74 - ETA: 1s - loss: 0.4695 - accuracy: 0.75 - ETA: 1s - loss: 0.4692 - accuracy: 0.75 - ETA: 1s - loss: 0.4689 - accuracy: 0.75 - ETA: 1s - loss: 0.4686 - accuracy: 0.75 - ETA: 0s - loss: 0.4683 - accuracy: 0.75 - ETA: 0s - loss: 0.4683 - accuracy: 0.75 - ETA: 0s - loss: 0.4680 - accuracy: 0.75 - ETA: 0s - loss: 0.4676 - accuracy: 0.75 - ETA: 0s - loss: 0.4673 - accuracy: 0.75 - ETA: 0s - loss: 0.4673 - accuracy: 0.75 - ETA: 0s - loss: 0.4670 - accuracy: 0.75 - ETA: 0s - loss: 0.4667 - accuracy: 0.75 - 76s 122ms/step - loss: 0.4663 - accuracy: 0.7520 - val_loss: 0.2799 - val_accuracy: 0.8886\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/625 [=======>......................] - ETA: 1:08 - loss: 0.1616 - accuracy: 0.93 - ETA: 1:05 - loss: 0.2095 - accuracy: 0.90 - ETA: 1:03 - loss: 0.2348 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2563 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2331 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2256 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2287 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2376 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2296 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2430 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2624 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2810 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2657 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2682 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2630 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2609 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2699 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2663 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2730 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2806 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2770 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2787 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2715 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2753 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2755 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2711 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2710 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2721 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2744 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2751 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2794 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2827 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2831 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2844 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2838 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2836 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2831 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2852 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2894 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2875 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2877 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2872 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2882 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2853 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2853 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2843 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2871 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2868 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2874 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2888 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2886 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2883 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2898 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2867 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2872 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2890 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2886 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2925 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2916 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2930 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2939 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2954 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2960 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2992 - accuracy: 0.87 - ETA: 1:03 - loss: 0.2984 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2981 - accuracy: 0.88 - ETA: 1:02 - loss: 0.2969 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3004 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3015 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3011 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3003 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3012 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3030 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3033 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3042 - accuracy: 0.87 - ETA: 1:02 - loss: 0.3059 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3052 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3051 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3071 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3060 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3043 - accuracy: 0.88 - ETA: 1:01 - loss: 0.3042 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3069 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3056 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3057 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3058 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3054 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3048 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3078 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3062 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3059 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3052 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3039 - accuracy: 0.87 - ETA: 59s - loss: 0.3037 - accuracy: 0.8793 - ETA: 59s - loss: 0.3051 - accuracy: 0.878 - ETA: 59s - loss: 0.3045 - accuracy: 0.878 - ETA: 59s - loss: 0.3047 - accuracy: 0.877 - ETA: 59s - loss: 0.3032 - accuracy: 0.878 - ETA: 59s - loss: 0.3034 - accuracy: 0.878 - ETA: 59s - loss: 0.3034 - accuracy: 0.878 - ETA: 59s - loss: 0.3037 - accuracy: 0.878 - ETA: 58s - loss: 0.3051 - accuracy: 0.877 - ETA: 58s - loss: 0.3038 - accuracy: 0.878 - ETA: 58s - loss: 0.3030 - accuracy: 0.878 - ETA: 58s - loss: 0.3024 - accuracy: 0.879 - ETA: 58s - loss: 0.3018 - accuracy: 0.879 - ETA: 58s - loss: 0.3015 - accuracy: 0.878 - ETA: 58s - loss: 0.3015 - accuracy: 0.878 - ETA: 58s - loss: 0.3005 - accuracy: 0.878 - ETA: 58s - loss: 0.3012 - accuracy: 0.878 - ETA: 57s - loss: 0.3010 - accuracy: 0.878 - ETA: 57s - loss: 0.2999 - accuracy: 0.879 - ETA: 57s - loss: 0.2996 - accuracy: 0.879 - ETA: 57s - loss: 0.2996 - accuracy: 0.879 - ETA: 57s - loss: 0.2983 - accuracy: 0.880 - ETA: 57s - loss: 0.2986 - accuracy: 0.879 - ETA: 57s - loss: 0.2981 - accuracy: 0.880 - ETA: 57s - loss: 0.2978 - accuracy: 0.880 - ETA: 56s - loss: 0.2963 - accuracy: 0.880 - ETA: 56s - loss: 0.2967 - accuracy: 0.880 - ETA: 56s - loss: 0.2963 - accuracy: 0.880 - ETA: 56s - loss: 0.2959 - accuracy: 0.880 - ETA: 56s - loss: 0.2953 - accuracy: 0.880 - ETA: 56s - loss: 0.2955 - accuracy: 0.880 - ETA: 56s - loss: 0.2955 - accuracy: 0.880 - ETA: 56s - loss: 0.2967 - accuracy: 0.880 - ETA: 56s - loss: 0.2959 - accuracy: 0.880 - ETA: 56s - loss: 0.2954 - accuracy: 0.880 - ETA: 55s - loss: 0.2956 - accuracy: 0.880 - ETA: 55s - loss: 0.2956 - accuracy: 0.880 - ETA: 55s - loss: 0.2959 - accuracy: 0.880 - ETA: 55s - loss: 0.2953 - accuracy: 0.880 - ETA: 55s - loss: 0.2940 - accuracy: 0.881 - ETA: 55s - loss: 0.2937 - accuracy: 0.881 - ETA: 55s - loss: 0.2929 - accuracy: 0.881 - ETA: 55s - loss: 0.2938 - accuracy: 0.881 - ETA: 55s - loss: 0.2939 - accuracy: 0.880 - ETA: 54s - loss: 0.2930 - accuracy: 0.881 - ETA: 54s - loss: 0.2929 - accuracy: 0.881 - ETA: 54s - loss: 0.2919 - accuracy: 0.881 - ETA: 54s - loss: 0.2922 - accuracy: 0.881 - ETA: 54s - loss: 0.2925 - accuracy: 0.881 - ETA: 54s - loss: 0.2925 - accuracy: 0.881 - ETA: 54s - loss: 0.2914 - accuracy: 0.882 - ETA: 54s - loss: 0.2913 - accuracy: 0.882 - ETA: 53s - loss: 0.2910 - accuracy: 0.882 - ETA: 53s - loss: 0.2913 - accuracy: 0.882 - ETA: 53s - loss: 0.2919 - accuracy: 0.882 - ETA: 53s - loss: 0.2915 - accuracy: 0.882 - ETA: 53s - loss: 0.2903 - accuracy: 0.883 - ETA: 53s - loss: 0.2917 - accuracy: 0.882 - ETA: 53s - loss: 0.2922 - accuracy: 0.882 - ETA: 53s - loss: 0.2919 - accuracy: 0.883 - ETA: 53s - loss: 0.2924 - accuracy: 0.882 - ETA: 52s - loss: 0.2935 - accuracy: 0.882 - ETA: 52s - loss: 0.2922 - accuracy: 0.882 - ETA: 52s - loss: 0.2918 - accuracy: 0.883 - ETA: 52s - loss: 0.2916 - accuracy: 0.883 - ETA: 52s - loss: 0.2907 - accuracy: 0.883 - ETA: 52s - loss: 0.2911 - accuracy: 0.883 - ETA: 52s - loss: 0.2904 - accuracy: 0.883 - ETA: 52s - loss: 0.2896 - accuracy: 0.884 - ETA: 52s - loss: 0.2904 - accuracy: 0.883 - ETA: 51s - loss: 0.2897 - accuracy: 0.884 - ETA: 51s - loss: 0.2893 - accuracy: 0.884 - ETA: 51s - loss: 0.2888 - accuracy: 0.884 - ETA: 51s - loss: 0.2885 - accuracy: 0.884 - ETA: 51s - loss: 0.2881 - accuracy: 0.884 - ETA: 51s - loss: 0.2875 - accuracy: 0.884 - ETA: 51s - loss: 0.2868 - accuracy: 0.884 - ETA: 51s - loss: 0.2876 - accuracy: 0.884 - ETA: 50s - loss: 0.2873 - accuracy: 0.883 - ETA: 50s - loss: 0.2872 - accuracy: 0.883 - ETA: 50s - loss: 0.2872 - accuracy: 0.884 - ETA: 50s - loss: 0.2873 - accuracy: 0.883 - ETA: 50s - loss: 0.2872 - accuracy: 0.883 - ETA: 50s - loss: 0.2865 - accuracy: 0.884 - ETA: 50s - loss: 0.2861 - accuracy: 0.884 - ETA: 50s - loss: 0.2853 - accuracy: 0.884 - ETA: 50s - loss: 0.2850 - accuracy: 0.884 - ETA: 49s - loss: 0.2846 - accuracy: 0.884 - ETA: 49s - loss: 0.2838 - accuracy: 0.884 - ETA: 49s - loss: 0.2847 - accuracy: 0.884 - ETA: 49s - loss: 0.2857 - accuracy: 0.883 - ETA: 49s - loss: 0.2856 - accuracy: 0.883 - ETA: 49s - loss: 0.2850 - accuracy: 0.8841"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/625 [================>.............] - ETA: 49s - loss: 0.2848 - accuracy: 0.884 - ETA: 49s - loss: 0.2856 - accuracy: 0.883 - ETA: 48s - loss: 0.2849 - accuracy: 0.884 - ETA: 48s - loss: 0.2850 - accuracy: 0.884 - ETA: 48s - loss: 0.2848 - accuracy: 0.884 - ETA: 48s - loss: 0.2841 - accuracy: 0.884 - ETA: 48s - loss: 0.2840 - accuracy: 0.884 - ETA: 48s - loss: 0.2836 - accuracy: 0.884 - ETA: 48s - loss: 0.2832 - accuracy: 0.884 - ETA: 48s - loss: 0.2834 - accuracy: 0.884 - ETA: 48s - loss: 0.2829 - accuracy: 0.884 - ETA: 47s - loss: 0.2834 - accuracy: 0.884 - ETA: 47s - loss: 0.2825 - accuracy: 0.885 - ETA: 47s - loss: 0.2827 - accuracy: 0.885 - ETA: 47s - loss: 0.2824 - accuracy: 0.885 - ETA: 47s - loss: 0.2817 - accuracy: 0.885 - ETA: 47s - loss: 0.2816 - accuracy: 0.885 - ETA: 47s - loss: 0.2813 - accuracy: 0.885 - ETA: 47s - loss: 0.2806 - accuracy: 0.886 - ETA: 47s - loss: 0.2804 - accuracy: 0.886 - ETA: 46s - loss: 0.2794 - accuracy: 0.887 - ETA: 46s - loss: 0.2787 - accuracy: 0.887 - ETA: 46s - loss: 0.2787 - accuracy: 0.887 - ETA: 46s - loss: 0.2786 - accuracy: 0.887 - ETA: 46s - loss: 0.2782 - accuracy: 0.887 - ETA: 46s - loss: 0.2793 - accuracy: 0.886 - ETA: 46s - loss: 0.2791 - accuracy: 0.886 - ETA: 46s - loss: 0.2799 - accuracy: 0.886 - ETA: 46s - loss: 0.2797 - accuracy: 0.886 - ETA: 45s - loss: 0.2797 - accuracy: 0.886 - ETA: 45s - loss: 0.2792 - accuracy: 0.886 - ETA: 45s - loss: 0.2788 - accuracy: 0.886 - ETA: 45s - loss: 0.2786 - accuracy: 0.886 - ETA: 45s - loss: 0.2782 - accuracy: 0.886 - ETA: 45s - loss: 0.2783 - accuracy: 0.887 - ETA: 45s - loss: 0.2784 - accuracy: 0.887 - ETA: 45s - loss: 0.2792 - accuracy: 0.887 - ETA: 45s - loss: 0.2788 - accuracy: 0.887 - ETA: 44s - loss: 0.2783 - accuracy: 0.887 - ETA: 44s - loss: 0.2780 - accuracy: 0.887 - ETA: 44s - loss: 0.2773 - accuracy: 0.887 - ETA: 44s - loss: 0.2780 - accuracy: 0.886 - ETA: 44s - loss: 0.2778 - accuracy: 0.887 - ETA: 44s - loss: 0.2780 - accuracy: 0.886 - ETA: 44s - loss: 0.2784 - accuracy: 0.886 - ETA: 44s - loss: 0.2777 - accuracy: 0.887 - ETA: 44s - loss: 0.2768 - accuracy: 0.887 - ETA: 43s - loss: 0.2764 - accuracy: 0.887 - ETA: 43s - loss: 0.2755 - accuracy: 0.888 - ETA: 43s - loss: 0.2753 - accuracy: 0.888 - ETA: 43s - loss: 0.2747 - accuracy: 0.888 - ETA: 43s - loss: 0.2751 - accuracy: 0.888 - ETA: 43s - loss: 0.2748 - accuracy: 0.888 - ETA: 43s - loss: 0.2752 - accuracy: 0.888 - ETA: 43s - loss: 0.2748 - accuracy: 0.888 - ETA: 43s - loss: 0.2749 - accuracy: 0.888 - ETA: 42s - loss: 0.2746 - accuracy: 0.888 - ETA: 42s - loss: 0.2741 - accuracy: 0.888 - ETA: 42s - loss: 0.2733 - accuracy: 0.889 - ETA: 42s - loss: 0.2734 - accuracy: 0.889 - ETA: 42s - loss: 0.2728 - accuracy: 0.889 - ETA: 42s - loss: 0.2731 - accuracy: 0.889 - ETA: 42s - loss: 0.2723 - accuracy: 0.889 - ETA: 42s - loss: 0.2721 - accuracy: 0.889 - ETA: 42s - loss: 0.2717 - accuracy: 0.889 - ETA: 41s - loss: 0.2709 - accuracy: 0.890 - ETA: 41s - loss: 0.2705 - accuracy: 0.890 - ETA: 41s - loss: 0.2705 - accuracy: 0.890 - ETA: 41s - loss: 0.2702 - accuracy: 0.890 - ETA: 41s - loss: 0.2707 - accuracy: 0.890 - ETA: 41s - loss: 0.2710 - accuracy: 0.889 - ETA: 41s - loss: 0.2708 - accuracy: 0.889 - ETA: 41s - loss: 0.2701 - accuracy: 0.890 - ETA: 41s - loss: 0.2703 - accuracy: 0.890 - ETA: 40s - loss: 0.2698 - accuracy: 0.890 - ETA: 40s - loss: 0.2696 - accuracy: 0.890 - ETA: 40s - loss: 0.2694 - accuracy: 0.890 - ETA: 40s - loss: 0.2686 - accuracy: 0.890 - ETA: 40s - loss: 0.2684 - accuracy: 0.891 - ETA: 40s - loss: 0.2681 - accuracy: 0.891 - ETA: 40s - loss: 0.2680 - accuracy: 0.890 - ETA: 40s - loss: 0.2676 - accuracy: 0.891 - ETA: 40s - loss: 0.2671 - accuracy: 0.891 - ETA: 39s - loss: 0.2666 - accuracy: 0.891 - ETA: 39s - loss: 0.2659 - accuracy: 0.892 - ETA: 39s - loss: 0.2657 - accuracy: 0.891 - ETA: 39s - loss: 0.2661 - accuracy: 0.891 - ETA: 39s - loss: 0.2658 - accuracy: 0.891 - ETA: 39s - loss: 0.2660 - accuracy: 0.891 - ETA: 39s - loss: 0.2657 - accuracy: 0.891 - ETA: 39s - loss: 0.2656 - accuracy: 0.891 - ETA: 39s - loss: 0.2656 - accuracy: 0.891 - ETA: 38s - loss: 0.2651 - accuracy: 0.891 - ETA: 38s - loss: 0.2646 - accuracy: 0.892 - ETA: 38s - loss: 0.2639 - accuracy: 0.892 - ETA: 38s - loss: 0.2641 - accuracy: 0.892 - ETA: 38s - loss: 0.2637 - accuracy: 0.892 - ETA: 38s - loss: 0.2629 - accuracy: 0.892 - ETA: 38s - loss: 0.2628 - accuracy: 0.892 - ETA: 38s - loss: 0.2622 - accuracy: 0.892 - ETA: 38s - loss: 0.2627 - accuracy: 0.892 - ETA: 37s - loss: 0.2625 - accuracy: 0.892 - ETA: 37s - loss: 0.2619 - accuracy: 0.892 - ETA: 37s - loss: 0.2616 - accuracy: 0.892 - ETA: 37s - loss: 0.2614 - accuracy: 0.892 - ETA: 37s - loss: 0.2610 - accuracy: 0.892 - ETA: 37s - loss: 0.2610 - accuracy: 0.892 - ETA: 37s - loss: 0.2608 - accuracy: 0.892 - ETA: 37s - loss: 0.2602 - accuracy: 0.893 - ETA: 37s - loss: 0.2604 - accuracy: 0.892 - ETA: 36s - loss: 0.2602 - accuracy: 0.893 - ETA: 36s - loss: 0.2605 - accuracy: 0.893 - ETA: 36s - loss: 0.2605 - accuracy: 0.893 - ETA: 36s - loss: 0.2604 - accuracy: 0.892 - ETA: 36s - loss: 0.2605 - accuracy: 0.892 - ETA: 36s - loss: 0.2601 - accuracy: 0.893 - ETA: 36s - loss: 0.2595 - accuracy: 0.893 - ETA: 36s - loss: 0.2589 - accuracy: 0.893 - ETA: 36s - loss: 0.2584 - accuracy: 0.893 - ETA: 35s - loss: 0.2582 - accuracy: 0.893 - ETA: 35s - loss: 0.2579 - accuracy: 0.894 - ETA: 35s - loss: 0.2576 - accuracy: 0.893 - ETA: 35s - loss: 0.2583 - accuracy: 0.893 - ETA: 35s - loss: 0.2582 - accuracy: 0.893 - ETA: 35s - loss: 0.2589 - accuracy: 0.893 - ETA: 35s - loss: 0.2586 - accuracy: 0.893 - ETA: 35s - loss: 0.2584 - accuracy: 0.894 - ETA: 34s - loss: 0.2584 - accuracy: 0.894 - ETA: 34s - loss: 0.2584 - accuracy: 0.894 - ETA: 34s - loss: 0.2586 - accuracy: 0.894 - ETA: 34s - loss: 0.2586 - accuracy: 0.894 - ETA: 34s - loss: 0.2584 - accuracy: 0.894 - ETA: 34s - loss: 0.2582 - accuracy: 0.894 - ETA: 34s - loss: 0.2579 - accuracy: 0.894 - ETA: 34s - loss: 0.2587 - accuracy: 0.894 - ETA: 34s - loss: 0.2586 - accuracy: 0.894 - ETA: 33s - loss: 0.2585 - accuracy: 0.894 - ETA: 33s - loss: 0.2588 - accuracy: 0.894 - ETA: 33s - loss: 0.2584 - accuracy: 0.894 - ETA: 33s - loss: 0.2579 - accuracy: 0.894 - ETA: 33s - loss: 0.2575 - accuracy: 0.895 - ETA: 33s - loss: 0.2576 - accuracy: 0.895 - ETA: 33s - loss: 0.2571 - accuracy: 0.895 - ETA: 33s - loss: 0.2573 - accuracy: 0.895 - ETA: 33s - loss: 0.2569 - accuracy: 0.895 - ETA: 32s - loss: 0.2567 - accuracy: 0.895 - ETA: 32s - loss: 0.2560 - accuracy: 0.895 - ETA: 32s - loss: 0.2563 - accuracy: 0.896 - ETA: 32s - loss: 0.2560 - accuracy: 0.896 - ETA: 32s - loss: 0.2556 - accuracy: 0.896 - ETA: 32s - loss: 0.2555 - accuracy: 0.896 - ETA: 32s - loss: 0.2561 - accuracy: 0.895 - ETA: 32s - loss: 0.2561 - accuracy: 0.895 - ETA: 32s - loss: 0.2559 - accuracy: 0.896 - ETA: 31s - loss: 0.2558 - accuracy: 0.896 - ETA: 31s - loss: 0.2557 - accuracy: 0.896 - ETA: 31s - loss: 0.2556 - accuracy: 0.896 - ETA: 31s - loss: 0.2554 - accuracy: 0.896 - ETA: 31s - loss: 0.2554 - accuracy: 0.896 - ETA: 31s - loss: 0.2552 - accuracy: 0.896 - ETA: 31s - loss: 0.2550 - accuracy: 0.896 - ETA: 31s - loss: 0.2548 - accuracy: 0.896 - ETA: 31s - loss: 0.2544 - accuracy: 0.896 - ETA: 30s - loss: 0.2539 - accuracy: 0.897 - ETA: 30s - loss: 0.2538 - accuracy: 0.897 - ETA: 30s - loss: 0.2534 - accuracy: 0.897 - ETA: 30s - loss: 0.2531 - accuracy: 0.897 - ETA: 30s - loss: 0.2528 - accuracy: 0.898 - ETA: 30s - loss: 0.2528 - accuracy: 0.897 - ETA: 30s - loss: 0.2532 - accuracy: 0.897 - ETA: 30s - loss: 0.2530 - accuracy: 0.898 - ETA: 30s - loss: 0.2529 - accuracy: 0.898 - ETA: 29s - loss: 0.2524 - accuracy: 0.898 - ETA: 29s - loss: 0.2525 - accuracy: 0.898 - ETA: 29s - loss: 0.2524 - accuracy: 0.898 - ETA: 29s - loss: 0.2522 - accuracy: 0.898 - ETA: 29s - loss: 0.2523 - accuracy: 0.898 - ETA: 29s - loss: 0.2523 - accuracy: 0.898 - ETA: 29s - loss: 0.2524 - accuracy: 0.898 - ETA: 29s - loss: 0.2525 - accuracy: 0.898 - ETA: 29s - loss: 0.2520 - accuracy: 0.898 - ETA: 28s - loss: 0.2521 - accuracy: 0.898 - ETA: 28s - loss: 0.2519 - accuracy: 0.898 - ETA: 28s - loss: 0.2517 - accuracy: 0.898 - ETA: 28s - loss: 0.2516 - accuracy: 0.898 - ETA: 28s - loss: 0.2512 - accuracy: 0.8990"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559/625 [=========================>....] - ETA: 28s - loss: 0.2511 - accuracy: 0.899 - ETA: 28s - loss: 0.2507 - accuracy: 0.899 - ETA: 28s - loss: 0.2508 - accuracy: 0.899 - ETA: 28s - loss: 0.2510 - accuracy: 0.899 - ETA: 27s - loss: 0.2507 - accuracy: 0.899 - ETA: 27s - loss: 0.2502 - accuracy: 0.899 - ETA: 27s - loss: 0.2498 - accuracy: 0.899 - ETA: 27s - loss: 0.2499 - accuracy: 0.899 - ETA: 27s - loss: 0.2508 - accuracy: 0.899 - ETA: 27s - loss: 0.2509 - accuracy: 0.899 - ETA: 27s - loss: 0.2504 - accuracy: 0.899 - ETA: 27s - loss: 0.2505 - accuracy: 0.899 - ETA: 26s - loss: 0.2501 - accuracy: 0.900 - ETA: 26s - loss: 0.2498 - accuracy: 0.900 - ETA: 26s - loss: 0.2499 - accuracy: 0.900 - ETA: 26s - loss: 0.2496 - accuracy: 0.900 - ETA: 26s - loss: 0.2497 - accuracy: 0.900 - ETA: 26s - loss: 0.2497 - accuracy: 0.900 - ETA: 26s - loss: 0.2498 - accuracy: 0.900 - ETA: 26s - loss: 0.2497 - accuracy: 0.900 - ETA: 26s - loss: 0.2495 - accuracy: 0.900 - ETA: 25s - loss: 0.2495 - accuracy: 0.900 - ETA: 25s - loss: 0.2491 - accuracy: 0.900 - ETA: 25s - loss: 0.2489 - accuracy: 0.900 - ETA: 25s - loss: 0.2497 - accuracy: 0.900 - ETA: 25s - loss: 0.2498 - accuracy: 0.900 - ETA: 25s - loss: 0.2498 - accuracy: 0.900 - ETA: 25s - loss: 0.2496 - accuracy: 0.900 - ETA: 25s - loss: 0.2499 - accuracy: 0.900 - ETA: 25s - loss: 0.2495 - accuracy: 0.900 - ETA: 24s - loss: 0.2495 - accuracy: 0.900 - ETA: 24s - loss: 0.2492 - accuracy: 0.900 - ETA: 24s - loss: 0.2491 - accuracy: 0.900 - ETA: 24s - loss: 0.2493 - accuracy: 0.900 - ETA: 24s - loss: 0.2489 - accuracy: 0.901 - ETA: 24s - loss: 0.2489 - accuracy: 0.901 - ETA: 24s - loss: 0.2487 - accuracy: 0.901 - ETA: 24s - loss: 0.2486 - accuracy: 0.901 - ETA: 24s - loss: 0.2482 - accuracy: 0.901 - ETA: 23s - loss: 0.2479 - accuracy: 0.901 - ETA: 23s - loss: 0.2475 - accuracy: 0.901 - ETA: 23s - loss: 0.2473 - accuracy: 0.901 - ETA: 23s - loss: 0.2472 - accuracy: 0.901 - ETA: 23s - loss: 0.2468 - accuracy: 0.901 - ETA: 23s - loss: 0.2468 - accuracy: 0.901 - ETA: 23s - loss: 0.2467 - accuracy: 0.901 - ETA: 23s - loss: 0.2466 - accuracy: 0.901 - ETA: 23s - loss: 0.2465 - accuracy: 0.901 - ETA: 22s - loss: 0.2461 - accuracy: 0.902 - ETA: 22s - loss: 0.2458 - accuracy: 0.902 - ETA: 22s - loss: 0.2454 - accuracy: 0.902 - ETA: 22s - loss: 0.2451 - accuracy: 0.902 - ETA: 22s - loss: 0.2452 - accuracy: 0.902 - ETA: 22s - loss: 0.2450 - accuracy: 0.902 - ETA: 22s - loss: 0.2453 - accuracy: 0.902 - ETA: 22s - loss: 0.2450 - accuracy: 0.902 - ETA: 22s - loss: 0.2449 - accuracy: 0.902 - ETA: 21s - loss: 0.2447 - accuracy: 0.902 - ETA: 21s - loss: 0.2443 - accuracy: 0.902 - ETA: 21s - loss: 0.2442 - accuracy: 0.902 - ETA: 21s - loss: 0.2444 - accuracy: 0.902 - ETA: 21s - loss: 0.2440 - accuracy: 0.903 - ETA: 21s - loss: 0.2441 - accuracy: 0.903 - ETA: 21s - loss: 0.2437 - accuracy: 0.903 - ETA: 21s - loss: 0.2440 - accuracy: 0.903 - ETA: 21s - loss: 0.2440 - accuracy: 0.903 - ETA: 20s - loss: 0.2439 - accuracy: 0.903 - ETA: 20s - loss: 0.2442 - accuracy: 0.902 - ETA: 20s - loss: 0.2444 - accuracy: 0.902 - ETA: 20s - loss: 0.2440 - accuracy: 0.903 - ETA: 20s - loss: 0.2442 - accuracy: 0.902 - ETA: 20s - loss: 0.2441 - accuracy: 0.902 - ETA: 20s - loss: 0.2441 - accuracy: 0.902 - ETA: 20s - loss: 0.2442 - accuracy: 0.902 - ETA: 20s - loss: 0.2441 - accuracy: 0.902 - ETA: 19s - loss: 0.2437 - accuracy: 0.902 - ETA: 19s - loss: 0.2434 - accuracy: 0.903 - ETA: 19s - loss: 0.2434 - accuracy: 0.903 - ETA: 19s - loss: 0.2433 - accuracy: 0.903 - ETA: 19s - loss: 0.2430 - accuracy: 0.903 - ETA: 19s - loss: 0.2427 - accuracy: 0.903 - ETA: 19s - loss: 0.2429 - accuracy: 0.903 - ETA: 19s - loss: 0.2428 - accuracy: 0.903 - ETA: 19s - loss: 0.2424 - accuracy: 0.903 - ETA: 18s - loss: 0.2425 - accuracy: 0.903 - ETA: 18s - loss: 0.2427 - accuracy: 0.903 - ETA: 18s - loss: 0.2423 - accuracy: 0.903 - ETA: 18s - loss: 0.2420 - accuracy: 0.903 - ETA: 18s - loss: 0.2417 - accuracy: 0.903 - ETA: 18s - loss: 0.2414 - accuracy: 0.903 - ETA: 18s - loss: 0.2413 - accuracy: 0.904 - ETA: 18s - loss: 0.2414 - accuracy: 0.904 - ETA: 18s - loss: 0.2411 - accuracy: 0.904 - ETA: 17s - loss: 0.2411 - accuracy: 0.904 - ETA: 17s - loss: 0.2409 - accuracy: 0.904 - ETA: 17s - loss: 0.2406 - accuracy: 0.904 - ETA: 17s - loss: 0.2403 - accuracy: 0.904 - ETA: 17s - loss: 0.2404 - accuracy: 0.904 - ETA: 17s - loss: 0.2403 - accuracy: 0.904 - ETA: 17s - loss: 0.2402 - accuracy: 0.904 - ETA: 17s - loss: 0.2398 - accuracy: 0.904 - ETA: 17s - loss: 0.2402 - accuracy: 0.904 - ETA: 16s - loss: 0.2398 - accuracy: 0.904 - ETA: 16s - loss: 0.2394 - accuracy: 0.904 - ETA: 16s - loss: 0.2394 - accuracy: 0.904 - ETA: 16s - loss: 0.2398 - accuracy: 0.904 - ETA: 16s - loss: 0.2395 - accuracy: 0.904 - ETA: 16s - loss: 0.2393 - accuracy: 0.904 - ETA: 16s - loss: 0.2390 - accuracy: 0.905 - ETA: 16s - loss: 0.2388 - accuracy: 0.905 - ETA: 16s - loss: 0.2387 - accuracy: 0.905 - ETA: 15s - loss: 0.2384 - accuracy: 0.905 - ETA: 15s - loss: 0.2382 - accuracy: 0.905 - ETA: 15s - loss: 0.2381 - accuracy: 0.905 - ETA: 15s - loss: 0.2380 - accuracy: 0.905 - ETA: 15s - loss: 0.2381 - accuracy: 0.905 - ETA: 15s - loss: 0.2379 - accuracy: 0.905 - ETA: 15s - loss: 0.2376 - accuracy: 0.905 - ETA: 15s - loss: 0.2373 - accuracy: 0.905 - ETA: 14s - loss: 0.2371 - accuracy: 0.905 - ETA: 14s - loss: 0.2369 - accuracy: 0.905 - ETA: 14s - loss: 0.2366 - accuracy: 0.905 - ETA: 14s - loss: 0.2364 - accuracy: 0.906 - ETA: 14s - loss: 0.2365 - accuracy: 0.906 - ETA: 14s - loss: 0.2362 - accuracy: 0.906 - ETA: 14s - loss: 0.2363 - accuracy: 0.906 - ETA: 14s - loss: 0.2364 - accuracy: 0.906 - ETA: 14s - loss: 0.2368 - accuracy: 0.906 - ETA: 13s - loss: 0.2369 - accuracy: 0.906 - ETA: 13s - loss: 0.2371 - accuracy: 0.906 - ETA: 13s - loss: 0.2368 - accuracy: 0.906 - ETA: 13s - loss: 0.2365 - accuracy: 0.906 - ETA: 13s - loss: 0.2363 - accuracy: 0.906 - ETA: 13s - loss: 0.2361 - accuracy: 0.906 - ETA: 13s - loss: 0.2362 - accuracy: 0.906 - ETA: 13s - loss: 0.2363 - accuracy: 0.906 - ETA: 13s - loss: 0.2361 - accuracy: 0.906 - ETA: 12s - loss: 0.2360 - accuracy: 0.906 - ETA: 12s - loss: 0.2361 - accuracy: 0.906 - ETA: 12s - loss: 0.2358 - accuracy: 0.906 - ETA: 12s - loss: 0.2357 - accuracy: 0.906 - ETA: 12s - loss: 0.2358 - accuracy: 0.906 - ETA: 12s - loss: 0.2357 - accuracy: 0.906 - ETA: 12s - loss: 0.2357 - accuracy: 0.906 - ETA: 12s - loss: 0.2355 - accuracy: 0.906 - ETA: 12s - loss: 0.2357 - accuracy: 0.906 - ETA: 11s - loss: 0.2355 - accuracy: 0.906 - ETA: 11s - loss: 0.2352 - accuracy: 0.906 - ETA: 11s - loss: 0.2351 - accuracy: 0.906 - ETA: 11s - loss: 0.2347 - accuracy: 0.907 - ETA: 11s - loss: 0.2345 - accuracy: 0.907 - ETA: 11s - loss: 0.2342 - accuracy: 0.907 - ETA: 11s - loss: 0.2341 - accuracy: 0.907 - ETA: 11s - loss: 0.2339 - accuracy: 0.907 - ETA: 11s - loss: 0.2338 - accuracy: 0.907 - ETA: 10s - loss: 0.2337 - accuracy: 0.907 - ETA: 10s - loss: 0.2336 - accuracy: 0.907 - ETA: 10s - loss: 0.2333 - accuracy: 0.907 - ETA: 10s - loss: 0.2331 - accuracy: 0.907 - ETA: 10s - loss: 0.2333 - accuracy: 0.907 - ETA: 10s - loss: 0.2332 - accuracy: 0.907 - ETA: 10s - loss: 0.2328 - accuracy: 0.907 - ETA: 10s - loss: 0.2325 - accuracy: 0.907 - ETA: 10s - loss: 0.2322 - accuracy: 0.908 - ETA: 9s - loss: 0.2319 - accuracy: 0.908 - ETA: 9s - loss: 0.2320 - accuracy: 0.90 - ETA: 9s - loss: 0.2316 - accuracy: 0.90 - ETA: 9s - loss: 0.2313 - accuracy: 0.90 - ETA: 9s - loss: 0.2315 - accuracy: 0.90 - ETA: 9s - loss: 0.2316 - accuracy: 0.90 - ETA: 9s - loss: 0.2317 - accuracy: 0.90 - ETA: 9s - loss: 0.2315 - accuracy: 0.90 - ETA: 9s - loss: 0.2315 - accuracy: 0.90 - ETA: 8s - loss: 0.2313 - accuracy: 0.90 - ETA: 8s - loss: 0.2313 - accuracy: 0.90 - ETA: 8s - loss: 0.2313 - accuracy: 0.90 - ETA: 8s - loss: 0.2310 - accuracy: 0.90 - ETA: 8s - loss: 0.2308 - accuracy: 0.90 - ETA: 8s - loss: 0.2308 - accuracy: 0.90 - ETA: 8s - loss: 0.2306 - accuracy: 0.90 - ETA: 8s - loss: 0.2305 - accuracy: 0.90 - ETA: 8s - loss: 0.2303 - accuracy: 0.90 - ETA: 7s - loss: 0.2301 - accuracy: 0.90 - ETA: 7s - loss: 0.2300 - accuracy: 0.90 - ETA: 7s - loss: 0.2297 - accuracy: 0.90 - ETA: 7s - loss: 0.2296 - accuracy: 0.90 - ETA: 7s - loss: 0.2293 - accuracy: 0.9093"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 7s - loss: 0.2290 - accuracy: 0.90 - ETA: 7s - loss: 0.2288 - accuracy: 0.90 - ETA: 7s - loss: 0.2287 - accuracy: 0.90 - ETA: 7s - loss: 0.2286 - accuracy: 0.90 - ETA: 6s - loss: 0.2286 - accuracy: 0.90 - ETA: 6s - loss: 0.2287 - accuracy: 0.90 - ETA: 6s - loss: 0.2284 - accuracy: 0.90 - ETA: 6s - loss: 0.2285 - accuracy: 0.90 - ETA: 6s - loss: 0.2282 - accuracy: 0.90 - ETA: 6s - loss: 0.2280 - accuracy: 0.90 - ETA: 6s - loss: 0.2278 - accuracy: 0.90 - ETA: 6s - loss: 0.2280 - accuracy: 0.90 - ETA: 6s - loss: 0.2280 - accuracy: 0.90 - ETA: 5s - loss: 0.2279 - accuracy: 0.90 - ETA: 5s - loss: 0.2276 - accuracy: 0.91 - ETA: 5s - loss: 0.2274 - accuracy: 0.91 - ETA: 5s - loss: 0.2271 - accuracy: 0.91 - ETA: 5s - loss: 0.2269 - accuracy: 0.91 - ETA: 5s - loss: 0.2266 - accuracy: 0.91 - ETA: 5s - loss: 0.2265 - accuracy: 0.91 - ETA: 5s - loss: 0.2266 - accuracy: 0.91 - ETA: 5s - loss: 0.2264 - accuracy: 0.91 - ETA: 4s - loss: 0.2263 - accuracy: 0.91 - ETA: 4s - loss: 0.2263 - accuracy: 0.91 - ETA: 4s - loss: 0.2260 - accuracy: 0.91 - ETA: 4s - loss: 0.2259 - accuracy: 0.91 - ETA: 4s - loss: 0.2259 - accuracy: 0.91 - ETA: 4s - loss: 0.2257 - accuracy: 0.91 - ETA: 4s - loss: 0.2257 - accuracy: 0.91 - ETA: 4s - loss: 0.2255 - accuracy: 0.91 - ETA: 3s - loss: 0.2257 - accuracy: 0.91 - ETA: 3s - loss: 0.2257 - accuracy: 0.91 - ETA: 3s - loss: 0.2257 - accuracy: 0.91 - ETA: 3s - loss: 0.2258 - accuracy: 0.91 - ETA: 3s - loss: 0.2257 - accuracy: 0.91 - ETA: 3s - loss: 0.2256 - accuracy: 0.91 - ETA: 3s - loss: 0.2255 - accuracy: 0.91 - ETA: 3s - loss: 0.2252 - accuracy: 0.91 - ETA: 3s - loss: 0.2253 - accuracy: 0.91 - ETA: 2s - loss: 0.2252 - accuracy: 0.91 - ETA: 2s - loss: 0.2250 - accuracy: 0.91 - ETA: 2s - loss: 0.2251 - accuracy: 0.91 - ETA: 2s - loss: 0.2249 - accuracy: 0.91 - ETA: 2s - loss: 0.2246 - accuracy: 0.91 - ETA: 2s - loss: 0.2244 - accuracy: 0.91 - ETA: 2s - loss: 0.2243 - accuracy: 0.91 - ETA: 2s - loss: 0.2241 - accuracy: 0.91 - ETA: 2s - loss: 0.2241 - accuracy: 0.91 - ETA: 1s - loss: 0.2239 - accuracy: 0.91 - ETA: 1s - loss: 0.2239 - accuracy: 0.91 - ETA: 1s - loss: 0.2237 - accuracy: 0.91 - ETA: 1s - loss: 0.2235 - accuracy: 0.91 - ETA: 1s - loss: 0.2233 - accuracy: 0.91 - ETA: 1s - loss: 0.2230 - accuracy: 0.91 - ETA: 1s - loss: 0.2228 - accuracy: 0.91 - ETA: 1s - loss: 0.2227 - accuracy: 0.91 - ETA: 1s - loss: 0.2225 - accuracy: 0.91 - ETA: 0s - loss: 0.2225 - accuracy: 0.91 - ETA: 0s - loss: 0.2225 - accuracy: 0.91 - ETA: 0s - loss: 0.2224 - accuracy: 0.91 - ETA: 0s - loss: 0.2223 - accuracy: 0.91 - ETA: 0s - loss: 0.2221 - accuracy: 0.91 - ETA: 0s - loss: 0.2220 - accuracy: 0.91 - ETA: 0s - loss: 0.2220 - accuracy: 0.91 - ETA: 0s - loss: 0.2220 - accuracy: 0.91 - 77s 123ms/step - loss: 0.2217 - accuracy: 0.9125 - val_loss: 0.2706 - val_accuracy: 0.9014\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: fadd01add5bff0fd0417789bb9d35ff3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.27064952733600217</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/filters_0_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/kernel_size: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/max_pooling: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/num_blocks: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/separable: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/dense_block_1/units_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/embedding_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/embedding_1/embedding_dim: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/embedding_1/pretraining: none</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/spatial_reduction_1/reduction_type: global_max</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/text_to_int_sequence_1/output_sequence_length: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/vectorizer: sequence</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 625 steps, validate for 157 steps\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/625 [=======>......................] - ETA: 6:28 - loss: 0.6827 - accuracy: 0.62 - ETA: 3:46 - loss: 0.6774 - accuracy: 0.62 - ETA: 2:52 - loss: 0.6857 - accuracy: 0.59 - ETA: 2:25 - loss: 0.6833 - accuracy: 0.58 - ETA: 2:10 - loss: 0.6831 - accuracy: 0.58 - ETA: 2:00 - loss: 0.6874 - accuracy: 0.57 - ETA: 1:52 - loss: 0.6872 - accuracy: 0.57 - ETA: 1:47 - loss: 0.6968 - accuracy: 0.54 - ETA: 1:44 - loss: 0.7035 - accuracy: 0.52 - ETA: 1:41 - loss: 0.7011 - accuracy: 0.52 - ETA: 1:38 - loss: 0.7025 - accuracy: 0.51 - ETA: 1:36 - loss: 0.7013 - accuracy: 0.52 - ETA: 1:34 - loss: 0.7013 - accuracy: 0.50 - ETA: 1:32 - loss: 0.7006 - accuracy: 0.50 - ETA: 1:31 - loss: 0.6983 - accuracy: 0.51 - ETA: 1:29 - loss: 0.6985 - accuracy: 0.51 - ETA: 1:28 - loss: 0.6983 - accuracy: 0.51 - ETA: 1:27 - loss: 0.6987 - accuracy: 0.51 - ETA: 1:26 - loss: 0.6968 - accuracy: 0.52 - ETA: 1:25 - loss: 0.6979 - accuracy: 0.51 - ETA: 1:24 - loss: 0.6976 - accuracy: 0.51 - ETA: 1:23 - loss: 0.6983 - accuracy: 0.51 - ETA: 1:22 - loss: 0.6984 - accuracy: 0.51 - ETA: 1:22 - loss: 0.7001 - accuracy: 0.50 - ETA: 1:21 - loss: 0.6997 - accuracy: 0.51 - ETA: 1:21 - loss: 0.6995 - accuracy: 0.50 - ETA: 1:20 - loss: 0.6993 - accuracy: 0.50 - ETA: 1:19 - loss: 0.6987 - accuracy: 0.50 - ETA: 1:19 - loss: 0.6989 - accuracy: 0.50 - ETA: 1:18 - loss: 0.6990 - accuracy: 0.50 - ETA: 1:18 - loss: 0.6992 - accuracy: 0.50 - ETA: 1:17 - loss: 0.6992 - accuracy: 0.50 - ETA: 1:17 - loss: 0.6993 - accuracy: 0.49 - ETA: 1:16 - loss: 0.6989 - accuracy: 0.50 - ETA: 1:16 - loss: 0.6988 - accuracy: 0.50 - ETA: 1:16 - loss: 0.6985 - accuracy: 0.50 - ETA: 1:15 - loss: 0.6984 - accuracy: 0.50 - ETA: 1:15 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:14 - loss: 0.6975 - accuracy: 0.51 - ETA: 1:14 - loss: 0.6970 - accuracy: 0.51 - ETA: 1:14 - loss: 0.6969 - accuracy: 0.51 - ETA: 1:14 - loss: 0.6968 - accuracy: 0.51 - ETA: 1:13 - loss: 0.6976 - accuracy: 0.50 - ETA: 1:13 - loss: 0.6972 - accuracy: 0.50 - ETA: 1:13 - loss: 0.6980 - accuracy: 0.50 - ETA: 1:13 - loss: 0.6990 - accuracy: 0.50 - ETA: 1:12 - loss: 0.6993 - accuracy: 0.49 - ETA: 1:12 - loss: 0.6993 - accuracy: 0.49 - ETA: 1:12 - loss: 0.6995 - accuracy: 0.49 - ETA: 1:12 - loss: 0.6993 - accuracy: 0.49 - ETA: 1:11 - loss: 0.6992 - accuracy: 0.49 - ETA: 1:11 - loss: 0.6991 - accuracy: 0.49 - ETA: 1:11 - loss: 0.6991 - accuracy: 0.49 - ETA: 1:11 - loss: 0.6989 - accuracy: 0.49 - ETA: 1:10 - loss: 0.6989 - accuracy: 0.49 - ETA: 1:10 - loss: 0.6991 - accuracy: 0.49 - ETA: 1:10 - loss: 0.6987 - accuracy: 0.49 - ETA: 1:10 - loss: 0.6989 - accuracy: 0.49 - ETA: 1:09 - loss: 0.6995 - accuracy: 0.49 - ETA: 1:09 - loss: 0.6993 - accuracy: 0.49 - ETA: 1:09 - loss: 0.6986 - accuracy: 0.49 - ETA: 1:09 - loss: 0.6986 - accuracy: 0.49 - ETA: 1:09 - loss: 0.6989 - accuracy: 0.49 - ETA: 1:09 - loss: 0.6987 - accuracy: 0.49 - ETA: 1:08 - loss: 0.6988 - accuracy: 0.49 - ETA: 1:08 - loss: 0.6985 - accuracy: 0.49 - ETA: 1:08 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:08 - loss: 0.6978 - accuracy: 0.50 - ETA: 1:08 - loss: 0.6978 - accuracy: 0.50 - ETA: 1:07 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:07 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:07 - loss: 0.6982 - accuracy: 0.50 - ETA: 1:07 - loss: 0.6982 - accuracy: 0.50 - ETA: 1:07 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6981 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6983 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6985 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6982 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6984 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6984 - accuracy: 0.50 - ETA: 1:05 - loss: 0.6984 - accuracy: 0.50 - ETA: 1:05 - loss: 0.6984 - accuracy: 0.49 - ETA: 1:05 - loss: 0.6984 - accuracy: 0.49 - ETA: 1:05 - loss: 0.6983 - accuracy: 0.49 - ETA: 1:05 - loss: 0.6981 - accuracy: 0.49 - ETA: 1:04 - loss: 0.6981 - accuracy: 0.49 - ETA: 1:04 - loss: 0.6979 - accuracy: 0.49 - ETA: 1:04 - loss: 0.6980 - accuracy: 0.49 - ETA: 1:04 - loss: 0.6981 - accuracy: 0.49 - ETA: 1:04 - loss: 0.6980 - accuracy: 0.49 - ETA: 1:04 - loss: 0.6980 - accuracy: 0.49 - ETA: 1:04 - loss: 0.6978 - accuracy: 0.49 - ETA: 1:03 - loss: 0.6978 - accuracy: 0.49 - ETA: 1:03 - loss: 0.6977 - accuracy: 0.49 - ETA: 1:03 - loss: 0.6977 - accuracy: 0.49 - ETA: 1:03 - loss: 0.6975 - accuracy: 0.49 - ETA: 1:03 - loss: 0.6975 - accuracy: 0.49 - ETA: 1:03 - loss: 0.6974 - accuracy: 0.49 - ETA: 1:03 - loss: 0.6972 - accuracy: 0.50 - ETA: 1:02 - loss: 0.6973 - accuracy: 0.49 - ETA: 1:02 - loss: 0.6972 - accuracy: 0.49 - ETA: 1:02 - loss: 0.6972 - accuracy: 0.49 - ETA: 1:02 - loss: 0.6970 - accuracy: 0.50 - ETA: 1:02 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:02 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6966 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6965 - accuracy: 0.50 - ETA: 1:00 - loss: 0.6964 - accuracy: 0.50 - ETA: 1:00 - loss: 0.6964 - accuracy: 0.50 - ETA: 1:00 - loss: 0.6965 - accuracy: 0.50 - ETA: 1:00 - loss: 0.6965 - accuracy: 0.50 - ETA: 1:00 - loss: 0.6964 - accuracy: 0.50 - ETA: 1:00 - loss: 0.6963 - accuracy: 0.50 - ETA: 1:00 - loss: 0.6963 - accuracy: 0.50 - ETA: 59s - loss: 0.6963 - accuracy: 0.5010 - ETA: 59s - loss: 0.6962 - accuracy: 0.501 - ETA: 59s - loss: 0.6960 - accuracy: 0.502 - ETA: 59s - loss: 0.6959 - accuracy: 0.502 - ETA: 59s - loss: 0.6959 - accuracy: 0.502 - ETA: 59s - loss: 0.6958 - accuracy: 0.502 - ETA: 59s - loss: 0.6957 - accuracy: 0.502 - ETA: 58s - loss: 0.6957 - accuracy: 0.502 - ETA: 58s - loss: 0.6956 - accuracy: 0.502 - ETA: 58s - loss: 0.6955 - accuracy: 0.503 - ETA: 58s - loss: 0.6954 - accuracy: 0.503 - ETA: 58s - loss: 0.6954 - accuracy: 0.503 - ETA: 58s - loss: 0.6952 - accuracy: 0.505 - ETA: 58s - loss: 0.6950 - accuracy: 0.506 - ETA: 57s - loss: 0.6950 - accuracy: 0.505 - ETA: 57s - loss: 0.6950 - accuracy: 0.505 - ETA: 57s - loss: 0.6949 - accuracy: 0.506 - ETA: 57s - loss: 0.6948 - accuracy: 0.506 - ETA: 57s - loss: 0.6947 - accuracy: 0.507 - ETA: 57s - loss: 0.6945 - accuracy: 0.507 - ETA: 57s - loss: 0.6944 - accuracy: 0.508 - ETA: 57s - loss: 0.6943 - accuracy: 0.508 - ETA: 56s - loss: 0.6944 - accuracy: 0.508 - ETA: 56s - loss: 0.6941 - accuracy: 0.510 - ETA: 56s - loss: 0.6938 - accuracy: 0.511 - ETA: 56s - loss: 0.6937 - accuracy: 0.512 - ETA: 56s - loss: 0.6937 - accuracy: 0.512 - ETA: 56s - loss: 0.6934 - accuracy: 0.513 - ETA: 56s - loss: 0.6932 - accuracy: 0.514 - ETA: 55s - loss: 0.6930 - accuracy: 0.515 - ETA: 55s - loss: 0.6928 - accuracy: 0.516 - ETA: 55s - loss: 0.6924 - accuracy: 0.517 - ETA: 55s - loss: 0.6922 - accuracy: 0.518 - ETA: 55s - loss: 0.6919 - accuracy: 0.518 - ETA: 55s - loss: 0.6917 - accuracy: 0.518 - ETA: 55s - loss: 0.6915 - accuracy: 0.519 - ETA: 55s - loss: 0.6910 - accuracy: 0.520 - ETA: 54s - loss: 0.6906 - accuracy: 0.521 - ETA: 54s - loss: 0.6904 - accuracy: 0.522 - ETA: 54s - loss: 0.6899 - accuracy: 0.523 - ETA: 54s - loss: 0.6897 - accuracy: 0.523 - ETA: 54s - loss: 0.6890 - accuracy: 0.524 - ETA: 54s - loss: 0.6883 - accuracy: 0.525 - ETA: 54s - loss: 0.6880 - accuracy: 0.526 - ETA: 53s - loss: 0.6876 - accuracy: 0.527 - ETA: 53s - loss: 0.6871 - accuracy: 0.528 - ETA: 53s - loss: 0.6862 - accuracy: 0.529 - ETA: 53s - loss: 0.6861 - accuracy: 0.531 - ETA: 53s - loss: 0.6860 - accuracy: 0.531 - ETA: 53s - loss: 0.6852 - accuracy: 0.532 - ETA: 53s - loss: 0.6849 - accuracy: 0.533 - ETA: 53s - loss: 0.6850 - accuracy: 0.533 - ETA: 52s - loss: 0.6844 - accuracy: 0.534 - ETA: 52s - loss: 0.6832 - accuracy: 0.535 - ETA: 52s - loss: 0.6827 - accuracy: 0.536 - ETA: 52s - loss: 0.6820 - accuracy: 0.537 - ETA: 52s - loss: 0.6821 - accuracy: 0.537 - ETA: 52s - loss: 0.6820 - accuracy: 0.537 - ETA: 52s - loss: 0.6820 - accuracy: 0.537 - ETA: 52s - loss: 0.6813 - accuracy: 0.538 - ETA: 51s - loss: 0.6805 - accuracy: 0.539 - ETA: 51s - loss: 0.6803 - accuracy: 0.539 - ETA: 51s - loss: 0.6796 - accuracy: 0.540 - ETA: 51s - loss: 0.6789 - accuracy: 0.541 - ETA: 51s - loss: 0.6783 - accuracy: 0.543 - ETA: 51s - loss: 0.6775 - accuracy: 0.5443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/625 [================>.............] - ETA: 51s - loss: 0.6766 - accuracy: 0.545 - ETA: 51s - loss: 0.6767 - accuracy: 0.546 - ETA: 51s - loss: 0.6763 - accuracy: 0.547 - ETA: 50s - loss: 0.6757 - accuracy: 0.547 - ETA: 50s - loss: 0.6758 - accuracy: 0.548 - ETA: 50s - loss: 0.6760 - accuracy: 0.548 - ETA: 50s - loss: 0.6765 - accuracy: 0.547 - ETA: 50s - loss: 0.6759 - accuracy: 0.548 - ETA: 50s - loss: 0.6760 - accuracy: 0.548 - ETA: 50s - loss: 0.6761 - accuracy: 0.548 - ETA: 50s - loss: 0.6755 - accuracy: 0.548 - ETA: 49s - loss: 0.6746 - accuracy: 0.549 - ETA: 49s - loss: 0.6742 - accuracy: 0.550 - ETA: 49s - loss: 0.6736 - accuracy: 0.551 - ETA: 49s - loss: 0.6732 - accuracy: 0.552 - ETA: 49s - loss: 0.6730 - accuracy: 0.552 - ETA: 49s - loss: 0.6721 - accuracy: 0.553 - ETA: 49s - loss: 0.6717 - accuracy: 0.554 - ETA: 49s - loss: 0.6713 - accuracy: 0.554 - ETA: 48s - loss: 0.6710 - accuracy: 0.555 - ETA: 48s - loss: 0.6702 - accuracy: 0.556 - ETA: 48s - loss: 0.6693 - accuracy: 0.557 - ETA: 48s - loss: 0.6685 - accuracy: 0.559 - ETA: 48s - loss: 0.6679 - accuracy: 0.559 - ETA: 48s - loss: 0.6673 - accuracy: 0.560 - ETA: 48s - loss: 0.6666 - accuracy: 0.561 - ETA: 48s - loss: 0.6660 - accuracy: 0.561 - ETA: 47s - loss: 0.6650 - accuracy: 0.563 - ETA: 47s - loss: 0.6641 - accuracy: 0.564 - ETA: 47s - loss: 0.6633 - accuracy: 0.565 - ETA: 47s - loss: 0.6625 - accuracy: 0.566 - ETA: 47s - loss: 0.6616 - accuracy: 0.567 - ETA: 47s - loss: 0.6606 - accuracy: 0.567 - ETA: 47s - loss: 0.6597 - accuracy: 0.568 - ETA: 47s - loss: 0.6592 - accuracy: 0.569 - ETA: 46s - loss: 0.6596 - accuracy: 0.569 - ETA: 46s - loss: 0.6585 - accuracy: 0.570 - ETA: 46s - loss: 0.6579 - accuracy: 0.571 - ETA: 46s - loss: 0.6570 - accuracy: 0.572 - ETA: 46s - loss: 0.6567 - accuracy: 0.573 - ETA: 46s - loss: 0.6557 - accuracy: 0.574 - ETA: 46s - loss: 0.6549 - accuracy: 0.575 - ETA: 46s - loss: 0.6544 - accuracy: 0.575 - ETA: 46s - loss: 0.6533 - accuracy: 0.576 - ETA: 45s - loss: 0.6531 - accuracy: 0.577 - ETA: 45s - loss: 0.6523 - accuracy: 0.578 - ETA: 45s - loss: 0.6515 - accuracy: 0.579 - ETA: 45s - loss: 0.6507 - accuracy: 0.579 - ETA: 45s - loss: 0.6506 - accuracy: 0.579 - ETA: 45s - loss: 0.6494 - accuracy: 0.581 - ETA: 45s - loss: 0.6484 - accuracy: 0.582 - ETA: 45s - loss: 0.6483 - accuracy: 0.582 - ETA: 45s - loss: 0.6479 - accuracy: 0.583 - ETA: 44s - loss: 0.6473 - accuracy: 0.584 - ETA: 44s - loss: 0.6465 - accuracy: 0.584 - ETA: 44s - loss: 0.6465 - accuracy: 0.585 - ETA: 44s - loss: 0.6463 - accuracy: 0.585 - ETA: 44s - loss: 0.6453 - accuracy: 0.586 - ETA: 44s - loss: 0.6443 - accuracy: 0.587 - ETA: 44s - loss: 0.6433 - accuracy: 0.588 - ETA: 44s - loss: 0.6423 - accuracy: 0.589 - ETA: 43s - loss: 0.6413 - accuracy: 0.590 - ETA: 43s - loss: 0.6407 - accuracy: 0.591 - ETA: 43s - loss: 0.6395 - accuracy: 0.592 - ETA: 43s - loss: 0.6382 - accuracy: 0.593 - ETA: 43s - loss: 0.6375 - accuracy: 0.593 - ETA: 43s - loss: 0.6366 - accuracy: 0.594 - ETA: 43s - loss: 0.6359 - accuracy: 0.595 - ETA: 43s - loss: 0.6351 - accuracy: 0.596 - ETA: 42s - loss: 0.6345 - accuracy: 0.596 - ETA: 42s - loss: 0.6339 - accuracy: 0.597 - ETA: 42s - loss: 0.6333 - accuracy: 0.598 - ETA: 42s - loss: 0.6329 - accuracy: 0.598 - ETA: 42s - loss: 0.6322 - accuracy: 0.599 - ETA: 42s - loss: 0.6317 - accuracy: 0.600 - ETA: 42s - loss: 0.6308 - accuracy: 0.600 - ETA: 42s - loss: 0.6306 - accuracy: 0.601 - ETA: 42s - loss: 0.6304 - accuracy: 0.601 - ETA: 41s - loss: 0.6297 - accuracy: 0.602 - ETA: 41s - loss: 0.6286 - accuracy: 0.603 - ETA: 41s - loss: 0.6287 - accuracy: 0.603 - ETA: 41s - loss: 0.6277 - accuracy: 0.604 - ETA: 41s - loss: 0.6267 - accuracy: 0.605 - ETA: 41s - loss: 0.6259 - accuracy: 0.606 - ETA: 41s - loss: 0.6252 - accuracy: 0.606 - ETA: 41s - loss: 0.6247 - accuracy: 0.607 - ETA: 40s - loss: 0.6241 - accuracy: 0.607 - ETA: 40s - loss: 0.6234 - accuracy: 0.608 - ETA: 40s - loss: 0.6224 - accuracy: 0.609 - ETA: 40s - loss: 0.6217 - accuracy: 0.609 - ETA: 40s - loss: 0.6217 - accuracy: 0.609 - ETA: 40s - loss: 0.6210 - accuracy: 0.610 - ETA: 40s - loss: 0.6207 - accuracy: 0.611 - ETA: 40s - loss: 0.6205 - accuracy: 0.612 - ETA: 39s - loss: 0.6193 - accuracy: 0.613 - ETA: 39s - loss: 0.6182 - accuracy: 0.614 - ETA: 39s - loss: 0.6175 - accuracy: 0.615 - ETA: 39s - loss: 0.6167 - accuracy: 0.615 - ETA: 39s - loss: 0.6154 - accuracy: 0.616 - ETA: 39s - loss: 0.6150 - accuracy: 0.617 - ETA: 39s - loss: 0.6141 - accuracy: 0.618 - ETA: 39s - loss: 0.6141 - accuracy: 0.618 - ETA: 39s - loss: 0.6134 - accuracy: 0.619 - ETA: 38s - loss: 0.6124 - accuracy: 0.620 - ETA: 38s - loss: 0.6117 - accuracy: 0.620 - ETA: 38s - loss: 0.6111 - accuracy: 0.621 - ETA: 38s - loss: 0.6104 - accuracy: 0.622 - ETA: 38s - loss: 0.6097 - accuracy: 0.623 - ETA: 38s - loss: 0.6093 - accuracy: 0.623 - ETA: 38s - loss: 0.6082 - accuracy: 0.624 - ETA: 38s - loss: 0.6079 - accuracy: 0.624 - ETA: 37s - loss: 0.6070 - accuracy: 0.625 - ETA: 37s - loss: 0.6065 - accuracy: 0.626 - ETA: 37s - loss: 0.6058 - accuracy: 0.626 - ETA: 37s - loss: 0.6053 - accuracy: 0.627 - ETA: 37s - loss: 0.6047 - accuracy: 0.628 - ETA: 37s - loss: 0.6040 - accuracy: 0.628 - ETA: 37s - loss: 0.6029 - accuracy: 0.629 - ETA: 37s - loss: 0.6026 - accuracy: 0.630 - ETA: 37s - loss: 0.6012 - accuracy: 0.631 - ETA: 36s - loss: 0.6007 - accuracy: 0.631 - ETA: 36s - loss: 0.6002 - accuracy: 0.632 - ETA: 36s - loss: 0.5996 - accuracy: 0.632 - ETA: 36s - loss: 0.5995 - accuracy: 0.633 - ETA: 36s - loss: 0.5991 - accuracy: 0.633 - ETA: 36s - loss: 0.5986 - accuracy: 0.634 - ETA: 36s - loss: 0.5978 - accuracy: 0.635 - ETA: 36s - loss: 0.5972 - accuracy: 0.635 - ETA: 36s - loss: 0.5969 - accuracy: 0.636 - ETA: 35s - loss: 0.5963 - accuracy: 0.636 - ETA: 35s - loss: 0.5966 - accuracy: 0.636 - ETA: 35s - loss: 0.5962 - accuracy: 0.637 - ETA: 35s - loss: 0.5955 - accuracy: 0.638 - ETA: 35s - loss: 0.5947 - accuracy: 0.639 - ETA: 35s - loss: 0.5939 - accuracy: 0.639 - ETA: 35s - loss: 0.5933 - accuracy: 0.640 - ETA: 35s - loss: 0.5927 - accuracy: 0.640 - ETA: 34s - loss: 0.5920 - accuracy: 0.641 - ETA: 34s - loss: 0.5916 - accuracy: 0.641 - ETA: 34s - loss: 0.5912 - accuracy: 0.641 - ETA: 34s - loss: 0.5911 - accuracy: 0.642 - ETA: 34s - loss: 0.5905 - accuracy: 0.642 - ETA: 34s - loss: 0.5898 - accuracy: 0.643 - ETA: 34s - loss: 0.5896 - accuracy: 0.643 - ETA: 34s - loss: 0.5896 - accuracy: 0.643 - ETA: 34s - loss: 0.5888 - accuracy: 0.644 - ETA: 33s - loss: 0.5884 - accuracy: 0.645 - ETA: 33s - loss: 0.5873 - accuracy: 0.645 - ETA: 33s - loss: 0.5867 - accuracy: 0.646 - ETA: 33s - loss: 0.5859 - accuracy: 0.647 - ETA: 33s - loss: 0.5849 - accuracy: 0.647 - ETA: 33s - loss: 0.5841 - accuracy: 0.648 - ETA: 33s - loss: 0.5838 - accuracy: 0.648 - ETA: 33s - loss: 0.5831 - accuracy: 0.649 - ETA: 32s - loss: 0.5823 - accuracy: 0.650 - ETA: 32s - loss: 0.5819 - accuracy: 0.650 - ETA: 32s - loss: 0.5814 - accuracy: 0.651 - ETA: 32s - loss: 0.5810 - accuracy: 0.651 - ETA: 32s - loss: 0.5807 - accuracy: 0.651 - ETA: 32s - loss: 0.5799 - accuracy: 0.652 - ETA: 32s - loss: 0.5791 - accuracy: 0.653 - ETA: 32s - loss: 0.5785 - accuracy: 0.653 - ETA: 32s - loss: 0.5778 - accuracy: 0.654 - ETA: 31s - loss: 0.5768 - accuracy: 0.654 - ETA: 31s - loss: 0.5761 - accuracy: 0.655 - ETA: 31s - loss: 0.5755 - accuracy: 0.655 - ETA: 31s - loss: 0.5751 - accuracy: 0.656 - ETA: 31s - loss: 0.5746 - accuracy: 0.656 - ETA: 31s - loss: 0.5744 - accuracy: 0.657 - ETA: 31s - loss: 0.5738 - accuracy: 0.657 - ETA: 31s - loss: 0.5738 - accuracy: 0.657 - ETA: 31s - loss: 0.5736 - accuracy: 0.657 - ETA: 30s - loss: 0.5731 - accuracy: 0.658 - ETA: 30s - loss: 0.5723 - accuracy: 0.658 - ETA: 30s - loss: 0.5718 - accuracy: 0.659 - ETA: 30s - loss: 0.5709 - accuracy: 0.659 - ETA: 30s - loss: 0.5706 - accuracy: 0.660 - ETA: 30s - loss: 0.5700 - accuracy: 0.660 - ETA: 30s - loss: 0.5699 - accuracy: 0.661 - ETA: 30s - loss: 0.5697 - accuracy: 0.661 - ETA: 29s - loss: 0.5694 - accuracy: 0.661 - ETA: 29s - loss: 0.5685 - accuracy: 0.662 - ETA: 29s - loss: 0.5681 - accuracy: 0.663 - ETA: 29s - loss: 0.5676 - accuracy: 0.663 - ETA: 29s - loss: 0.5673 - accuracy: 0.663 - ETA: 29s - loss: 0.5672 - accuracy: 0.6643"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/625 [=========================>....] - ETA: 29s - loss: 0.5666 - accuracy: 0.664 - ETA: 29s - loss: 0.5661 - accuracy: 0.665 - ETA: 29s - loss: 0.5654 - accuracy: 0.665 - ETA: 28s - loss: 0.5651 - accuracy: 0.666 - ETA: 28s - loss: 0.5647 - accuracy: 0.666 - ETA: 28s - loss: 0.5643 - accuracy: 0.666 - ETA: 28s - loss: 0.5634 - accuracy: 0.667 - ETA: 28s - loss: 0.5630 - accuracy: 0.668 - ETA: 28s - loss: 0.5622 - accuracy: 0.668 - ETA: 28s - loss: 0.5620 - accuracy: 0.669 - ETA: 28s - loss: 0.5620 - accuracy: 0.669 - ETA: 28s - loss: 0.5611 - accuracy: 0.670 - ETA: 27s - loss: 0.5610 - accuracy: 0.670 - ETA: 27s - loss: 0.5606 - accuracy: 0.670 - ETA: 27s - loss: 0.5602 - accuracy: 0.670 - ETA: 27s - loss: 0.5600 - accuracy: 0.671 - ETA: 27s - loss: 0.5596 - accuracy: 0.671 - ETA: 27s - loss: 0.5593 - accuracy: 0.671 - ETA: 27s - loss: 0.5593 - accuracy: 0.671 - ETA: 27s - loss: 0.5589 - accuracy: 0.672 - ETA: 27s - loss: 0.5583 - accuracy: 0.672 - ETA: 26s - loss: 0.5578 - accuracy: 0.672 - ETA: 26s - loss: 0.5575 - accuracy: 0.673 - ETA: 26s - loss: 0.5569 - accuracy: 0.673 - ETA: 26s - loss: 0.5566 - accuracy: 0.673 - ETA: 26s - loss: 0.5568 - accuracy: 0.674 - ETA: 26s - loss: 0.5568 - accuracy: 0.674 - ETA: 26s - loss: 0.5564 - accuracy: 0.674 - ETA: 26s - loss: 0.5558 - accuracy: 0.675 - ETA: 25s - loss: 0.5554 - accuracy: 0.675 - ETA: 25s - loss: 0.5547 - accuracy: 0.676 - ETA: 25s - loss: 0.5543 - accuracy: 0.676 - ETA: 25s - loss: 0.5540 - accuracy: 0.676 - ETA: 25s - loss: 0.5535 - accuracy: 0.677 - ETA: 25s - loss: 0.5534 - accuracy: 0.677 - ETA: 25s - loss: 0.5528 - accuracy: 0.677 - ETA: 25s - loss: 0.5523 - accuracy: 0.678 - ETA: 25s - loss: 0.5517 - accuracy: 0.678 - ETA: 24s - loss: 0.5518 - accuracy: 0.678 - ETA: 24s - loss: 0.5511 - accuracy: 0.679 - ETA: 24s - loss: 0.5506 - accuracy: 0.679 - ETA: 24s - loss: 0.5501 - accuracy: 0.680 - ETA: 24s - loss: 0.5493 - accuracy: 0.680 - ETA: 24s - loss: 0.5488 - accuracy: 0.681 - ETA: 24s - loss: 0.5481 - accuracy: 0.681 - ETA: 24s - loss: 0.5474 - accuracy: 0.682 - ETA: 23s - loss: 0.5469 - accuracy: 0.682 - ETA: 23s - loss: 0.5467 - accuracy: 0.682 - ETA: 23s - loss: 0.5460 - accuracy: 0.683 - ETA: 23s - loss: 0.5453 - accuracy: 0.683 - ETA: 23s - loss: 0.5446 - accuracy: 0.684 - ETA: 23s - loss: 0.5439 - accuracy: 0.684 - ETA: 23s - loss: 0.5431 - accuracy: 0.685 - ETA: 23s - loss: 0.5425 - accuracy: 0.686 - ETA: 23s - loss: 0.5419 - accuracy: 0.686 - ETA: 22s - loss: 0.5418 - accuracy: 0.686 - ETA: 22s - loss: 0.5415 - accuracy: 0.686 - ETA: 22s - loss: 0.5412 - accuracy: 0.686 - ETA: 22s - loss: 0.5409 - accuracy: 0.687 - ETA: 22s - loss: 0.5405 - accuracy: 0.687 - ETA: 22s - loss: 0.5400 - accuracy: 0.687 - ETA: 22s - loss: 0.5397 - accuracy: 0.688 - ETA: 22s - loss: 0.5391 - accuracy: 0.688 - ETA: 22s - loss: 0.5389 - accuracy: 0.688 - ETA: 21s - loss: 0.5381 - accuracy: 0.689 - ETA: 21s - loss: 0.5385 - accuracy: 0.689 - ETA: 21s - loss: 0.5381 - accuracy: 0.689 - ETA: 21s - loss: 0.5379 - accuracy: 0.689 - ETA: 21s - loss: 0.5378 - accuracy: 0.689 - ETA: 21s - loss: 0.5375 - accuracy: 0.690 - ETA: 21s - loss: 0.5368 - accuracy: 0.690 - ETA: 21s - loss: 0.5366 - accuracy: 0.691 - ETA: 20s - loss: 0.5362 - accuracy: 0.691 - ETA: 20s - loss: 0.5357 - accuracy: 0.691 - ETA: 20s - loss: 0.5354 - accuracy: 0.692 - ETA: 20s - loss: 0.5347 - accuracy: 0.692 - ETA: 20s - loss: 0.5340 - accuracy: 0.693 - ETA: 20s - loss: 0.5335 - accuracy: 0.693 - ETA: 20s - loss: 0.5332 - accuracy: 0.694 - ETA: 20s - loss: 0.5333 - accuracy: 0.694 - ETA: 20s - loss: 0.5327 - accuracy: 0.694 - ETA: 19s - loss: 0.5325 - accuracy: 0.695 - ETA: 19s - loss: 0.5322 - accuracy: 0.695 - ETA: 19s - loss: 0.5319 - accuracy: 0.695 - ETA: 19s - loss: 0.5313 - accuracy: 0.696 - ETA: 19s - loss: 0.5310 - accuracy: 0.696 - ETA: 19s - loss: 0.5306 - accuracy: 0.696 - ETA: 19s - loss: 0.5300 - accuracy: 0.697 - ETA: 19s - loss: 0.5296 - accuracy: 0.697 - ETA: 19s - loss: 0.5293 - accuracy: 0.697 - ETA: 18s - loss: 0.5288 - accuracy: 0.698 - ETA: 18s - loss: 0.5287 - accuracy: 0.698 - ETA: 18s - loss: 0.5284 - accuracy: 0.698 - ETA: 18s - loss: 0.5280 - accuracy: 0.698 - ETA: 18s - loss: 0.5277 - accuracy: 0.699 - ETA: 18s - loss: 0.5274 - accuracy: 0.699 - ETA: 18s - loss: 0.5268 - accuracy: 0.699 - ETA: 18s - loss: 0.5264 - accuracy: 0.700 - ETA: 17s - loss: 0.5264 - accuracy: 0.699 - ETA: 17s - loss: 0.5261 - accuracy: 0.700 - ETA: 17s - loss: 0.5260 - accuracy: 0.700 - ETA: 17s - loss: 0.5257 - accuracy: 0.700 - ETA: 17s - loss: 0.5255 - accuracy: 0.700 - ETA: 17s - loss: 0.5249 - accuracy: 0.701 - ETA: 17s - loss: 0.5244 - accuracy: 0.701 - ETA: 17s - loss: 0.5242 - accuracy: 0.701 - ETA: 17s - loss: 0.5244 - accuracy: 0.701 - ETA: 16s - loss: 0.5241 - accuracy: 0.701 - ETA: 16s - loss: 0.5236 - accuracy: 0.702 - ETA: 16s - loss: 0.5230 - accuracy: 0.702 - ETA: 16s - loss: 0.5223 - accuracy: 0.703 - ETA: 16s - loss: 0.5218 - accuracy: 0.703 - ETA: 16s - loss: 0.5213 - accuracy: 0.704 - ETA: 16s - loss: 0.5210 - accuracy: 0.704 - ETA: 16s - loss: 0.5206 - accuracy: 0.704 - ETA: 16s - loss: 0.5204 - accuracy: 0.704 - ETA: 15s - loss: 0.5203 - accuracy: 0.704 - ETA: 15s - loss: 0.5199 - accuracy: 0.705 - ETA: 15s - loss: 0.5195 - accuracy: 0.705 - ETA: 15s - loss: 0.5189 - accuracy: 0.706 - ETA: 15s - loss: 0.5189 - accuracy: 0.706 - ETA: 15s - loss: 0.5183 - accuracy: 0.706 - ETA: 15s - loss: 0.5181 - accuracy: 0.706 - ETA: 15s - loss: 0.5177 - accuracy: 0.707 - ETA: 14s - loss: 0.5176 - accuracy: 0.707 - ETA: 14s - loss: 0.5171 - accuracy: 0.707 - ETA: 14s - loss: 0.5169 - accuracy: 0.708 - ETA: 14s - loss: 0.5166 - accuracy: 0.708 - ETA: 14s - loss: 0.5162 - accuracy: 0.708 - ETA: 14s - loss: 0.5159 - accuracy: 0.708 - ETA: 14s - loss: 0.5156 - accuracy: 0.709 - ETA: 14s - loss: 0.5150 - accuracy: 0.709 - ETA: 14s - loss: 0.5145 - accuracy: 0.710 - ETA: 13s - loss: 0.5141 - accuracy: 0.710 - ETA: 13s - loss: 0.5135 - accuracy: 0.710 - ETA: 13s - loss: 0.5134 - accuracy: 0.711 - ETA: 13s - loss: 0.5134 - accuracy: 0.711 - ETA: 13s - loss: 0.5129 - accuracy: 0.711 - ETA: 13s - loss: 0.5125 - accuracy: 0.711 - ETA: 13s - loss: 0.5123 - accuracy: 0.712 - ETA: 13s - loss: 0.5118 - accuracy: 0.712 - ETA: 13s - loss: 0.5115 - accuracy: 0.712 - ETA: 12s - loss: 0.5112 - accuracy: 0.712 - ETA: 12s - loss: 0.5109 - accuracy: 0.713 - ETA: 12s - loss: 0.5107 - accuracy: 0.713 - ETA: 12s - loss: 0.5103 - accuracy: 0.713 - ETA: 12s - loss: 0.5100 - accuracy: 0.713 - ETA: 12s - loss: 0.5095 - accuracy: 0.714 - ETA: 12s - loss: 0.5089 - accuracy: 0.714 - ETA: 12s - loss: 0.5088 - accuracy: 0.714 - ETA: 11s - loss: 0.5082 - accuracy: 0.715 - ETA: 11s - loss: 0.5079 - accuracy: 0.715 - ETA: 11s - loss: 0.5077 - accuracy: 0.715 - ETA: 11s - loss: 0.5076 - accuracy: 0.715 - ETA: 11s - loss: 0.5071 - accuracy: 0.716 - ETA: 11s - loss: 0.5069 - accuracy: 0.716 - ETA: 11s - loss: 0.5064 - accuracy: 0.716 - ETA: 11s - loss: 0.5062 - accuracy: 0.716 - ETA: 11s - loss: 0.5058 - accuracy: 0.716 - ETA: 10s - loss: 0.5054 - accuracy: 0.717 - ETA: 10s - loss: 0.5052 - accuracy: 0.717 - ETA: 10s - loss: 0.5049 - accuracy: 0.717 - ETA: 10s - loss: 0.5045 - accuracy: 0.718 - ETA: 10s - loss: 0.5040 - accuracy: 0.718 - ETA: 10s - loss: 0.5037 - accuracy: 0.718 - ETA: 10s - loss: 0.5034 - accuracy: 0.718 - ETA: 10s - loss: 0.5033 - accuracy: 0.719 - ETA: 10s - loss: 0.5027 - accuracy: 0.719 - ETA: 9s - loss: 0.5021 - accuracy: 0.720 - ETA: 9s - loss: 0.5020 - accuracy: 0.72 - ETA: 9s - loss: 0.5015 - accuracy: 0.72 - ETA: 9s - loss: 0.5011 - accuracy: 0.72 - ETA: 9s - loss: 0.5008 - accuracy: 0.72 - ETA: 9s - loss: 0.5009 - accuracy: 0.72 - ETA: 9s - loss: 0.5005 - accuracy: 0.72 - ETA: 9s - loss: 0.5002 - accuracy: 0.72 - ETA: 8s - loss: 0.5001 - accuracy: 0.72 - ETA: 8s - loss: 0.4996 - accuracy: 0.72 - ETA: 8s - loss: 0.4990 - accuracy: 0.72 - ETA: 8s - loss: 0.4988 - accuracy: 0.72 - ETA: 8s - loss: 0.4983 - accuracy: 0.72 - ETA: 8s - loss: 0.4981 - accuracy: 0.72 - ETA: 8s - loss: 0.4978 - accuracy: 0.72 - ETA: 8s - loss: 0.4973 - accuracy: 0.72 - ETA: 8s - loss: 0.4969 - accuracy: 0.72 - ETA: 7s - loss: 0.4966 - accuracy: 0.72 - ETA: 7s - loss: 0.4960 - accuracy: 0.7247"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 7s - loss: 0.4955 - accuracy: 0.72 - ETA: 7s - loss: 0.4949 - accuracy: 0.72 - ETA: 7s - loss: 0.4946 - accuracy: 0.72 - ETA: 7s - loss: 0.4943 - accuracy: 0.72 - ETA: 7s - loss: 0.4942 - accuracy: 0.72 - ETA: 7s - loss: 0.4938 - accuracy: 0.72 - ETA: 6s - loss: 0.4932 - accuracy: 0.72 - ETA: 6s - loss: 0.4926 - accuracy: 0.72 - ETA: 6s - loss: 0.4922 - accuracy: 0.72 - ETA: 6s - loss: 0.4917 - accuracy: 0.72 - ETA: 6s - loss: 0.4914 - accuracy: 0.72 - ETA: 6s - loss: 0.4909 - accuracy: 0.72 - ETA: 6s - loss: 0.4904 - accuracy: 0.72 - ETA: 6s - loss: 0.4902 - accuracy: 0.72 - ETA: 6s - loss: 0.4900 - accuracy: 0.72 - ETA: 5s - loss: 0.4896 - accuracy: 0.72 - ETA: 5s - loss: 0.4892 - accuracy: 0.72 - ETA: 5s - loss: 0.4887 - accuracy: 0.73 - ETA: 5s - loss: 0.4887 - accuracy: 0.73 - ETA: 5s - loss: 0.4884 - accuracy: 0.73 - ETA: 5s - loss: 0.4880 - accuracy: 0.73 - ETA: 5s - loss: 0.4876 - accuracy: 0.73 - ETA: 5s - loss: 0.4871 - accuracy: 0.73 - ETA: 5s - loss: 0.4868 - accuracy: 0.73 - ETA: 4s - loss: 0.4865 - accuracy: 0.73 - ETA: 4s - loss: 0.4859 - accuracy: 0.73 - ETA: 4s - loss: 0.4856 - accuracy: 0.73 - ETA: 4s - loss: 0.4856 - accuracy: 0.73 - ETA: 4s - loss: 0.4852 - accuracy: 0.73 - ETA: 4s - loss: 0.4848 - accuracy: 0.73 - ETA: 4s - loss: 0.4846 - accuracy: 0.73 - ETA: 4s - loss: 0.4844 - accuracy: 0.73 - ETA: 3s - loss: 0.4845 - accuracy: 0.73 - ETA: 3s - loss: 0.4843 - accuracy: 0.73 - ETA: 3s - loss: 0.4841 - accuracy: 0.73 - ETA: 3s - loss: 0.4838 - accuracy: 0.73 - ETA: 3s - loss: 0.4840 - accuracy: 0.73 - ETA: 3s - loss: 0.4838 - accuracy: 0.73 - ETA: 3s - loss: 0.4834 - accuracy: 0.73 - ETA: 3s - loss: 0.4830 - accuracy: 0.73 - ETA: 3s - loss: 0.4826 - accuracy: 0.73 - ETA: 2s - loss: 0.4822 - accuracy: 0.73 - ETA: 2s - loss: 0.4822 - accuracy: 0.73 - ETA: 2s - loss: 0.4819 - accuracy: 0.73 - ETA: 2s - loss: 0.4813 - accuracy: 0.73 - ETA: 2s - loss: 0.4809 - accuracy: 0.73 - ETA: 2s - loss: 0.4806 - accuracy: 0.73 - ETA: 2s - loss: 0.4803 - accuracy: 0.73 - ETA: 2s - loss: 0.4805 - accuracy: 0.73 - ETA: 1s - loss: 0.4800 - accuracy: 0.73 - ETA: 1s - loss: 0.4797 - accuracy: 0.73 - ETA: 1s - loss: 0.4792 - accuracy: 0.73 - ETA: 1s - loss: 0.4789 - accuracy: 0.73 - ETA: 1s - loss: 0.4783 - accuracy: 0.73 - ETA: 1s - loss: 0.4779 - accuracy: 0.73 - ETA: 1s - loss: 0.4776 - accuracy: 0.73 - ETA: 1s - loss: 0.4771 - accuracy: 0.73 - ETA: 1s - loss: 0.4767 - accuracy: 0.73 - ETA: 0s - loss: 0.4764 - accuracy: 0.73 - ETA: 0s - loss: 0.4762 - accuracy: 0.73 - ETA: 0s - loss: 0.4759 - accuracy: 0.74 - ETA: 0s - loss: 0.4757 - accuracy: 0.74 - ETA: 0s - loss: 0.4756 - accuracy: 0.74 - ETA: 0s - loss: 0.4755 - accuracy: 0.74 - ETA: 0s - loss: 0.4754 - accuracy: 0.74 - ETA: 0s - loss: 0.4752 - accuracy: 0.74 - 79s 126ms/step - loss: 0.4748 - accuracy: 0.7411 - val_loss: 0.2799 - val_accuracy: 0.8904\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/625 [=======>......................] - ETA: 1:26 - loss: 0.2098 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2257 - accuracy: 0.89 - ETA: 1:19 - loss: 0.2323 - accuracy: 0.89 - ETA: 1:18 - loss: 0.2606 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2550 - accuracy: 0.87 - ETA: 1:17 - loss: 0.2534 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2512 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2493 - accuracy: 0.89 - ETA: 1:17 - loss: 0.2466 - accuracy: 0.89 - ETA: 1:20 - loss: 0.2620 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2740 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2854 - accuracy: 0.86 - ETA: 1:25 - loss: 0.2716 - accuracy: 0.87 - ETA: 1:26 - loss: 0.2717 - accuracy: 0.87 - ETA: 1:26 - loss: 0.2705 - accuracy: 0.88 - ETA: 1:26 - loss: 0.2719 - accuracy: 0.88 - ETA: 1:26 - loss: 0.2783 - accuracy: 0.87 - ETA: 1:25 - loss: 0.2756 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2798 - accuracy: 0.87 - ETA: 1:25 - loss: 0.2863 - accuracy: 0.87 - ETA: 1:25 - loss: 0.2824 - accuracy: 0.87 - ETA: 1:25 - loss: 0.2854 - accuracy: 0.87 - ETA: 1:25 - loss: 0.2779 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2768 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2782 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2725 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2717 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2778 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2770 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2794 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2829 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2836 - accuracy: 0.87 - ETA: 1:25 - loss: 0.2840 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2861 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2855 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2835 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2863 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2889 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2910 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2879 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2873 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2875 - accuracy: 0.87 - ETA: 1:23 - loss: 0.2873 - accuracy: 0.87 - ETA: 1:23 - loss: 0.2850 - accuracy: 0.87 - ETA: 1:23 - loss: 0.2846 - accuracy: 0.87 - ETA: 1:22 - loss: 0.2839 - accuracy: 0.87 - ETA: 1:22 - loss: 0.2890 - accuracy: 0.87 - ETA: 1:22 - loss: 0.2889 - accuracy: 0.87 - ETA: 1:21 - loss: 0.2881 - accuracy: 0.87 - ETA: 1:21 - loss: 0.2880 - accuracy: 0.87 - ETA: 1:21 - loss: 0.2865 - accuracy: 0.87 - ETA: 1:20 - loss: 0.2857 - accuracy: 0.87 - ETA: 1:20 - loss: 0.2863 - accuracy: 0.87 - ETA: 1:20 - loss: 0.2834 - accuracy: 0.88 - ETA: 1:20 - loss: 0.2849 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2879 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2887 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2895 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2888 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2895 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2906 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2914 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2914 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2925 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2913 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2903 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2899 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2946 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2963 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2956 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2948 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2958 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2964 - accuracy: 0.87 - ETA: 1:14 - loss: 0.2955 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2953 - accuracy: 0.87 - ETA: 1:14 - loss: 0.2968 - accuracy: 0.87 - ETA: 1:13 - loss: 0.2955 - accuracy: 0.87 - ETA: 1:13 - loss: 0.2964 - accuracy: 0.87 - ETA: 1:13 - loss: 0.2991 - accuracy: 0.87 - ETA: 1:13 - loss: 0.2976 - accuracy: 0.87 - ETA: 1:12 - loss: 0.2961 - accuracy: 0.87 - ETA: 1:12 - loss: 0.2949 - accuracy: 0.88 - ETA: 1:12 - loss: 0.2966 - accuracy: 0.87 - ETA: 1:12 - loss: 0.2957 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2958 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2963 - accuracy: 0.87 - ETA: 1:11 - loss: 0.2968 - accuracy: 0.87 - ETA: 1:11 - loss: 0.2974 - accuracy: 0.87 - ETA: 1:10 - loss: 0.2994 - accuracy: 0.87 - ETA: 1:10 - loss: 0.2984 - accuracy: 0.87 - ETA: 1:10 - loss: 0.2982 - accuracy: 0.87 - ETA: 1:10 - loss: 0.2974 - accuracy: 0.87 - ETA: 1:10 - loss: 0.2968 - accuracy: 0.87 - ETA: 1:10 - loss: 0.2968 - accuracy: 0.87 - ETA: 1:09 - loss: 0.2983 - accuracy: 0.87 - ETA: 1:09 - loss: 0.2989 - accuracy: 0.87 - ETA: 1:09 - loss: 0.2989 - accuracy: 0.87 - ETA: 1:09 - loss: 0.2979 - accuracy: 0.87 - ETA: 1:09 - loss: 0.2982 - accuracy: 0.87 - ETA: 1:08 - loss: 0.2981 - accuracy: 0.87 - ETA: 1:08 - loss: 0.2986 - accuracy: 0.87 - ETA: 1:08 - loss: 0.3000 - accuracy: 0.87 - ETA: 1:08 - loss: 0.2993 - accuracy: 0.87 - ETA: 1:08 - loss: 0.2987 - accuracy: 0.87 - ETA: 1:07 - loss: 0.2982 - accuracy: 0.87 - ETA: 1:07 - loss: 0.2978 - accuracy: 0.87 - ETA: 1:07 - loss: 0.2976 - accuracy: 0.87 - ETA: 1:07 - loss: 0.2976 - accuracy: 0.87 - ETA: 1:06 - loss: 0.2966 - accuracy: 0.87 - ETA: 1:06 - loss: 0.2971 - accuracy: 0.87 - ETA: 1:06 - loss: 0.2969 - accuracy: 0.87 - ETA: 1:06 - loss: 0.2959 - accuracy: 0.87 - ETA: 1:06 - loss: 0.2955 - accuracy: 0.87 - ETA: 1:06 - loss: 0.2955 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2949 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2953 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2949 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2938 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2929 - accuracy: 0.87 - ETA: 1:04 - loss: 0.2930 - accuracy: 0.87 - ETA: 1:04 - loss: 0.2936 - accuracy: 0.87 - ETA: 1:04 - loss: 0.2933 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2934 - accuracy: 0.87 - ETA: 1:04 - loss: 0.2933 - accuracy: 0.87 - ETA: 1:04 - loss: 0.2930 - accuracy: 0.87 - ETA: 1:03 - loss: 0.2948 - accuracy: 0.87 - ETA: 1:03 - loss: 0.2941 - accuracy: 0.87 - ETA: 1:03 - loss: 0.2935 - accuracy: 0.87 - ETA: 1:03 - loss: 0.2940 - accuracy: 0.87 - ETA: 1:03 - loss: 0.2928 - accuracy: 0.87 - ETA: 1:03 - loss: 0.2933 - accuracy: 0.87 - ETA: 1:03 - loss: 0.2927 - accuracy: 0.87 - ETA: 1:02 - loss: 0.2914 - accuracy: 0.87 - ETA: 1:02 - loss: 0.2909 - accuracy: 0.87 - ETA: 1:02 - loss: 0.2907 - accuracy: 0.87 - ETA: 1:02 - loss: 0.2918 - accuracy: 0.87 - ETA: 1:02 - loss: 0.2910 - accuracy: 0.87 - ETA: 1:01 - loss: 0.2901 - accuracy: 0.87 - ETA: 1:01 - loss: 0.2899 - accuracy: 0.87 - ETA: 1:01 - loss: 0.2894 - accuracy: 0.88 - ETA: 1:01 - loss: 0.2901 - accuracy: 0.87 - ETA: 1:01 - loss: 0.2908 - accuracy: 0.87 - ETA: 1:01 - loss: 0.2908 - accuracy: 0.87 - ETA: 1:00 - loss: 0.2901 - accuracy: 0.87 - ETA: 1:00 - loss: 0.2905 - accuracy: 0.87 - ETA: 1:00 - loss: 0.2904 - accuracy: 0.87 - ETA: 1:00 - loss: 0.2907 - accuracy: 0.87 - ETA: 1:00 - loss: 0.2909 - accuracy: 0.87 - ETA: 1:00 - loss: 0.2907 - accuracy: 0.87 - ETA: 59s - loss: 0.2896 - accuracy: 0.8794 - ETA: 59s - loss: 0.2907 - accuracy: 0.879 - ETA: 59s - loss: 0.2910 - accuracy: 0.878 - ETA: 59s - loss: 0.2911 - accuracy: 0.878 - ETA: 59s - loss: 0.2918 - accuracy: 0.878 - ETA: 59s - loss: 0.2939 - accuracy: 0.877 - ETA: 59s - loss: 0.2928 - accuracy: 0.878 - ETA: 59s - loss: 0.2931 - accuracy: 0.878 - ETA: 58s - loss: 0.2933 - accuracy: 0.878 - ETA: 58s - loss: 0.2930 - accuracy: 0.878 - ETA: 58s - loss: 0.2928 - accuracy: 0.878 - ETA: 58s - loss: 0.2919 - accuracy: 0.879 - ETA: 58s - loss: 0.2909 - accuracy: 0.879 - ETA: 58s - loss: 0.2925 - accuracy: 0.879 - ETA: 57s - loss: 0.2922 - accuracy: 0.879 - ETA: 57s - loss: 0.2923 - accuracy: 0.879 - ETA: 57s - loss: 0.2918 - accuracy: 0.879 - ETA: 57s - loss: 0.2916 - accuracy: 0.879 - ETA: 57s - loss: 0.2909 - accuracy: 0.880 - ETA: 57s - loss: 0.2906 - accuracy: 0.880 - ETA: 56s - loss: 0.2901 - accuracy: 0.880 - ETA: 56s - loss: 0.2908 - accuracy: 0.879 - ETA: 56s - loss: 0.2907 - accuracy: 0.879 - ETA: 56s - loss: 0.2907 - accuracy: 0.880 - ETA: 56s - loss: 0.2900 - accuracy: 0.880 - ETA: 56s - loss: 0.2905 - accuracy: 0.880 - ETA: 55s - loss: 0.2904 - accuracy: 0.879 - ETA: 55s - loss: 0.2902 - accuracy: 0.879 - ETA: 55s - loss: 0.2896 - accuracy: 0.880 - ETA: 55s - loss: 0.2892 - accuracy: 0.880 - ETA: 55s - loss: 0.2890 - accuracy: 0.880 - ETA: 55s - loss: 0.2895 - accuracy: 0.880 - ETA: 55s - loss: 0.2888 - accuracy: 0.880 - ETA: 54s - loss: 0.2902 - accuracy: 0.879 - ETA: 54s - loss: 0.2914 - accuracy: 0.879 - ETA: 54s - loss: 0.2907 - accuracy: 0.879 - ETA: 54s - loss: 0.2902 - accuracy: 0.8795"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/625 [================>.............] - ETA: 54s - loss: 0.2898 - accuracy: 0.879 - ETA: 54s - loss: 0.2902 - accuracy: 0.879 - ETA: 54s - loss: 0.2897 - accuracy: 0.879 - ETA: 53s - loss: 0.2894 - accuracy: 0.879 - ETA: 53s - loss: 0.2893 - accuracy: 0.879 - ETA: 53s - loss: 0.2885 - accuracy: 0.880 - ETA: 53s - loss: 0.2888 - accuracy: 0.879 - ETA: 53s - loss: 0.2884 - accuracy: 0.880 - ETA: 53s - loss: 0.2879 - accuracy: 0.880 - ETA: 52s - loss: 0.2886 - accuracy: 0.879 - ETA: 52s - loss: 0.2880 - accuracy: 0.880 - ETA: 52s - loss: 0.2883 - accuracy: 0.880 - ETA: 52s - loss: 0.2874 - accuracy: 0.880 - ETA: 52s - loss: 0.2875 - accuracy: 0.880 - ETA: 52s - loss: 0.2870 - accuracy: 0.881 - ETA: 52s - loss: 0.2866 - accuracy: 0.881 - ETA: 51s - loss: 0.2863 - accuracy: 0.881 - ETA: 51s - loss: 0.2861 - accuracy: 0.881 - ETA: 51s - loss: 0.2853 - accuracy: 0.881 - ETA: 51s - loss: 0.2846 - accuracy: 0.882 - ETA: 51s - loss: 0.2841 - accuracy: 0.882 - ETA: 51s - loss: 0.2840 - accuracy: 0.882 - ETA: 51s - loss: 0.2840 - accuracy: 0.882 - ETA: 50s - loss: 0.2838 - accuracy: 0.882 - ETA: 50s - loss: 0.2835 - accuracy: 0.882 - ETA: 50s - loss: 0.2843 - accuracy: 0.882 - ETA: 50s - loss: 0.2840 - accuracy: 0.882 - ETA: 50s - loss: 0.2841 - accuracy: 0.881 - ETA: 50s - loss: 0.2840 - accuracy: 0.882 - ETA: 50s - loss: 0.2839 - accuracy: 0.881 - ETA: 49s - loss: 0.2835 - accuracy: 0.882 - ETA: 49s - loss: 0.2833 - accuracy: 0.882 - ETA: 49s - loss: 0.2831 - accuracy: 0.882 - ETA: 49s - loss: 0.2830 - accuracy: 0.882 - ETA: 49s - loss: 0.2832 - accuracy: 0.882 - ETA: 49s - loss: 0.2832 - accuracy: 0.882 - ETA: 49s - loss: 0.2833 - accuracy: 0.882 - ETA: 48s - loss: 0.2829 - accuracy: 0.882 - ETA: 48s - loss: 0.2824 - accuracy: 0.882 - ETA: 48s - loss: 0.2821 - accuracy: 0.882 - ETA: 48s - loss: 0.2814 - accuracy: 0.883 - ETA: 48s - loss: 0.2818 - accuracy: 0.883 - ETA: 48s - loss: 0.2820 - accuracy: 0.883 - ETA: 48s - loss: 0.2821 - accuracy: 0.883 - ETA: 48s - loss: 0.2818 - accuracy: 0.883 - ETA: 48s - loss: 0.2812 - accuracy: 0.883 - ETA: 47s - loss: 0.2805 - accuracy: 0.884 - ETA: 47s - loss: 0.2803 - accuracy: 0.884 - ETA: 47s - loss: 0.2794 - accuracy: 0.884 - ETA: 47s - loss: 0.2794 - accuracy: 0.884 - ETA: 47s - loss: 0.2790 - accuracy: 0.885 - ETA: 47s - loss: 0.2794 - accuracy: 0.884 - ETA: 47s - loss: 0.2789 - accuracy: 0.885 - ETA: 46s - loss: 0.2788 - accuracy: 0.884 - ETA: 46s - loss: 0.2784 - accuracy: 0.885 - ETA: 46s - loss: 0.2784 - accuracy: 0.884 - ETA: 46s - loss: 0.2780 - accuracy: 0.885 - ETA: 46s - loss: 0.2775 - accuracy: 0.885 - ETA: 46s - loss: 0.2770 - accuracy: 0.885 - ETA: 46s - loss: 0.2766 - accuracy: 0.885 - ETA: 45s - loss: 0.2762 - accuracy: 0.886 - ETA: 45s - loss: 0.2761 - accuracy: 0.886 - ETA: 45s - loss: 0.2754 - accuracy: 0.886 - ETA: 45s - loss: 0.2750 - accuracy: 0.886 - ETA: 45s - loss: 0.2746 - accuracy: 0.886 - ETA: 45s - loss: 0.2739 - accuracy: 0.886 - ETA: 45s - loss: 0.2734 - accuracy: 0.887 - ETA: 45s - loss: 0.2733 - accuracy: 0.886 - ETA: 44s - loss: 0.2731 - accuracy: 0.887 - ETA: 44s - loss: 0.2733 - accuracy: 0.886 - ETA: 44s - loss: 0.2738 - accuracy: 0.886 - ETA: 44s - loss: 0.2735 - accuracy: 0.887 - ETA: 44s - loss: 0.2728 - accuracy: 0.887 - ETA: 44s - loss: 0.2728 - accuracy: 0.887 - ETA: 44s - loss: 0.2721 - accuracy: 0.887 - ETA: 43s - loss: 0.2719 - accuracy: 0.887 - ETA: 43s - loss: 0.2715 - accuracy: 0.888 - ETA: 43s - loss: 0.2707 - accuracy: 0.888 - ETA: 43s - loss: 0.2702 - accuracy: 0.888 - ETA: 43s - loss: 0.2700 - accuracy: 0.888 - ETA: 43s - loss: 0.2705 - accuracy: 0.888 - ETA: 43s - loss: 0.2700 - accuracy: 0.888 - ETA: 43s - loss: 0.2701 - accuracy: 0.888 - ETA: 42s - loss: 0.2700 - accuracy: 0.888 - ETA: 42s - loss: 0.2695 - accuracy: 0.889 - ETA: 42s - loss: 0.2699 - accuracy: 0.888 - ETA: 42s - loss: 0.2703 - accuracy: 0.888 - ETA: 42s - loss: 0.2700 - accuracy: 0.888 - ETA: 42s - loss: 0.2704 - accuracy: 0.888 - ETA: 42s - loss: 0.2702 - accuracy: 0.888 - ETA: 42s - loss: 0.2700 - accuracy: 0.888 - ETA: 41s - loss: 0.2698 - accuracy: 0.888 - ETA: 41s - loss: 0.2693 - accuracy: 0.889 - ETA: 41s - loss: 0.2689 - accuracy: 0.889 - ETA: 41s - loss: 0.2686 - accuracy: 0.889 - ETA: 41s - loss: 0.2687 - accuracy: 0.889 - ETA: 41s - loss: 0.2686 - accuracy: 0.889 - ETA: 41s - loss: 0.2679 - accuracy: 0.889 - ETA: 41s - loss: 0.2685 - accuracy: 0.889 - ETA: 40s - loss: 0.2684 - accuracy: 0.889 - ETA: 40s - loss: 0.2687 - accuracy: 0.889 - ETA: 40s - loss: 0.2686 - accuracy: 0.889 - ETA: 40s - loss: 0.2684 - accuracy: 0.889 - ETA: 40s - loss: 0.2679 - accuracy: 0.890 - ETA: 40s - loss: 0.2675 - accuracy: 0.890 - ETA: 40s - loss: 0.2670 - accuracy: 0.890 - ETA: 40s - loss: 0.2671 - accuracy: 0.890 - ETA: 39s - loss: 0.2673 - accuracy: 0.890 - ETA: 39s - loss: 0.2668 - accuracy: 0.890 - ETA: 39s - loss: 0.2669 - accuracy: 0.890 - ETA: 39s - loss: 0.2666 - accuracy: 0.890 - ETA: 39s - loss: 0.2670 - accuracy: 0.890 - ETA: 39s - loss: 0.2669 - accuracy: 0.890 - ETA: 39s - loss: 0.2668 - accuracy: 0.890 - ETA: 39s - loss: 0.2665 - accuracy: 0.890 - ETA: 39s - loss: 0.2660 - accuracy: 0.891 - ETA: 38s - loss: 0.2657 - accuracy: 0.891 - ETA: 38s - loss: 0.2652 - accuracy: 0.891 - ETA: 38s - loss: 0.2647 - accuracy: 0.891 - ETA: 38s - loss: 0.2646 - accuracy: 0.891 - ETA: 38s - loss: 0.2640 - accuracy: 0.891 - ETA: 38s - loss: 0.2640 - accuracy: 0.891 - ETA: 38s - loss: 0.2642 - accuracy: 0.891 - ETA: 38s - loss: 0.2643 - accuracy: 0.891 - ETA: 38s - loss: 0.2644 - accuracy: 0.891 - ETA: 37s - loss: 0.2641 - accuracy: 0.891 - ETA: 37s - loss: 0.2639 - accuracy: 0.892 - ETA: 37s - loss: 0.2641 - accuracy: 0.891 - ETA: 37s - loss: 0.2641 - accuracy: 0.891 - ETA: 37s - loss: 0.2643 - accuracy: 0.891 - ETA: 37s - loss: 0.2644 - accuracy: 0.891 - ETA: 37s - loss: 0.2640 - accuracy: 0.891 - ETA: 36s - loss: 0.2643 - accuracy: 0.891 - ETA: 36s - loss: 0.2639 - accuracy: 0.891 - ETA: 36s - loss: 0.2644 - accuracy: 0.891 - ETA: 36s - loss: 0.2641 - accuracy: 0.891 - ETA: 36s - loss: 0.2641 - accuracy: 0.891 - ETA: 36s - loss: 0.2643 - accuracy: 0.891 - ETA: 36s - loss: 0.2637 - accuracy: 0.892 - ETA: 36s - loss: 0.2633 - accuracy: 0.892 - ETA: 35s - loss: 0.2630 - accuracy: 0.892 - ETA: 35s - loss: 0.2626 - accuracy: 0.892 - ETA: 35s - loss: 0.2622 - accuracy: 0.893 - ETA: 35s - loss: 0.2624 - accuracy: 0.892 - ETA: 35s - loss: 0.2619 - accuracy: 0.893 - ETA: 35s - loss: 0.2615 - accuracy: 0.893 - ETA: 35s - loss: 0.2609 - accuracy: 0.893 - ETA: 35s - loss: 0.2611 - accuracy: 0.893 - ETA: 34s - loss: 0.2608 - accuracy: 0.893 - ETA: 34s - loss: 0.2603 - accuracy: 0.893 - ETA: 34s - loss: 0.2600 - accuracy: 0.893 - ETA: 34s - loss: 0.2599 - accuracy: 0.894 - ETA: 34s - loss: 0.2601 - accuracy: 0.893 - ETA: 34s - loss: 0.2599 - accuracy: 0.894 - ETA: 34s - loss: 0.2599 - accuracy: 0.894 - ETA: 34s - loss: 0.2595 - accuracy: 0.894 - ETA: 33s - loss: 0.2594 - accuracy: 0.894 - ETA: 33s - loss: 0.2592 - accuracy: 0.894 - ETA: 33s - loss: 0.2589 - accuracy: 0.894 - ETA: 33s - loss: 0.2587 - accuracy: 0.894 - ETA: 33s - loss: 0.2587 - accuracy: 0.894 - ETA: 33s - loss: 0.2585 - accuracy: 0.894 - ETA: 33s - loss: 0.2583 - accuracy: 0.894 - ETA: 33s - loss: 0.2579 - accuracy: 0.895 - ETA: 32s - loss: 0.2578 - accuracy: 0.895 - ETA: 32s - loss: 0.2575 - accuracy: 0.895 - ETA: 32s - loss: 0.2573 - accuracy: 0.895 - ETA: 32s - loss: 0.2573 - accuracy: 0.895 - ETA: 32s - loss: 0.2572 - accuracy: 0.895 - ETA: 32s - loss: 0.2577 - accuracy: 0.895 - ETA: 32s - loss: 0.2577 - accuracy: 0.895 - ETA: 32s - loss: 0.2576 - accuracy: 0.895 - ETA: 31s - loss: 0.2571 - accuracy: 0.896 - ETA: 31s - loss: 0.2569 - accuracy: 0.896 - ETA: 31s - loss: 0.2567 - accuracy: 0.896 - ETA: 31s - loss: 0.2565 - accuracy: 0.896 - ETA: 31s - loss: 0.2568 - accuracy: 0.896 - ETA: 31s - loss: 0.2572 - accuracy: 0.895 - ETA: 31s - loss: 0.2578 - accuracy: 0.895 - ETA: 31s - loss: 0.2579 - accuracy: 0.895 - ETA: 30s - loss: 0.2576 - accuracy: 0.895 - ETA: 30s - loss: 0.2575 - accuracy: 0.896 - ETA: 30s - loss: 0.2571 - accuracy: 0.896 - ETA: 30s - loss: 0.2569 - accuracy: 0.896 - ETA: 30s - loss: 0.2569 - accuracy: 0.896 - ETA: 30s - loss: 0.2567 - accuracy: 0.8962"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/625 [=========================>....] - ETA: 30s - loss: 0.2566 - accuracy: 0.896 - ETA: 30s - loss: 0.2563 - accuracy: 0.896 - ETA: 30s - loss: 0.2562 - accuracy: 0.896 - ETA: 29s - loss: 0.2560 - accuracy: 0.896 - ETA: 29s - loss: 0.2556 - accuracy: 0.896 - ETA: 29s - loss: 0.2551 - accuracy: 0.896 - ETA: 29s - loss: 0.2548 - accuracy: 0.896 - ETA: 29s - loss: 0.2548 - accuracy: 0.896 - ETA: 29s - loss: 0.2553 - accuracy: 0.896 - ETA: 29s - loss: 0.2553 - accuracy: 0.896 - ETA: 29s - loss: 0.2551 - accuracy: 0.896 - ETA: 29s - loss: 0.2549 - accuracy: 0.896 - ETA: 28s - loss: 0.2547 - accuracy: 0.896 - ETA: 28s - loss: 0.2546 - accuracy: 0.896 - ETA: 28s - loss: 0.2547 - accuracy: 0.896 - ETA: 28s - loss: 0.2544 - accuracy: 0.897 - ETA: 28s - loss: 0.2545 - accuracy: 0.897 - ETA: 28s - loss: 0.2545 - accuracy: 0.896 - ETA: 28s - loss: 0.2547 - accuracy: 0.896 - ETA: 28s - loss: 0.2543 - accuracy: 0.896 - ETA: 27s - loss: 0.2540 - accuracy: 0.896 - ETA: 27s - loss: 0.2541 - accuracy: 0.896 - ETA: 27s - loss: 0.2537 - accuracy: 0.897 - ETA: 27s - loss: 0.2535 - accuracy: 0.897 - ETA: 27s - loss: 0.2540 - accuracy: 0.897 - ETA: 27s - loss: 0.2541 - accuracy: 0.896 - ETA: 27s - loss: 0.2540 - accuracy: 0.896 - ETA: 27s - loss: 0.2537 - accuracy: 0.897 - ETA: 26s - loss: 0.2538 - accuracy: 0.896 - ETA: 26s - loss: 0.2535 - accuracy: 0.897 - ETA: 26s - loss: 0.2536 - accuracy: 0.896 - ETA: 26s - loss: 0.2534 - accuracy: 0.897 - ETA: 26s - loss: 0.2533 - accuracy: 0.897 - ETA: 26s - loss: 0.2532 - accuracy: 0.897 - ETA: 26s - loss: 0.2529 - accuracy: 0.897 - ETA: 26s - loss: 0.2528 - accuracy: 0.897 - ETA: 25s - loss: 0.2526 - accuracy: 0.897 - ETA: 25s - loss: 0.2524 - accuracy: 0.897 - ETA: 25s - loss: 0.2520 - accuracy: 0.897 - ETA: 25s - loss: 0.2519 - accuracy: 0.897 - ETA: 25s - loss: 0.2519 - accuracy: 0.897 - ETA: 25s - loss: 0.2515 - accuracy: 0.898 - ETA: 25s - loss: 0.2515 - accuracy: 0.898 - ETA: 25s - loss: 0.2511 - accuracy: 0.898 - ETA: 24s - loss: 0.2508 - accuracy: 0.898 - ETA: 24s - loss: 0.2507 - accuracy: 0.898 - ETA: 24s - loss: 0.2509 - accuracy: 0.898 - ETA: 24s - loss: 0.2507 - accuracy: 0.898 - ETA: 24s - loss: 0.2504 - accuracy: 0.898 - ETA: 24s - loss: 0.2502 - accuracy: 0.898 - ETA: 24s - loss: 0.2498 - accuracy: 0.898 - ETA: 24s - loss: 0.2494 - accuracy: 0.898 - ETA: 23s - loss: 0.2495 - accuracy: 0.898 - ETA: 23s - loss: 0.2494 - accuracy: 0.898 - ETA: 23s - loss: 0.2497 - accuracy: 0.898 - ETA: 23s - loss: 0.2496 - accuracy: 0.898 - ETA: 23s - loss: 0.2495 - accuracy: 0.898 - ETA: 23s - loss: 0.2494 - accuracy: 0.898 - ETA: 23s - loss: 0.2490 - accuracy: 0.899 - ETA: 23s - loss: 0.2488 - accuracy: 0.899 - ETA: 22s - loss: 0.2490 - accuracy: 0.899 - ETA: 22s - loss: 0.2488 - accuracy: 0.899 - ETA: 22s - loss: 0.2488 - accuracy: 0.899 - ETA: 22s - loss: 0.2485 - accuracy: 0.899 - ETA: 22s - loss: 0.2486 - accuracy: 0.899 - ETA: 22s - loss: 0.2487 - accuracy: 0.899 - ETA: 22s - loss: 0.2487 - accuracy: 0.899 - ETA: 22s - loss: 0.2489 - accuracy: 0.899 - ETA: 22s - loss: 0.2487 - accuracy: 0.899 - ETA: 21s - loss: 0.2486 - accuracy: 0.899 - ETA: 21s - loss: 0.2489 - accuracy: 0.899 - ETA: 21s - loss: 0.2487 - accuracy: 0.899 - ETA: 21s - loss: 0.2489 - accuracy: 0.899 - ETA: 21s - loss: 0.2488 - accuracy: 0.899 - ETA: 21s - loss: 0.2486 - accuracy: 0.899 - ETA: 21s - loss: 0.2482 - accuracy: 0.899 - ETA: 21s - loss: 0.2481 - accuracy: 0.899 - ETA: 21s - loss: 0.2480 - accuracy: 0.899 - ETA: 20s - loss: 0.2480 - accuracy: 0.899 - ETA: 20s - loss: 0.2477 - accuracy: 0.899 - ETA: 20s - loss: 0.2475 - accuracy: 0.899 - ETA: 20s - loss: 0.2473 - accuracy: 0.899 - ETA: 20s - loss: 0.2472 - accuracy: 0.899 - ETA: 20s - loss: 0.2468 - accuracy: 0.899 - ETA: 20s - loss: 0.2466 - accuracy: 0.900 - ETA: 20s - loss: 0.2466 - accuracy: 0.900 - ETA: 19s - loss: 0.2464 - accuracy: 0.900 - ETA: 19s - loss: 0.2460 - accuracy: 0.900 - ETA: 19s - loss: 0.2457 - accuracy: 0.900 - ETA: 19s - loss: 0.2454 - accuracy: 0.900 - ETA: 19s - loss: 0.2453 - accuracy: 0.900 - ETA: 19s - loss: 0.2455 - accuracy: 0.900 - ETA: 19s - loss: 0.2452 - accuracy: 0.900 - ETA: 19s - loss: 0.2449 - accuracy: 0.900 - ETA: 18s - loss: 0.2448 - accuracy: 0.900 - ETA: 18s - loss: 0.2444 - accuracy: 0.901 - ETA: 18s - loss: 0.2441 - accuracy: 0.901 - ETA: 18s - loss: 0.2442 - accuracy: 0.901 - ETA: 18s - loss: 0.2441 - accuracy: 0.901 - ETA: 18s - loss: 0.2442 - accuracy: 0.900 - ETA: 18s - loss: 0.2439 - accuracy: 0.901 - ETA: 18s - loss: 0.2443 - accuracy: 0.900 - ETA: 18s - loss: 0.2439 - accuracy: 0.901 - ETA: 17s - loss: 0.2435 - accuracy: 0.901 - ETA: 17s - loss: 0.2435 - accuracy: 0.901 - ETA: 17s - loss: 0.2438 - accuracy: 0.901 - ETA: 17s - loss: 0.2436 - accuracy: 0.901 - ETA: 17s - loss: 0.2434 - accuracy: 0.901 - ETA: 17s - loss: 0.2432 - accuracy: 0.901 - ETA: 17s - loss: 0.2431 - accuracy: 0.901 - ETA: 17s - loss: 0.2430 - accuracy: 0.901 - ETA: 17s - loss: 0.2427 - accuracy: 0.901 - ETA: 16s - loss: 0.2424 - accuracy: 0.901 - ETA: 16s - loss: 0.2421 - accuracy: 0.901 - ETA: 16s - loss: 0.2420 - accuracy: 0.901 - ETA: 16s - loss: 0.2418 - accuracy: 0.902 - ETA: 16s - loss: 0.2418 - accuracy: 0.902 - ETA: 16s - loss: 0.2416 - accuracy: 0.902 - ETA: 16s - loss: 0.2413 - accuracy: 0.902 - ETA: 16s - loss: 0.2416 - accuracy: 0.902 - ETA: 15s - loss: 0.2413 - accuracy: 0.902 - ETA: 15s - loss: 0.2413 - accuracy: 0.902 - ETA: 15s - loss: 0.2410 - accuracy: 0.902 - ETA: 15s - loss: 0.2413 - accuracy: 0.902 - ETA: 15s - loss: 0.2409 - accuracy: 0.902 - ETA: 15s - loss: 0.2414 - accuracy: 0.902 - ETA: 15s - loss: 0.2413 - accuracy: 0.902 - ETA: 15s - loss: 0.2414 - accuracy: 0.902 - ETA: 15s - loss: 0.2414 - accuracy: 0.902 - ETA: 14s - loss: 0.2414 - accuracy: 0.902 - ETA: 14s - loss: 0.2411 - accuracy: 0.902 - ETA: 14s - loss: 0.2408 - accuracy: 0.902 - ETA: 14s - loss: 0.2406 - accuracy: 0.902 - ETA: 14s - loss: 0.2406 - accuracy: 0.902 - ETA: 14s - loss: 0.2409 - accuracy: 0.902 - ETA: 14s - loss: 0.2409 - accuracy: 0.902 - ETA: 14s - loss: 0.2407 - accuracy: 0.902 - ETA: 13s - loss: 0.2405 - accuracy: 0.902 - ETA: 13s - loss: 0.2406 - accuracy: 0.902 - ETA: 13s - loss: 0.2403 - accuracy: 0.902 - ETA: 13s - loss: 0.2402 - accuracy: 0.902 - ETA: 13s - loss: 0.2403 - accuracy: 0.902 - ETA: 13s - loss: 0.2400 - accuracy: 0.902 - ETA: 13s - loss: 0.2400 - accuracy: 0.902 - ETA: 13s - loss: 0.2398 - accuracy: 0.902 - ETA: 12s - loss: 0.2399 - accuracy: 0.903 - ETA: 12s - loss: 0.2397 - accuracy: 0.903 - ETA: 12s - loss: 0.2394 - accuracy: 0.903 - ETA: 12s - loss: 0.2393 - accuracy: 0.903 - ETA: 12s - loss: 0.2390 - accuracy: 0.903 - ETA: 12s - loss: 0.2388 - accuracy: 0.903 - ETA: 12s - loss: 0.2388 - accuracy: 0.903 - ETA: 12s - loss: 0.2387 - accuracy: 0.903 - ETA: 11s - loss: 0.2383 - accuracy: 0.903 - ETA: 11s - loss: 0.2382 - accuracy: 0.903 - ETA: 11s - loss: 0.2381 - accuracy: 0.903 - ETA: 11s - loss: 0.2382 - accuracy: 0.903 - ETA: 11s - loss: 0.2381 - accuracy: 0.903 - ETA: 11s - loss: 0.2379 - accuracy: 0.903 - ETA: 11s - loss: 0.2378 - accuracy: 0.903 - ETA: 11s - loss: 0.2376 - accuracy: 0.904 - ETA: 11s - loss: 0.2373 - accuracy: 0.904 - ETA: 10s - loss: 0.2369 - accuracy: 0.904 - ETA: 10s - loss: 0.2366 - accuracy: 0.904 - ETA: 10s - loss: 0.2365 - accuracy: 0.904 - ETA: 10s - loss: 0.2367 - accuracy: 0.904 - ETA: 10s - loss: 0.2363 - accuracy: 0.904 - ETA: 10s - loss: 0.2360 - accuracy: 0.904 - ETA: 10s - loss: 0.2367 - accuracy: 0.904 - ETA: 10s - loss: 0.2369 - accuracy: 0.904 - ETA: 9s - loss: 0.2369 - accuracy: 0.904 - ETA: 9s - loss: 0.2368 - accuracy: 0.90 - ETA: 9s - loss: 0.2372 - accuracy: 0.90 - ETA: 9s - loss: 0.2369 - accuracy: 0.90 - ETA: 9s - loss: 0.2366 - accuracy: 0.90 - ETA: 9s - loss: 0.2367 - accuracy: 0.90 - ETA: 9s - loss: 0.2366 - accuracy: 0.90 - ETA: 9s - loss: 0.2363 - accuracy: 0.90 - ETA: 8s - loss: 0.2362 - accuracy: 0.90 - ETA: 8s - loss: 0.2362 - accuracy: 0.90 - ETA: 8s - loss: 0.2363 - accuracy: 0.90 - ETA: 8s - loss: 0.2359 - accuracy: 0.90 - ETA: 8s - loss: 0.2357 - accuracy: 0.90 - ETA: 8s - loss: 0.2354 - accuracy: 0.90 - ETA: 8s - loss: 0.2352 - accuracy: 0.90 - ETA: 8s - loss: 0.2349 - accuracy: 0.9055"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 8s - loss: 0.2346 - accuracy: 0.90 - ETA: 7s - loss: 0.2343 - accuracy: 0.90 - ETA: 7s - loss: 0.2341 - accuracy: 0.90 - ETA: 7s - loss: 0.2340 - accuracy: 0.90 - ETA: 7s - loss: 0.2339 - accuracy: 0.90 - ETA: 7s - loss: 0.2339 - accuracy: 0.90 - ETA: 7s - loss: 0.2337 - accuracy: 0.90 - ETA: 7s - loss: 0.2334 - accuracy: 0.90 - ETA: 7s - loss: 0.2333 - accuracy: 0.90 - ETA: 6s - loss: 0.2330 - accuracy: 0.90 - ETA: 6s - loss: 0.2330 - accuracy: 0.90 - ETA: 6s - loss: 0.2327 - accuracy: 0.90 - ETA: 6s - loss: 0.2326 - accuracy: 0.90 - ETA: 6s - loss: 0.2326 - accuracy: 0.90 - ETA: 6s - loss: 0.2325 - accuracy: 0.90 - ETA: 6s - loss: 0.2322 - accuracy: 0.90 - ETA: 6s - loss: 0.2320 - accuracy: 0.90 - ETA: 5s - loss: 0.2318 - accuracy: 0.90 - ETA: 5s - loss: 0.2317 - accuracy: 0.90 - ETA: 5s - loss: 0.2316 - accuracy: 0.90 - ETA: 5s - loss: 0.2314 - accuracy: 0.90 - ETA: 5s - loss: 0.2311 - accuracy: 0.90 - ETA: 5s - loss: 0.2310 - accuracy: 0.90 - ETA: 5s - loss: 0.2310 - accuracy: 0.90 - ETA: 5s - loss: 0.2311 - accuracy: 0.90 - ETA: 4s - loss: 0.2309 - accuracy: 0.90 - ETA: 4s - loss: 0.2307 - accuracy: 0.90 - ETA: 4s - loss: 0.2307 - accuracy: 0.90 - ETA: 4s - loss: 0.2305 - accuracy: 0.90 - ETA: 4s - loss: 0.2303 - accuracy: 0.90 - ETA: 4s - loss: 0.2303 - accuracy: 0.90 - ETA: 4s - loss: 0.2305 - accuracy: 0.90 - ETA: 4s - loss: 0.2305 - accuracy: 0.90 - ETA: 4s - loss: 0.2306 - accuracy: 0.90 - ETA: 3s - loss: 0.2306 - accuracy: 0.90 - ETA: 3s - loss: 0.2305 - accuracy: 0.90 - ETA: 3s - loss: 0.2305 - accuracy: 0.90 - ETA: 3s - loss: 0.2304 - accuracy: 0.90 - ETA: 3s - loss: 0.2302 - accuracy: 0.90 - ETA: 3s - loss: 0.2302 - accuracy: 0.90 - ETA: 3s - loss: 0.2301 - accuracy: 0.90 - ETA: 3s - loss: 0.2299 - accuracy: 0.90 - ETA: 2s - loss: 0.2300 - accuracy: 0.90 - ETA: 2s - loss: 0.2298 - accuracy: 0.90 - ETA: 2s - loss: 0.2295 - accuracy: 0.90 - ETA: 2s - loss: 0.2292 - accuracy: 0.90 - ETA: 2s - loss: 0.2290 - accuracy: 0.90 - ETA: 2s - loss: 0.2288 - accuracy: 0.90 - ETA: 2s - loss: 0.2289 - accuracy: 0.90 - ETA: 2s - loss: 0.2286 - accuracy: 0.90 - ETA: 1s - loss: 0.2284 - accuracy: 0.90 - ETA: 1s - loss: 0.2283 - accuracy: 0.90 - ETA: 1s - loss: 0.2281 - accuracy: 0.90 - ETA: 1s - loss: 0.2279 - accuracy: 0.90 - ETA: 1s - loss: 0.2277 - accuracy: 0.90 - ETA: 1s - loss: 0.2276 - accuracy: 0.90 - ETA: 1s - loss: 0.2275 - accuracy: 0.90 - ETA: 1s - loss: 0.2274 - accuracy: 0.90 - ETA: 0s - loss: 0.2274 - accuracy: 0.90 - ETA: 0s - loss: 0.2275 - accuracy: 0.90 - ETA: 0s - loss: 0.2272 - accuracy: 0.90 - ETA: 0s - loss: 0.2270 - accuracy: 0.90 - ETA: 0s - loss: 0.2268 - accuracy: 0.90 - ETA: 0s - loss: 0.2268 - accuracy: 0.90 - ETA: 0s - loss: 0.2268 - accuracy: 0.90 - ETA: 0s - loss: 0.2267 - accuracy: 0.90 - 81s 130ms/step - loss: 0.2264 - accuracy: 0.9094 - val_loss: 0.2716 - val_accuracy: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 5f34af2a30399bda1c2a69bfd0f2a09e</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.271592194368695</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/filters_0_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/kernel_size: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/max_pooling: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/num_blocks: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/separable: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/dense_block_1/units_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/embedding_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/embedding_1/embedding_dim: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/embedding_1/pretraining: none</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/spatial_reduction_1/reduction_type: global_max</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/text_to_int_sequence_1/output_sequence_length: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/vectorizer: sequence</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Train for 782 steps, validate for 157 steps\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/782 [======>.......................] - ETA: 7:20 - loss: 0.7044 - accuracy: 0.50 - ETA: 4:26 - loss: 0.7005 - accuracy: 0.48 - ETA: 3:29 - loss: 0.6965 - accuracy: 0.50 - ETA: 3:00 - loss: 0.6934 - accuracy: 0.51 - ETA: 2:43 - loss: 0.6880 - accuracy: 0.53 - ETA: 2:31 - loss: 0.6883 - accuracy: 0.53 - ETA: 2:24 - loss: 0.6915 - accuracy: 0.53 - ETA: 2:18 - loss: 0.7011 - accuracy: 0.51 - ETA: 2:13 - loss: 0.7060 - accuracy: 0.49 - ETA: 2:09 - loss: 0.7037 - accuracy: 0.50 - ETA: 2:06 - loss: 0.7077 - accuracy: 0.48 - ETA: 2:03 - loss: 0.7055 - accuracy: 0.49 - ETA: 2:01 - loss: 0.7043 - accuracy: 0.49 - ETA: 1:59 - loss: 0.7038 - accuracy: 0.49 - ETA: 1:57 - loss: 0.7035 - accuracy: 0.49 - ETA: 1:55 - loss: 0.7028 - accuracy: 0.49 - ETA: 1:53 - loss: 0.7024 - accuracy: 0.49 - ETA: 1:52 - loss: 0.7017 - accuracy: 0.50 - ETA: 1:51 - loss: 0.7007 - accuracy: 0.50 - ETA: 1:50 - loss: 0.7003 - accuracy: 0.50 - ETA: 1:49 - loss: 0.6997 - accuracy: 0.50 - ETA: 1:48 - loss: 0.6992 - accuracy: 0.50 - ETA: 1:47 - loss: 0.6991 - accuracy: 0.50 - ETA: 1:46 - loss: 0.7004 - accuracy: 0.49 - ETA: 1:45 - loss: 0.7000 - accuracy: 0.50 - ETA: 1:45 - loss: 0.7000 - accuracy: 0.50 - ETA: 1:44 - loss: 0.7000 - accuracy: 0.49 - ETA: 1:43 - loss: 0.6995 - accuracy: 0.49 - ETA: 1:43 - loss: 0.7002 - accuracy: 0.49 - ETA: 1:42 - loss: 0.6998 - accuracy: 0.49 - ETA: 1:42 - loss: 0.6996 - accuracy: 0.50 - ETA: 1:41 - loss: 0.6998 - accuracy: 0.49 - ETA: 1:41 - loss: 0.6995 - accuracy: 0.49 - ETA: 1:40 - loss: 0.6993 - accuracy: 0.49 - ETA: 1:40 - loss: 0.6990 - accuracy: 0.50 - ETA: 1:39 - loss: 0.6988 - accuracy: 0.50 - ETA: 1:39 - loss: 0.6986 - accuracy: 0.50 - ETA: 1:39 - loss: 0.6982 - accuracy: 0.50 - ETA: 1:39 - loss: 0.6976 - accuracy: 0.51 - ETA: 1:38 - loss: 0.6976 - accuracy: 0.50 - ETA: 1:38 - loss: 0.6975 - accuracy: 0.50 - ETA: 1:38 - loss: 0.6973 - accuracy: 0.50 - ETA: 1:37 - loss: 0.6978 - accuracy: 0.50 - ETA: 1:37 - loss: 0.6976 - accuracy: 0.50 - ETA: 1:37 - loss: 0.6979 - accuracy: 0.50 - ETA: 1:37 - loss: 0.6982 - accuracy: 0.50 - ETA: 1:36 - loss: 0.6982 - accuracy: 0.49 - ETA: 1:36 - loss: 0.6983 - accuracy: 0.49 - ETA: 1:36 - loss: 0.6979 - accuracy: 0.50 - ETA: 1:36 - loss: 0.6978 - accuracy: 0.50 - ETA: 1:35 - loss: 0.6975 - accuracy: 0.50 - ETA: 1:35 - loss: 0.6976 - accuracy: 0.50 - ETA: 1:35 - loss: 0.6974 - accuracy: 0.50 - ETA: 1:35 - loss: 0.6975 - accuracy: 0.50 - ETA: 1:35 - loss: 0.6973 - accuracy: 0.50 - ETA: 1:34 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:34 - loss: 0.6972 - accuracy: 0.50 - ETA: 1:34 - loss: 0.6979 - accuracy: 0.50 - ETA: 1:34 - loss: 0.6984 - accuracy: 0.50 - ETA: 1:33 - loss: 0.6980 - accuracy: 0.50 - ETA: 1:33 - loss: 0.6975 - accuracy: 0.50 - ETA: 1:33 - loss: 0.6974 - accuracy: 0.50 - ETA: 1:33 - loss: 0.6978 - accuracy: 0.50 - ETA: 1:33 - loss: 0.6976 - accuracy: 0.50 - ETA: 1:32 - loss: 0.6978 - accuracy: 0.50 - ETA: 1:32 - loss: 0.6974 - accuracy: 0.50 - ETA: 1:32 - loss: 0.6973 - accuracy: 0.50 - ETA: 1:32 - loss: 0.6970 - accuracy: 0.50 - ETA: 1:31 - loss: 0.6968 - accuracy: 0.51 - ETA: 1:31 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:31 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:31 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:31 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:31 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:31 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:30 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:30 - loss: 0.6973 - accuracy: 0.50 - ETA: 1:30 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:30 - loss: 0.6972 - accuracy: 0.50 - ETA: 1:30 - loss: 0.6972 - accuracy: 0.50 - ETA: 1:30 - loss: 0.6971 - accuracy: 0.50 - ETA: 1:30 - loss: 0.6971 - accuracy: 0.50 - ETA: 1:29 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:29 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:29 - loss: 0.6969 - accuracy: 0.50 - ETA: 1:29 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:29 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:29 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:28 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:28 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:28 - loss: 0.6968 - accuracy: 0.50 - ETA: 1:28 - loss: 0.6967 - accuracy: 0.50 - ETA: 1:28 - loss: 0.6965 - accuracy: 0.50 - ETA: 1:28 - loss: 0.6965 - accuracy: 0.50 - ETA: 1:27 - loss: 0.6965 - accuracy: 0.50 - ETA: 1:27 - loss: 0.6965 - accuracy: 0.50 - ETA: 1:27 - loss: 0.6964 - accuracy: 0.50 - ETA: 1:27 - loss: 0.6964 - accuracy: 0.50 - ETA: 1:27 - loss: 0.6964 - accuracy: 0.50 - ETA: 1:27 - loss: 0.6963 - accuracy: 0.51 - ETA: 1:26 - loss: 0.6962 - accuracy: 0.51 - ETA: 1:26 - loss: 0.6962 - accuracy: 0.51 - ETA: 1:26 - loss: 0.6962 - accuracy: 0.51 - ETA: 1:26 - loss: 0.6962 - accuracy: 0.51 - ETA: 1:26 - loss: 0.6962 - accuracy: 0.51 - ETA: 1:26 - loss: 0.6961 - accuracy: 0.51 - ETA: 1:25 - loss: 0.6962 - accuracy: 0.51 - ETA: 1:25 - loss: 0.6961 - accuracy: 0.51 - ETA: 1:25 - loss: 0.6962 - accuracy: 0.51 - ETA: 1:25 - loss: 0.6962 - accuracy: 0.51 - ETA: 1:25 - loss: 0.6961 - accuracy: 0.51 - ETA: 1:25 - loss: 0.6960 - accuracy: 0.51 - ETA: 1:24 - loss: 0.6958 - accuracy: 0.51 - ETA: 1:24 - loss: 0.6959 - accuracy: 0.51 - ETA: 1:24 - loss: 0.6959 - accuracy: 0.51 - ETA: 1:24 - loss: 0.6958 - accuracy: 0.51 - ETA: 1:24 - loss: 0.6957 - accuracy: 0.51 - ETA: 1:24 - loss: 0.6955 - accuracy: 0.51 - ETA: 1:23 - loss: 0.6955 - accuracy: 0.51 - ETA: 1:23 - loss: 0.6957 - accuracy: 0.51 - ETA: 1:23 - loss: 0.6956 - accuracy: 0.51 - ETA: 1:23 - loss: 0.6955 - accuracy: 0.51 - ETA: 1:23 - loss: 0.6954 - accuracy: 0.51 - ETA: 1:23 - loss: 0.6954 - accuracy: 0.51 - ETA: 1:23 - loss: 0.6954 - accuracy: 0.51 - ETA: 1:22 - loss: 0.6953 - accuracy: 0.51 - ETA: 1:22 - loss: 0.6952 - accuracy: 0.51 - ETA: 1:22 - loss: 0.6951 - accuracy: 0.51 - ETA: 1:22 - loss: 0.6951 - accuracy: 0.51 - ETA: 1:22 - loss: 0.6950 - accuracy: 0.51 - ETA: 1:22 - loss: 0.6950 - accuracy: 0.51 - ETA: 1:22 - loss: 0.6948 - accuracy: 0.51 - ETA: 1:22 - loss: 0.6948 - accuracy: 0.51 - ETA: 1:21 - loss: 0.6947 - accuracy: 0.51 - ETA: 1:21 - loss: 0.6946 - accuracy: 0.51 - ETA: 1:21 - loss: 0.6945 - accuracy: 0.51 - ETA: 1:21 - loss: 0.6944 - accuracy: 0.51 - ETA: 1:21 - loss: 0.6943 - accuracy: 0.51 - ETA: 1:21 - loss: 0.6942 - accuracy: 0.51 - ETA: 1:21 - loss: 0.6941 - accuracy: 0.51 - ETA: 1:20 - loss: 0.6939 - accuracy: 0.51 - ETA: 1:20 - loss: 0.6938 - accuracy: 0.52 - ETA: 1:20 - loss: 0.6936 - accuracy: 0.52 - ETA: 1:20 - loss: 0.6934 - accuracy: 0.52 - ETA: 1:20 - loss: 0.6934 - accuracy: 0.52 - ETA: 1:20 - loss: 0.6933 - accuracy: 0.52 - ETA: 1:20 - loss: 0.6931 - accuracy: 0.52 - ETA: 1:20 - loss: 0.6930 - accuracy: 0.52 - ETA: 1:20 - loss: 0.6927 - accuracy: 0.52 - ETA: 1:19 - loss: 0.6925 - accuracy: 0.52 - ETA: 1:19 - loss: 0.6922 - accuracy: 0.52 - ETA: 1:19 - loss: 0.6919 - accuracy: 0.52 - ETA: 1:19 - loss: 0.6918 - accuracy: 0.52 - ETA: 1:19 - loss: 0.6918 - accuracy: 0.52 - ETA: 1:19 - loss: 0.6916 - accuracy: 0.53 - ETA: 1:19 - loss: 0.6913 - accuracy: 0.53 - ETA: 1:18 - loss: 0.6909 - accuracy: 0.53 - ETA: 1:18 - loss: 0.6905 - accuracy: 0.53 - ETA: 1:18 - loss: 0.6900 - accuracy: 0.53 - ETA: 1:18 - loss: 0.6900 - accuracy: 0.53 - ETA: 1:18 - loss: 0.6894 - accuracy: 0.53 - ETA: 1:18 - loss: 0.6889 - accuracy: 0.53 - ETA: 1:18 - loss: 0.6887 - accuracy: 0.53 - ETA: 1:18 - loss: 0.6882 - accuracy: 0.54 - ETA: 1:17 - loss: 0.6879 - accuracy: 0.54 - ETA: 1:17 - loss: 0.6872 - accuracy: 0.54 - ETA: 1:17 - loss: 0.6871 - accuracy: 0.54 - ETA: 1:17 - loss: 0.6870 - accuracy: 0.54 - ETA: 1:17 - loss: 0.6863 - accuracy: 0.54 - ETA: 1:17 - loss: 0.6859 - accuracy: 0.54 - ETA: 1:17 - loss: 0.6859 - accuracy: 0.54 - ETA: 1:17 - loss: 0.6854 - accuracy: 0.54 - ETA: 1:17 - loss: 0.6844 - accuracy: 0.54 - ETA: 1:16 - loss: 0.6837 - accuracy: 0.54 - ETA: 1:16 - loss: 0.6829 - accuracy: 0.54 - ETA: 1:16 - loss: 0.6829 - accuracy: 0.54 - ETA: 1:16 - loss: 0.6827 - accuracy: 0.55 - ETA: 1:16 - loss: 0.6827 - accuracy: 0.55 - ETA: 1:16 - loss: 0.6823 - accuracy: 0.55 - ETA: 1:16 - loss: 0.6815 - accuracy: 0.55 - ETA: 1:15 - loss: 0.6811 - accuracy: 0.55 - ETA: 1:15 - loss: 0.6803 - accuracy: 0.55 - ETA: 1:15 - loss: 0.6797 - accuracy: 0.55 - ETA: 1:15 - loss: 0.6791 - accuracy: 0.5552\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/782 [=============>................] - ETA: 1:15 - loss: 0.6784 - accuracy: 0.55 - ETA: 1:15 - loss: 0.6775 - accuracy: 0.55 - ETA: 1:15 - loss: 0.6771 - accuracy: 0.55 - ETA: 1:14 - loss: 0.6771 - accuracy: 0.55 - ETA: 1:14 - loss: 0.6764 - accuracy: 0.56 - ETA: 1:14 - loss: 0.6765 - accuracy: 0.56 - ETA: 1:14 - loss: 0.6763 - accuracy: 0.56 - ETA: 1:14 - loss: 0.6768 - accuracy: 0.56 - ETA: 1:14 - loss: 0.6761 - accuracy: 0.56 - ETA: 1:14 - loss: 0.6758 - accuracy: 0.56 - ETA: 1:14 - loss: 0.6757 - accuracy: 0.56 - ETA: 1:13 - loss: 0.6751 - accuracy: 0.56 - ETA: 1:13 - loss: 0.6741 - accuracy: 0.56 - ETA: 1:13 - loss: 0.6735 - accuracy: 0.56 - ETA: 1:13 - loss: 0.6728 - accuracy: 0.56 - ETA: 1:13 - loss: 0.6722 - accuracy: 0.56 - ETA: 1:13 - loss: 0.6715 - accuracy: 0.56 - ETA: 1:13 - loss: 0.6703 - accuracy: 0.56 - ETA: 1:12 - loss: 0.6696 - accuracy: 0.56 - ETA: 1:12 - loss: 0.6686 - accuracy: 0.57 - ETA: 1:12 - loss: 0.6682 - accuracy: 0.57 - ETA: 1:12 - loss: 0.6676 - accuracy: 0.57 - ETA: 1:12 - loss: 0.6664 - accuracy: 0.57 - ETA: 1:12 - loss: 0.6653 - accuracy: 0.57 - ETA: 1:12 - loss: 0.6648 - accuracy: 0.57 - ETA: 1:12 - loss: 0.6646 - accuracy: 0.57 - ETA: 1:11 - loss: 0.6634 - accuracy: 0.57 - ETA: 1:11 - loss: 0.6626 - accuracy: 0.57 - ETA: 1:11 - loss: 0.6611 - accuracy: 0.57 - ETA: 1:11 - loss: 0.6603 - accuracy: 0.58 - ETA: 1:11 - loss: 0.6596 - accuracy: 0.58 - ETA: 1:11 - loss: 0.6587 - accuracy: 0.58 - ETA: 1:11 - loss: 0.6577 - accuracy: 0.58 - ETA: 1:10 - loss: 0.6568 - accuracy: 0.58 - ETA: 1:10 - loss: 0.6558 - accuracy: 0.58 - ETA: 1:10 - loss: 0.6556 - accuracy: 0.58 - ETA: 1:10 - loss: 0.6556 - accuracy: 0.58 - ETA: 1:10 - loss: 0.6545 - accuracy: 0.58 - ETA: 1:10 - loss: 0.6539 - accuracy: 0.58 - ETA: 1:10 - loss: 0.6528 - accuracy: 0.58 - ETA: 1:10 - loss: 0.6524 - accuracy: 0.58 - ETA: 1:09 - loss: 0.6513 - accuracy: 0.59 - ETA: 1:09 - loss: 0.6502 - accuracy: 0.59 - ETA: 1:09 - loss: 0.6498 - accuracy: 0.59 - ETA: 1:09 - loss: 0.6485 - accuracy: 0.59 - ETA: 1:09 - loss: 0.6480 - accuracy: 0.59 - ETA: 1:09 - loss: 0.6473 - accuracy: 0.59 - ETA: 1:09 - loss: 0.6468 - accuracy: 0.59 - ETA: 1:09 - loss: 0.6456 - accuracy: 0.59 - ETA: 1:08 - loss: 0.6449 - accuracy: 0.59 - ETA: 1:08 - loss: 0.6437 - accuracy: 0.59 - ETA: 1:08 - loss: 0.6426 - accuracy: 0.59 - ETA: 1:08 - loss: 0.6419 - accuracy: 0.59 - ETA: 1:08 - loss: 0.6415 - accuracy: 0.60 - ETA: 1:08 - loss: 0.6407 - accuracy: 0.60 - ETA: 1:08 - loss: 0.6403 - accuracy: 0.60 - ETA: 1:07 - loss: 0.6397 - accuracy: 0.60 - ETA: 1:07 - loss: 0.6395 - accuracy: 0.60 - ETA: 1:07 - loss: 0.6386 - accuracy: 0.60 - ETA: 1:07 - loss: 0.6374 - accuracy: 0.60 - ETA: 1:07 - loss: 0.6362 - accuracy: 0.60 - ETA: 1:07 - loss: 0.6358 - accuracy: 0.60 - ETA: 1:07 - loss: 0.6348 - accuracy: 0.60 - ETA: 1:07 - loss: 0.6344 - accuracy: 0.60 - ETA: 1:06 - loss: 0.6331 - accuracy: 0.60 - ETA: 1:06 - loss: 0.6318 - accuracy: 0.61 - ETA: 1:06 - loss: 0.6308 - accuracy: 0.61 - ETA: 1:06 - loss: 0.6298 - accuracy: 0.61 - ETA: 1:06 - loss: 0.6292 - accuracy: 0.61 - ETA: 1:06 - loss: 0.6283 - accuracy: 0.61 - ETA: 1:06 - loss: 0.6279 - accuracy: 0.61 - ETA: 1:06 - loss: 0.6272 - accuracy: 0.61 - ETA: 1:06 - loss: 0.6267 - accuracy: 0.61 - ETA: 1:05 - loss: 0.6260 - accuracy: 0.61 - ETA: 1:05 - loss: 0.6252 - accuracy: 0.61 - ETA: 1:05 - loss: 0.6244 - accuracy: 0.61 - ETA: 1:05 - loss: 0.6232 - accuracy: 0.61 - ETA: 1:05 - loss: 0.6226 - accuracy: 0.61 - ETA: 1:05 - loss: 0.6224 - accuracy: 0.61 - ETA: 1:05 - loss: 0.6215 - accuracy: 0.62 - ETA: 1:05 - loss: 0.6205 - accuracy: 0.62 - ETA: 1:04 - loss: 0.6201 - accuracy: 0.62 - ETA: 1:04 - loss: 0.6190 - accuracy: 0.62 - ETA: 1:04 - loss: 0.6179 - accuracy: 0.62 - ETA: 1:04 - loss: 0.6170 - accuracy: 0.62 - ETA: 1:04 - loss: 0.6163 - accuracy: 0.62 - ETA: 1:04 - loss: 0.6154 - accuracy: 0.62 - ETA: 1:04 - loss: 0.6149 - accuracy: 0.62 - ETA: 1:04 - loss: 0.6140 - accuracy: 0.62 - ETA: 1:03 - loss: 0.6129 - accuracy: 0.62 - ETA: 1:03 - loss: 0.6124 - accuracy: 0.62 - ETA: 1:03 - loss: 0.6125 - accuracy: 0.62 - ETA: 1:03 - loss: 0.6118 - accuracy: 0.62 - ETA: 1:03 - loss: 0.6115 - accuracy: 0.63 - ETA: 1:03 - loss: 0.6108 - accuracy: 0.63 - ETA: 1:03 - loss: 0.6097 - accuracy: 0.63 - ETA: 1:02 - loss: 0.6085 - accuracy: 0.63 - ETA: 1:02 - loss: 0.6079 - accuracy: 0.63 - ETA: 1:02 - loss: 0.6069 - accuracy: 0.63 - ETA: 1:02 - loss: 0.6056 - accuracy: 0.63 - ETA: 1:02 - loss: 0.6049 - accuracy: 0.63 - ETA: 1:02 - loss: 0.6043 - accuracy: 0.63 - ETA: 1:02 - loss: 0.6042 - accuracy: 0.63 - ETA: 1:02 - loss: 0.6034 - accuracy: 0.63 - ETA: 1:01 - loss: 0.6028 - accuracy: 0.63 - ETA: 1:01 - loss: 0.6021 - accuracy: 0.63 - ETA: 1:01 - loss: 0.6014 - accuracy: 0.63 - ETA: 1:01 - loss: 0.6007 - accuracy: 0.63 - ETA: 1:01 - loss: 0.6003 - accuracy: 0.63 - ETA: 1:01 - loss: 0.5996 - accuracy: 0.64 - ETA: 1:01 - loss: 0.5985 - accuracy: 0.64 - ETA: 1:01 - loss: 0.5983 - accuracy: 0.64 - ETA: 1:00 - loss: 0.5977 - accuracy: 0.64 - ETA: 1:00 - loss: 0.5973 - accuracy: 0.64 - ETA: 1:00 - loss: 0.5965 - accuracy: 0.64 - ETA: 1:00 - loss: 0.5958 - accuracy: 0.64 - ETA: 1:00 - loss: 0.5954 - accuracy: 0.64 - ETA: 1:00 - loss: 0.5945 - accuracy: 0.64 - ETA: 1:00 - loss: 0.5937 - accuracy: 0.64 - ETA: 59s - loss: 0.5934 - accuracy: 0.6467 - ETA: 59s - loss: 0.5922 - accuracy: 0.647 - ETA: 59s - loss: 0.5916 - accuracy: 0.648 - ETA: 59s - loss: 0.5911 - accuracy: 0.648 - ETA: 59s - loss: 0.5912 - accuracy: 0.648 - ETA: 59s - loss: 0.5909 - accuracy: 0.649 - ETA: 59s - loss: 0.5906 - accuracy: 0.649 - ETA: 59s - loss: 0.5904 - accuracy: 0.650 - ETA: 58s - loss: 0.5896 - accuracy: 0.650 - ETA: 58s - loss: 0.5888 - accuracy: 0.651 - ETA: 58s - loss: 0.5881 - accuracy: 0.652 - ETA: 58s - loss: 0.5879 - accuracy: 0.652 - ETA: 58s - loss: 0.5883 - accuracy: 0.652 - ETA: 58s - loss: 0.5876 - accuracy: 0.653 - ETA: 58s - loss: 0.5870 - accuracy: 0.653 - ETA: 58s - loss: 0.5862 - accuracy: 0.654 - ETA: 57s - loss: 0.5856 - accuracy: 0.654 - ETA: 57s - loss: 0.5850 - accuracy: 0.655 - ETA: 57s - loss: 0.5843 - accuracy: 0.656 - ETA: 57s - loss: 0.5836 - accuracy: 0.656 - ETA: 57s - loss: 0.5834 - accuracy: 0.657 - ETA: 57s - loss: 0.5828 - accuracy: 0.657 - ETA: 57s - loss: 0.5824 - accuracy: 0.658 - ETA: 57s - loss: 0.5818 - accuracy: 0.658 - ETA: 56s - loss: 0.5816 - accuracy: 0.658 - ETA: 56s - loss: 0.5811 - accuracy: 0.659 - ETA: 56s - loss: 0.5807 - accuracy: 0.659 - ETA: 56s - loss: 0.5800 - accuracy: 0.660 - ETA: 56s - loss: 0.5795 - accuracy: 0.660 - ETA: 56s - loss: 0.5785 - accuracy: 0.661 - ETA: 56s - loss: 0.5780 - accuracy: 0.661 - ETA: 56s - loss: 0.5773 - accuracy: 0.662 - ETA: 55s - loss: 0.5764 - accuracy: 0.662 - ETA: 55s - loss: 0.5759 - accuracy: 0.663 - ETA: 55s - loss: 0.5758 - accuracy: 0.663 - ETA: 55s - loss: 0.5750 - accuracy: 0.663 - ETA: 55s - loss: 0.5742 - accuracy: 0.664 - ETA: 55s - loss: 0.5740 - accuracy: 0.665 - ETA: 55s - loss: 0.5735 - accuracy: 0.665 - ETA: 54s - loss: 0.5731 - accuracy: 0.665 - ETA: 54s - loss: 0.5727 - accuracy: 0.665 - ETA: 54s - loss: 0.5723 - accuracy: 0.666 - ETA: 54s - loss: 0.5712 - accuracy: 0.667 - ETA: 54s - loss: 0.5706 - accuracy: 0.667 - ETA: 54s - loss: 0.5698 - accuracy: 0.668 - ETA: 54s - loss: 0.5690 - accuracy: 0.668 - ETA: 54s - loss: 0.5685 - accuracy: 0.669 - ETA: 53s - loss: 0.5681 - accuracy: 0.669 - ETA: 53s - loss: 0.5677 - accuracy: 0.670 - ETA: 53s - loss: 0.5670 - accuracy: 0.670 - ETA: 53s - loss: 0.5667 - accuracy: 0.670 - ETA: 53s - loss: 0.5659 - accuracy: 0.671 - ETA: 53s - loss: 0.5653 - accuracy: 0.672 - ETA: 53s - loss: 0.5650 - accuracy: 0.672 - ETA: 53s - loss: 0.5646 - accuracy: 0.672 - ETA: 52s - loss: 0.5638 - accuracy: 0.673 - ETA: 52s - loss: 0.5633 - accuracy: 0.673 - ETA: 52s - loss: 0.5624 - accuracy: 0.674 - ETA: 52s - loss: 0.5622 - accuracy: 0.674 - ETA: 52s - loss: 0.5617 - accuracy: 0.674 - ETA: 52s - loss: 0.5615 - accuracy: 0.675 - ETA: 52s - loss: 0.5615 - accuracy: 0.675 - ETA: 52s - loss: 0.5615 - accuracy: 0.675 - ETA: 51s - loss: 0.5606 - accuracy: 0.676 - ETA: 51s - loss: 0.5602 - accuracy: 0.676 - ETA: 51s - loss: 0.5597 - accuracy: 0.677 - ETA: 51s - loss: 0.5592 - accuracy: 0.6774"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/782 [====================>.........] - ETA: 51s - loss: 0.5590 - accuracy: 0.677 - ETA: 51s - loss: 0.5584 - accuracy: 0.678 - ETA: 51s - loss: 0.5578 - accuracy: 0.678 - ETA: 51s - loss: 0.5571 - accuracy: 0.678 - ETA: 50s - loss: 0.5569 - accuracy: 0.679 - ETA: 50s - loss: 0.5567 - accuracy: 0.679 - ETA: 50s - loss: 0.5562 - accuracy: 0.680 - ETA: 50s - loss: 0.5554 - accuracy: 0.680 - ETA: 50s - loss: 0.5547 - accuracy: 0.681 - ETA: 50s - loss: 0.5540 - accuracy: 0.682 - ETA: 50s - loss: 0.5541 - accuracy: 0.682 - ETA: 49s - loss: 0.5542 - accuracy: 0.682 - ETA: 49s - loss: 0.5534 - accuracy: 0.682 - ETA: 49s - loss: 0.5534 - accuracy: 0.683 - ETA: 49s - loss: 0.5530 - accuracy: 0.683 - ETA: 49s - loss: 0.5528 - accuracy: 0.683 - ETA: 49s - loss: 0.5528 - accuracy: 0.684 - ETA: 49s - loss: 0.5524 - accuracy: 0.684 - ETA: 49s - loss: 0.5519 - accuracy: 0.684 - ETA: 48s - loss: 0.5516 - accuracy: 0.684 - ETA: 48s - loss: 0.5515 - accuracy: 0.685 - ETA: 48s - loss: 0.5510 - accuracy: 0.685 - ETA: 48s - loss: 0.5506 - accuracy: 0.685 - ETA: 48s - loss: 0.5504 - accuracy: 0.686 - ETA: 48s - loss: 0.5497 - accuracy: 0.686 - ETA: 48s - loss: 0.5494 - accuracy: 0.687 - ETA: 48s - loss: 0.5495 - accuracy: 0.687 - ETA: 48s - loss: 0.5492 - accuracy: 0.687 - ETA: 47s - loss: 0.5490 - accuracy: 0.687 - ETA: 47s - loss: 0.5483 - accuracy: 0.688 - ETA: 47s - loss: 0.5479 - accuracy: 0.688 - ETA: 47s - loss: 0.5472 - accuracy: 0.689 - ETA: 47s - loss: 0.5468 - accuracy: 0.689 - ETA: 47s - loss: 0.5464 - accuracy: 0.689 - ETA: 47s - loss: 0.5461 - accuracy: 0.690 - ETA: 47s - loss: 0.5461 - accuracy: 0.690 - ETA: 46s - loss: 0.5453 - accuracy: 0.690 - ETA: 46s - loss: 0.5448 - accuracy: 0.691 - ETA: 46s - loss: 0.5440 - accuracy: 0.691 - ETA: 46s - loss: 0.5440 - accuracy: 0.692 - ETA: 46s - loss: 0.5432 - accuracy: 0.692 - ETA: 46s - loss: 0.5426 - accuracy: 0.693 - ETA: 46s - loss: 0.5420 - accuracy: 0.693 - ETA: 46s - loss: 0.5414 - accuracy: 0.694 - ETA: 46s - loss: 0.5409 - accuracy: 0.694 - ETA: 45s - loss: 0.5403 - accuracy: 0.694 - ETA: 45s - loss: 0.5398 - accuracy: 0.695 - ETA: 45s - loss: 0.5394 - accuracy: 0.695 - ETA: 45s - loss: 0.5389 - accuracy: 0.696 - ETA: 45s - loss: 0.5384 - accuracy: 0.696 - ETA: 45s - loss: 0.5378 - accuracy: 0.697 - ETA: 45s - loss: 0.5369 - accuracy: 0.697 - ETA: 45s - loss: 0.5361 - accuracy: 0.698 - ETA: 45s - loss: 0.5353 - accuracy: 0.698 - ETA: 45s - loss: 0.5348 - accuracy: 0.698 - ETA: 44s - loss: 0.5345 - accuracy: 0.699 - ETA: 44s - loss: 0.5343 - accuracy: 0.699 - ETA: 44s - loss: 0.5339 - accuracy: 0.699 - ETA: 44s - loss: 0.5337 - accuracy: 0.699 - ETA: 44s - loss: 0.5333 - accuracy: 0.700 - ETA: 44s - loss: 0.5327 - accuracy: 0.700 - ETA: 44s - loss: 0.5323 - accuracy: 0.700 - ETA: 44s - loss: 0.5321 - accuracy: 0.701 - ETA: 43s - loss: 0.5318 - accuracy: 0.701 - ETA: 43s - loss: 0.5316 - accuracy: 0.701 - ETA: 43s - loss: 0.5308 - accuracy: 0.702 - ETA: 43s - loss: 0.5310 - accuracy: 0.701 - ETA: 43s - loss: 0.5306 - accuracy: 0.702 - ETA: 43s - loss: 0.5304 - accuracy: 0.702 - ETA: 43s - loss: 0.5302 - accuracy: 0.702 - ETA: 43s - loss: 0.5299 - accuracy: 0.702 - ETA: 43s - loss: 0.5295 - accuracy: 0.703 - ETA: 43s - loss: 0.5295 - accuracy: 0.703 - ETA: 42s - loss: 0.5292 - accuracy: 0.703 - ETA: 42s - loss: 0.5287 - accuracy: 0.704 - ETA: 42s - loss: 0.5283 - accuracy: 0.704 - ETA: 42s - loss: 0.5277 - accuracy: 0.705 - ETA: 42s - loss: 0.5269 - accuracy: 0.705 - ETA: 42s - loss: 0.5264 - accuracy: 0.706 - ETA: 42s - loss: 0.5260 - accuracy: 0.706 - ETA: 42s - loss: 0.5259 - accuracy: 0.706 - ETA: 41s - loss: 0.5254 - accuracy: 0.706 - ETA: 41s - loss: 0.5250 - accuracy: 0.707 - ETA: 41s - loss: 0.5249 - accuracy: 0.707 - ETA: 41s - loss: 0.5244 - accuracy: 0.707 - ETA: 41s - loss: 0.5237 - accuracy: 0.708 - ETA: 41s - loss: 0.5233 - accuracy: 0.708 - ETA: 41s - loss: 0.5230 - accuracy: 0.708 - ETA: 41s - loss: 0.5225 - accuracy: 0.709 - ETA: 40s - loss: 0.5218 - accuracy: 0.709 - ETA: 40s - loss: 0.5213 - accuracy: 0.710 - ETA: 40s - loss: 0.5206 - accuracy: 0.710 - ETA: 40s - loss: 0.5203 - accuracy: 0.710 - ETA: 40s - loss: 0.5198 - accuracy: 0.711 - ETA: 40s - loss: 0.5193 - accuracy: 0.711 - ETA: 40s - loss: 0.5193 - accuracy: 0.711 - ETA: 40s - loss: 0.5189 - accuracy: 0.711 - ETA: 40s - loss: 0.5185 - accuracy: 0.712 - ETA: 39s - loss: 0.5181 - accuracy: 0.712 - ETA: 39s - loss: 0.5182 - accuracy: 0.712 - ETA: 39s - loss: 0.5179 - accuracy: 0.712 - ETA: 39s - loss: 0.5176 - accuracy: 0.713 - ETA: 39s - loss: 0.5171 - accuracy: 0.713 - ETA: 39s - loss: 0.5169 - accuracy: 0.713 - ETA: 39s - loss: 0.5162 - accuracy: 0.714 - ETA: 39s - loss: 0.5157 - accuracy: 0.714 - ETA: 38s - loss: 0.5155 - accuracy: 0.714 - ETA: 38s - loss: 0.5157 - accuracy: 0.714 - ETA: 38s - loss: 0.5153 - accuracy: 0.715 - ETA: 38s - loss: 0.5147 - accuracy: 0.715 - ETA: 38s - loss: 0.5140 - accuracy: 0.716 - ETA: 38s - loss: 0.5133 - accuracy: 0.716 - ETA: 38s - loss: 0.5128 - accuracy: 0.717 - ETA: 38s - loss: 0.5123 - accuracy: 0.717 - ETA: 38s - loss: 0.5119 - accuracy: 0.717 - ETA: 37s - loss: 0.5114 - accuracy: 0.717 - ETA: 37s - loss: 0.5111 - accuracy: 0.718 - ETA: 37s - loss: 0.5110 - accuracy: 0.718 - ETA: 37s - loss: 0.5103 - accuracy: 0.718 - ETA: 37s - loss: 0.5098 - accuracy: 0.719 - ETA: 37s - loss: 0.5091 - accuracy: 0.719 - ETA: 37s - loss: 0.5090 - accuracy: 0.719 - ETA: 37s - loss: 0.5086 - accuracy: 0.720 - ETA: 36s - loss: 0.5083 - accuracy: 0.720 - ETA: 36s - loss: 0.5079 - accuracy: 0.720 - ETA: 36s - loss: 0.5077 - accuracy: 0.720 - ETA: 36s - loss: 0.5072 - accuracy: 0.721 - ETA: 36s - loss: 0.5069 - accuracy: 0.721 - ETA: 36s - loss: 0.5065 - accuracy: 0.721 - ETA: 36s - loss: 0.5062 - accuracy: 0.722 - ETA: 36s - loss: 0.5059 - accuracy: 0.722 - ETA: 36s - loss: 0.5056 - accuracy: 0.722 - ETA: 36s - loss: 0.5050 - accuracy: 0.723 - ETA: 36s - loss: 0.5043 - accuracy: 0.723 - ETA: 35s - loss: 0.5038 - accuracy: 0.723 - ETA: 35s - loss: 0.5034 - accuracy: 0.724 - ETA: 35s - loss: 0.5030 - accuracy: 0.724 - ETA: 35s - loss: 0.5029 - accuracy: 0.724 - ETA: 35s - loss: 0.5025 - accuracy: 0.725 - ETA: 35s - loss: 0.5020 - accuracy: 0.725 - ETA: 35s - loss: 0.5019 - accuracy: 0.725 - ETA: 35s - loss: 0.5015 - accuracy: 0.726 - ETA: 35s - loss: 0.5012 - accuracy: 0.726 - ETA: 35s - loss: 0.5011 - accuracy: 0.726 - ETA: 34s - loss: 0.5006 - accuracy: 0.726 - ETA: 34s - loss: 0.5004 - accuracy: 0.726 - ETA: 34s - loss: 0.5000 - accuracy: 0.727 - ETA: 34s - loss: 0.4997 - accuracy: 0.727 - ETA: 34s - loss: 0.4992 - accuracy: 0.727 - ETA: 34s - loss: 0.4986 - accuracy: 0.728 - ETA: 34s - loss: 0.4982 - accuracy: 0.728 - ETA: 34s - loss: 0.4976 - accuracy: 0.728 - ETA: 34s - loss: 0.4972 - accuracy: 0.729 - ETA: 33s - loss: 0.4967 - accuracy: 0.729 - ETA: 33s - loss: 0.4966 - accuracy: 0.729 - ETA: 33s - loss: 0.4959 - accuracy: 0.730 - ETA: 33s - loss: 0.4955 - accuracy: 0.730 - ETA: 33s - loss: 0.4949 - accuracy: 0.730 - ETA: 33s - loss: 0.4947 - accuracy: 0.730 - ETA: 33s - loss: 0.4943 - accuracy: 0.731 - ETA: 33s - loss: 0.4939 - accuracy: 0.731 - ETA: 32s - loss: 0.4937 - accuracy: 0.731 - ETA: 32s - loss: 0.4932 - accuracy: 0.731 - ETA: 32s - loss: 0.4929 - accuracy: 0.732 - ETA: 32s - loss: 0.4923 - accuracy: 0.732 - ETA: 32s - loss: 0.4919 - accuracy: 0.732 - ETA: 32s - loss: 0.4916 - accuracy: 0.733 - ETA: 32s - loss: 0.4915 - accuracy: 0.733 - ETA: 32s - loss: 0.4909 - accuracy: 0.733 - ETA: 31s - loss: 0.4902 - accuracy: 0.734 - ETA: 31s - loss: 0.4902 - accuracy: 0.734 - ETA: 31s - loss: 0.4900 - accuracy: 0.734 - ETA: 31s - loss: 0.4895 - accuracy: 0.734 - ETA: 31s - loss: 0.4891 - accuracy: 0.734 - ETA: 31s - loss: 0.4891 - accuracy: 0.735 - ETA: 31s - loss: 0.4887 - accuracy: 0.735 - ETA: 31s - loss: 0.4885 - accuracy: 0.735 - ETA: 31s - loss: 0.4884 - accuracy: 0.735 - ETA: 30s - loss: 0.4880 - accuracy: 0.735 - ETA: 30s - loss: 0.4874 - accuracy: 0.736 - ETA: 30s - loss: 0.4872 - accuracy: 0.736 - ETA: 30s - loss: 0.4867 - accuracy: 0.736 - ETA: 30s - loss: 0.4866 - accuracy: 0.736 - ETA: 30s - loss: 0.4863 - accuracy: 0.737 - ETA: 30s - loss: 0.4860 - accuracy: 0.737 - ETA: 29s - loss: 0.4856 - accuracy: 0.7376"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743/782 [===========================>..] - ETA: 29s - loss: 0.4855 - accuracy: 0.737 - ETA: 29s - loss: 0.4850 - accuracy: 0.738 - ETA: 29s - loss: 0.4846 - accuracy: 0.738 - ETA: 29s - loss: 0.4842 - accuracy: 0.738 - ETA: 29s - loss: 0.4840 - accuracy: 0.738 - ETA: 29s - loss: 0.4839 - accuracy: 0.738 - ETA: 29s - loss: 0.4836 - accuracy: 0.739 - ETA: 28s - loss: 0.4832 - accuracy: 0.739 - ETA: 28s - loss: 0.4827 - accuracy: 0.739 - ETA: 28s - loss: 0.4821 - accuracy: 0.740 - ETA: 28s - loss: 0.4818 - accuracy: 0.740 - ETA: 28s - loss: 0.4813 - accuracy: 0.741 - ETA: 28s - loss: 0.4811 - accuracy: 0.741 - ETA: 28s - loss: 0.4807 - accuracy: 0.741 - ETA: 28s - loss: 0.4804 - accuracy: 0.741 - ETA: 27s - loss: 0.4800 - accuracy: 0.741 - ETA: 27s - loss: 0.4798 - accuracy: 0.742 - ETA: 27s - loss: 0.4795 - accuracy: 0.742 - ETA: 27s - loss: 0.4792 - accuracy: 0.742 - ETA: 27s - loss: 0.4789 - accuracy: 0.742 - ETA: 27s - loss: 0.4786 - accuracy: 0.743 - ETA: 27s - loss: 0.4782 - accuracy: 0.743 - ETA: 27s - loss: 0.4777 - accuracy: 0.743 - ETA: 26s - loss: 0.4775 - accuracy: 0.743 - ETA: 26s - loss: 0.4770 - accuracy: 0.744 - ETA: 26s - loss: 0.4769 - accuracy: 0.744 - ETA: 26s - loss: 0.4767 - accuracy: 0.744 - ETA: 26s - loss: 0.4762 - accuracy: 0.744 - ETA: 26s - loss: 0.4758 - accuracy: 0.744 - ETA: 26s - loss: 0.4757 - accuracy: 0.745 - ETA: 26s - loss: 0.4753 - accuracy: 0.745 - ETA: 25s - loss: 0.4751 - accuracy: 0.745 - ETA: 25s - loss: 0.4747 - accuracy: 0.745 - ETA: 25s - loss: 0.4747 - accuracy: 0.745 - ETA: 25s - loss: 0.4746 - accuracy: 0.745 - ETA: 25s - loss: 0.4745 - accuracy: 0.746 - ETA: 25s - loss: 0.4742 - accuracy: 0.746 - ETA: 25s - loss: 0.4737 - accuracy: 0.746 - ETA: 25s - loss: 0.4738 - accuracy: 0.746 - ETA: 24s - loss: 0.4736 - accuracy: 0.746 - ETA: 24s - loss: 0.4732 - accuracy: 0.747 - ETA: 24s - loss: 0.4729 - accuracy: 0.747 - ETA: 24s - loss: 0.4725 - accuracy: 0.747 - ETA: 24s - loss: 0.4721 - accuracy: 0.747 - ETA: 24s - loss: 0.4720 - accuracy: 0.748 - ETA: 24s - loss: 0.4716 - accuracy: 0.748 - ETA: 24s - loss: 0.4711 - accuracy: 0.748 - ETA: 23s - loss: 0.4708 - accuracy: 0.748 - ETA: 23s - loss: 0.4704 - accuracy: 0.749 - ETA: 23s - loss: 0.4699 - accuracy: 0.749 - ETA: 23s - loss: 0.4698 - accuracy: 0.749 - ETA: 23s - loss: 0.4695 - accuracy: 0.749 - ETA: 23s - loss: 0.4692 - accuracy: 0.749 - ETA: 23s - loss: 0.4687 - accuracy: 0.750 - ETA: 23s - loss: 0.4685 - accuracy: 0.750 - ETA: 22s - loss: 0.4680 - accuracy: 0.750 - ETA: 22s - loss: 0.4677 - accuracy: 0.751 - ETA: 22s - loss: 0.4674 - accuracy: 0.751 - ETA: 22s - loss: 0.4671 - accuracy: 0.751 - ETA: 22s - loss: 0.4668 - accuracy: 0.751 - ETA: 22s - loss: 0.4665 - accuracy: 0.751 - ETA: 22s - loss: 0.4664 - accuracy: 0.751 - ETA: 22s - loss: 0.4661 - accuracy: 0.752 - ETA: 21s - loss: 0.4660 - accuracy: 0.752 - ETA: 21s - loss: 0.4658 - accuracy: 0.752 - ETA: 21s - loss: 0.4657 - accuracy: 0.752 - ETA: 21s - loss: 0.4656 - accuracy: 0.752 - ETA: 21s - loss: 0.4653 - accuracy: 0.752 - ETA: 21s - loss: 0.4649 - accuracy: 0.753 - ETA: 21s - loss: 0.4646 - accuracy: 0.753 - ETA: 21s - loss: 0.4645 - accuracy: 0.753 - ETA: 20s - loss: 0.4641 - accuracy: 0.753 - ETA: 20s - loss: 0.4638 - accuracy: 0.754 - ETA: 20s - loss: 0.4635 - accuracy: 0.754 - ETA: 20s - loss: 0.4631 - accuracy: 0.754 - ETA: 20s - loss: 0.4628 - accuracy: 0.754 - ETA: 20s - loss: 0.4628 - accuracy: 0.754 - ETA: 20s - loss: 0.4622 - accuracy: 0.755 - ETA: 20s - loss: 0.4618 - accuracy: 0.755 - ETA: 19s - loss: 0.4617 - accuracy: 0.755 - ETA: 19s - loss: 0.4613 - accuracy: 0.755 - ETA: 19s - loss: 0.4611 - accuracy: 0.755 - ETA: 19s - loss: 0.4608 - accuracy: 0.756 - ETA: 19s - loss: 0.4607 - accuracy: 0.756 - ETA: 19s - loss: 0.4607 - accuracy: 0.756 - ETA: 19s - loss: 0.4605 - accuracy: 0.756 - ETA: 19s - loss: 0.4604 - accuracy: 0.756 - ETA: 18s - loss: 0.4602 - accuracy: 0.756 - ETA: 18s - loss: 0.4599 - accuracy: 0.756 - ETA: 18s - loss: 0.4597 - accuracy: 0.757 - ETA: 18s - loss: 0.4595 - accuracy: 0.757 - ETA: 18s - loss: 0.4590 - accuracy: 0.757 - ETA: 18s - loss: 0.4591 - accuracy: 0.757 - ETA: 18s - loss: 0.4588 - accuracy: 0.757 - ETA: 17s - loss: 0.4587 - accuracy: 0.757 - ETA: 17s - loss: 0.4583 - accuracy: 0.757 - ETA: 17s - loss: 0.4580 - accuracy: 0.758 - ETA: 17s - loss: 0.4575 - accuracy: 0.758 - ETA: 17s - loss: 0.4572 - accuracy: 0.758 - ETA: 17s - loss: 0.4568 - accuracy: 0.758 - ETA: 17s - loss: 0.4565 - accuracy: 0.759 - ETA: 17s - loss: 0.4565 - accuracy: 0.759 - ETA: 16s - loss: 0.4561 - accuracy: 0.759 - ETA: 16s - loss: 0.4557 - accuracy: 0.759 - ETA: 16s - loss: 0.4554 - accuracy: 0.759 - ETA: 16s - loss: 0.4552 - accuracy: 0.759 - ETA: 16s - loss: 0.4547 - accuracy: 0.760 - ETA: 16s - loss: 0.4545 - accuracy: 0.760 - ETA: 16s - loss: 0.4541 - accuracy: 0.760 - ETA: 15s - loss: 0.4541 - accuracy: 0.760 - ETA: 15s - loss: 0.4539 - accuracy: 0.760 - ETA: 15s - loss: 0.4537 - accuracy: 0.761 - ETA: 15s - loss: 0.4536 - accuracy: 0.761 - ETA: 15s - loss: 0.4532 - accuracy: 0.761 - ETA: 15s - loss: 0.4531 - accuracy: 0.761 - ETA: 15s - loss: 0.4527 - accuracy: 0.761 - ETA: 14s - loss: 0.4526 - accuracy: 0.761 - ETA: 14s - loss: 0.4522 - accuracy: 0.762 - ETA: 14s - loss: 0.4519 - accuracy: 0.762 - ETA: 14s - loss: 0.4516 - accuracy: 0.762 - ETA: 14s - loss: 0.4512 - accuracy: 0.762 - ETA: 14s - loss: 0.4508 - accuracy: 0.763 - ETA: 14s - loss: 0.4506 - accuracy: 0.763 - ETA: 13s - loss: 0.4504 - accuracy: 0.763 - ETA: 13s - loss: 0.4501 - accuracy: 0.763 - ETA: 13s - loss: 0.4497 - accuracy: 0.763 - ETA: 13s - loss: 0.4497 - accuracy: 0.763 - ETA: 13s - loss: 0.4495 - accuracy: 0.764 - ETA: 13s - loss: 0.4498 - accuracy: 0.764 - ETA: 13s - loss: 0.4495 - accuracy: 0.764 - ETA: 13s - loss: 0.4495 - accuracy: 0.764 - ETA: 12s - loss: 0.4493 - accuracy: 0.764 - ETA: 12s - loss: 0.4490 - accuracy: 0.764 - ETA: 12s - loss: 0.4490 - accuracy: 0.764 - ETA: 12s - loss: 0.4486 - accuracy: 0.764 - ETA: 12s - loss: 0.4484 - accuracy: 0.764 - ETA: 12s - loss: 0.4480 - accuracy: 0.765 - ETA: 12s - loss: 0.4479 - accuracy: 0.765 - ETA: 11s - loss: 0.4479 - accuracy: 0.765 - ETA: 11s - loss: 0.4475 - accuracy: 0.765 - ETA: 11s - loss: 0.4471 - accuracy: 0.765 - ETA: 11s - loss: 0.4467 - accuracy: 0.765 - ETA: 11s - loss: 0.4467 - accuracy: 0.765 - ETA: 11s - loss: 0.4464 - accuracy: 0.765 - ETA: 11s - loss: 0.4463 - accuracy: 0.766 - ETA: 10s - loss: 0.4459 - accuracy: 0.766 - ETA: 10s - loss: 0.4458 - accuracy: 0.766 - ETA: 10s - loss: 0.4455 - accuracy: 0.766 - ETA: 10s - loss: 0.4456 - accuracy: 0.766 - ETA: 10s - loss: 0.4453 - accuracy: 0.767 - ETA: 10s - loss: 0.4451 - accuracy: 0.767 - ETA: 10s - loss: 0.4447 - accuracy: 0.767 - ETA: 9s - loss: 0.4445 - accuracy: 0.767 - ETA: 9s - loss: 0.4441 - accuracy: 0.76 - ETA: 9s - loss: 0.4441 - accuracy: 0.76 - ETA: 9s - loss: 0.4440 - accuracy: 0.76 - ETA: 9s - loss: 0.4437 - accuracy: 0.76 - ETA: 9s - loss: 0.4435 - accuracy: 0.76 - ETA: 9s - loss: 0.4431 - accuracy: 0.76 - ETA: 8s - loss: 0.4432 - accuracy: 0.76 - ETA: 8s - loss: 0.4430 - accuracy: 0.76 - ETA: 8s - loss: 0.4426 - accuracy: 0.76 - ETA: 8s - loss: 0.4425 - accuracy: 0.76 - ETA: 8s - loss: 0.4422 - accuracy: 0.76 - ETA: 8s - loss: 0.4418 - accuracy: 0.76 - ETA: 8s - loss: 0.4416 - accuracy: 0.76 - ETA: 8s - loss: 0.4411 - accuracy: 0.76 - ETA: 7s - loss: 0.4408 - accuracy: 0.76 - ETA: 7s - loss: 0.4406 - accuracy: 0.76 - ETA: 7s - loss: 0.4402 - accuracy: 0.77 - ETA: 7s - loss: 0.4399 - accuracy: 0.77 - ETA: 7s - loss: 0.4398 - accuracy: 0.77 - ETA: 7s - loss: 0.4394 - accuracy: 0.77 - ETA: 7s - loss: 0.4395 - accuracy: 0.77 - ETA: 6s - loss: 0.4391 - accuracy: 0.77 - ETA: 6s - loss: 0.4388 - accuracy: 0.77 - ETA: 6s - loss: 0.4385 - accuracy: 0.77 - ETA: 6s - loss: 0.4383 - accuracy: 0.77 - ETA: 6s - loss: 0.4382 - accuracy: 0.77 - ETA: 6s - loss: 0.4379 - accuracy: 0.77 - ETA: 6s - loss: 0.4377 - accuracy: 0.77 - ETA: 5s - loss: 0.4381 - accuracy: 0.77 - ETA: 5s - loss: 0.4379 - accuracy: 0.77 - ETA: 5s - loss: 0.4376 - accuracy: 0.77 - ETA: 5s - loss: 0.4372 - accuracy: 0.77 - ETA: 5s - loss: 0.4370 - accuracy: 0.77 - ETA: 5s - loss: 0.4368 - accuracy: 0.7728"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 5s - loss: 0.4367 - accuracy: 0.77 - ETA: 5s - loss: 0.4364 - accuracy: 0.77 - ETA: 4s - loss: 0.4366 - accuracy: 0.77 - ETA: 4s - loss: 0.4364 - accuracy: 0.77 - ETA: 4s - loss: 0.4363 - accuracy: 0.77 - ETA: 4s - loss: 0.4360 - accuracy: 0.77 - ETA: 4s - loss: 0.4357 - accuracy: 0.77 - ETA: 4s - loss: 0.4354 - accuracy: 0.77 - ETA: 4s - loss: 0.4351 - accuracy: 0.77 - ETA: 3s - loss: 0.4349 - accuracy: 0.77 - ETA: 3s - loss: 0.4347 - accuracy: 0.77 - ETA: 3s - loss: 0.4345 - accuracy: 0.77 - ETA: 3s - loss: 0.4343 - accuracy: 0.77 - ETA: 3s - loss: 0.4341 - accuracy: 0.77 - ETA: 3s - loss: 0.4340 - accuracy: 0.77 - ETA: 3s - loss: 0.4338 - accuracy: 0.77 - ETA: 2s - loss: 0.4336 - accuracy: 0.77 - ETA: 2s - loss: 0.4334 - accuracy: 0.77 - ETA: 2s - loss: 0.4333 - accuracy: 0.77 - ETA: 2s - loss: 0.4335 - accuracy: 0.77 - ETA: 2s - loss: 0.4333 - accuracy: 0.77 - ETA: 2s - loss: 0.4332 - accuracy: 0.77 - ETA: 2s - loss: 0.4330 - accuracy: 0.77 - ETA: 2s - loss: 0.4328 - accuracy: 0.77 - ETA: 1s - loss: 0.4328 - accuracy: 0.77 - ETA: 1s - loss: 0.4328 - accuracy: 0.77 - ETA: 1s - loss: 0.4326 - accuracy: 0.77 - ETA: 1s - loss: 0.4325 - accuracy: 0.77 - ETA: 1s - loss: 0.4322 - accuracy: 0.77 - ETA: 1s - loss: 0.4318 - accuracy: 0.77 - ETA: 1s - loss: 0.4315 - accuracy: 0.77 - ETA: 0s - loss: 0.4312 - accuracy: 0.77 - ETA: 0s - loss: 0.4313 - accuracy: 0.77 - ETA: 0s - loss: 0.4312 - accuracy: 0.77 - ETA: 0s - loss: 0.4311 - accuracy: 0.77 - ETA: 0s - loss: 0.4308 - accuracy: 0.77 - ETA: 0s - loss: 0.4307 - accuracy: 0.77 - ETA: 0s - loss: 0.4305 - accuracy: 0.77 - 110s 141ms/step - loss: 0.4305 - accuracy: 0.7780 - val_loss: 0.1452 - val_accuracy: 0.9622\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/782 [======>.......................] - ETA: 1:37 - loss: 0.1485 - accuracy: 0.93 - ETA: 1:35 - loss: 0.1887 - accuracy: 0.95 - ETA: 1:34 - loss: 0.2144 - accuracy: 0.93 - ETA: 1:34 - loss: 0.2548 - accuracy: 0.89 - ETA: 1:34 - loss: 0.2725 - accuracy: 0.88 - ETA: 1:34 - loss: 0.2583 - accuracy: 0.89 - ETA: 1:33 - loss: 0.2532 - accuracy: 0.90 - ETA: 1:34 - loss: 0.2654 - accuracy: 0.89 - ETA: 1:34 - loss: 0.2564 - accuracy: 0.89 - ETA: 1:34 - loss: 0.2620 - accuracy: 0.89 - ETA: 1:34 - loss: 0.2825 - accuracy: 0.88 - ETA: 1:33 - loss: 0.2936 - accuracy: 0.87 - ETA: 1:33 - loss: 0.2821 - accuracy: 0.88 - ETA: 1:32 - loss: 0.2805 - accuracy: 0.88 - ETA: 1:32 - loss: 0.2890 - accuracy: 0.88 - ETA: 1:32 - loss: 0.2830 - accuracy: 0.88 - ETA: 1:32 - loss: 0.2886 - accuracy: 0.88 - ETA: 1:32 - loss: 0.2843 - accuracy: 0.88 - ETA: 1:32 - loss: 0.2869 - accuracy: 0.88 - ETA: 1:32 - loss: 0.2968 - accuracy: 0.87 - ETA: 1:32 - loss: 0.2938 - accuracy: 0.87 - ETA: 1:31 - loss: 0.2924 - accuracy: 0.87 - ETA: 1:31 - loss: 0.2871 - accuracy: 0.88 - ETA: 1:31 - loss: 0.2887 - accuracy: 0.88 - ETA: 1:31 - loss: 0.2856 - accuracy: 0.88 - ETA: 1:31 - loss: 0.2829 - accuracy: 0.88 - ETA: 1:30 - loss: 0.2814 - accuracy: 0.88 - ETA: 1:30 - loss: 0.2875 - accuracy: 0.88 - ETA: 1:29 - loss: 0.2858 - accuracy: 0.88 - ETA: 1:29 - loss: 0.2904 - accuracy: 0.88 - ETA: 1:29 - loss: 0.2966 - accuracy: 0.87 - ETA: 1:29 - loss: 0.2969 - accuracy: 0.87 - ETA: 1:28 - loss: 0.2949 - accuracy: 0.87 - ETA: 1:28 - loss: 0.2957 - accuracy: 0.87 - ETA: 1:28 - loss: 0.2958 - accuracy: 0.87 - ETA: 1:28 - loss: 0.2936 - accuracy: 0.87 - ETA: 1:28 - loss: 0.2946 - accuracy: 0.87 - ETA: 1:28 - loss: 0.2961 - accuracy: 0.87 - ETA: 1:27 - loss: 0.2999 - accuracy: 0.87 - ETA: 1:27 - loss: 0.2964 - accuracy: 0.87 - ETA: 1:27 - loss: 0.2952 - accuracy: 0.87 - ETA: 1:27 - loss: 0.2931 - accuracy: 0.87 - ETA: 1:27 - loss: 0.2965 - accuracy: 0.87 - ETA: 1:26 - loss: 0.2933 - accuracy: 0.87 - ETA: 1:26 - loss: 0.2912 - accuracy: 0.87 - ETA: 1:26 - loss: 0.2894 - accuracy: 0.87 - ETA: 1:26 - loss: 0.2918 - accuracy: 0.87 - ETA: 1:26 - loss: 0.2907 - accuracy: 0.88 - ETA: 1:26 - loss: 0.2897 - accuracy: 0.87 - ETA: 1:26 - loss: 0.2913 - accuracy: 0.88 - ETA: 1:26 - loss: 0.2910 - accuracy: 0.88 - ETA: 1:26 - loss: 0.2892 - accuracy: 0.88 - ETA: 1:26 - loss: 0.2895 - accuracy: 0.88 - ETA: 1:26 - loss: 0.2879 - accuracy: 0.88 - ETA: 1:26 - loss: 0.2891 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2912 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2913 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2906 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2916 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2889 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2880 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2904 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2904 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2912 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2905 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2899 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2888 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2914 - accuracy: 0.88 - ETA: 1:23 - loss: 0.2916 - accuracy: 0.88 - ETA: 1:23 - loss: 0.2898 - accuracy: 0.88 - ETA: 1:23 - loss: 0.2885 - accuracy: 0.88 - ETA: 1:23 - loss: 0.2896 - accuracy: 0.88 - ETA: 1:23 - loss: 0.2897 - accuracy: 0.88 - ETA: 1:23 - loss: 0.2897 - accuracy: 0.88 - ETA: 1:23 - loss: 0.2907 - accuracy: 0.88 - ETA: 1:23 - loss: 0.2913 - accuracy: 0.87 - ETA: 1:23 - loss: 0.2897 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2909 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2939 - accuracy: 0.87 - ETA: 1:22 - loss: 0.2944 - accuracy: 0.87 - ETA: 1:22 - loss: 0.2922 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2921 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2931 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2919 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2916 - accuracy: 0.88 - ETA: 1:21 - loss: 0.2920 - accuracy: 0.88 - ETA: 1:21 - loss: 0.2920 - accuracy: 0.88 - ETA: 1:21 - loss: 0.2922 - accuracy: 0.88 - ETA: 1:21 - loss: 0.2944 - accuracy: 0.87 - ETA: 1:21 - loss: 0.2931 - accuracy: 0.88 - ETA: 1:21 - loss: 0.2929 - accuracy: 0.88 - ETA: 1:21 - loss: 0.2914 - accuracy: 0.88 - ETA: 1:21 - loss: 0.2925 - accuracy: 0.88 - ETA: 1:21 - loss: 0.2920 - accuracy: 0.88 - ETA: 1:20 - loss: 0.2932 - accuracy: 0.88 - ETA: 1:20 - loss: 0.2932 - accuracy: 0.88 - ETA: 1:20 - loss: 0.2937 - accuracy: 0.88 - ETA: 1:20 - loss: 0.2927 - accuracy: 0.88 - ETA: 1:20 - loss: 0.2940 - accuracy: 0.88 - ETA: 1:20 - loss: 0.2954 - accuracy: 0.87 - ETA: 1:20 - loss: 0.2965 - accuracy: 0.87 - ETA: 1:19 - loss: 0.2988 - accuracy: 0.87 - ETA: 1:19 - loss: 0.2976 - accuracy: 0.87 - ETA: 1:19 - loss: 0.2960 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2956 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2957 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2950 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2948 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2938 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2934 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2936 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2924 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2917 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2914 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2902 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2900 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2900 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2894 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2878 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2877 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2880 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2880 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2872 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2881 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2882 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2888 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2877 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2870 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2864 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2860 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2864 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2866 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2854 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2854 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2845 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2850 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2845 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2835 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2842 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2835 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2845 - accuracy: 0.88 - ETA: 1:17 - loss: 0.2849 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2856 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2845 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2848 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2850 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2850 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2858 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2855 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2845 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2860 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2872 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2882 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2887 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2905 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2895 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2897 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2896 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2895 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2896 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2893 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2885 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2905 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2899 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2895 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2889 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2889 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2889 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2886 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2875 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2880 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2876 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2873 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2871 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2871 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2869 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2862 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2868 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2863 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2870 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2876 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2870 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2875 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2885 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2878 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2876 - accuracy: 0.8863"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/782 [=============>................] - ETA: 1:14 - loss: 0.2873 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2881 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2877 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2877 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2879 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2872 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2868 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2861 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2858 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2862 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2856 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2856 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2849 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2849 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2846 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2840 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2839 - accuracy: 0.88 - ETA: 1:12 - loss: 0.2838 - accuracy: 0.88 - ETA: 1:12 - loss: 0.2831 - accuracy: 0.88 - ETA: 1:12 - loss: 0.2824 - accuracy: 0.88 - ETA: 1:12 - loss: 0.2818 - accuracy: 0.88 - ETA: 1:12 - loss: 0.2812 - accuracy: 0.88 - ETA: 1:12 - loss: 0.2810 - accuracy: 0.88 - ETA: 1:12 - loss: 0.2809 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2804 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2814 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2806 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2808 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2802 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2798 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2790 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2789 - accuracy: 0.88 - ETA: 1:10 - loss: 0.2788 - accuracy: 0.88 - ETA: 1:10 - loss: 0.2786 - accuracy: 0.88 - ETA: 1:10 - loss: 0.2785 - accuracy: 0.88 - ETA: 1:10 - loss: 0.2786 - accuracy: 0.88 - ETA: 1:10 - loss: 0.2791 - accuracy: 0.88 - ETA: 1:10 - loss: 0.2786 - accuracy: 0.88 - ETA: 1:10 - loss: 0.2788 - accuracy: 0.88 - ETA: 1:09 - loss: 0.2788 - accuracy: 0.88 - ETA: 1:09 - loss: 0.2780 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2785 - accuracy: 0.88 - ETA: 1:09 - loss: 0.2781 - accuracy: 0.88 - ETA: 1:09 - loss: 0.2781 - accuracy: 0.88 - ETA: 1:09 - loss: 0.2781 - accuracy: 0.88 - ETA: 1:09 - loss: 0.2775 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2767 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2761 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2754 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2756 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2753 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2757 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2752 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2748 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2745 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2745 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2743 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2738 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2733 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2729 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2723 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2723 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2715 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2708 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2702 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2696 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2690 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2692 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2688 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2692 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2699 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2696 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2688 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2689 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2684 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2684 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2683 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2677 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2673 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2673 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2668 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2663 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2661 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2657 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2651 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2650 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2654 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2650 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2655 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2658 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2657 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2661 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2658 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2654 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2649 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2655 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2650 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2642 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2641 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2637 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2637 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2637 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2634 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2631 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2629 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2623 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2619 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2622 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2618 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2620 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2617 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2623 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2620 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2617 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2615 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2609 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2605 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2599 - accuracy: 0.89 - ETA: 59s - loss: 0.2593 - accuracy: 0.8966 - ETA: 59s - loss: 0.2593 - accuracy: 0.896 - ETA: 59s - loss: 0.2590 - accuracy: 0.896 - ETA: 59s - loss: 0.2591 - accuracy: 0.896 - ETA: 59s - loss: 0.2598 - accuracy: 0.896 - ETA: 59s - loss: 0.2598 - accuracy: 0.896 - ETA: 59s - loss: 0.2598 - accuracy: 0.896 - ETA: 59s - loss: 0.2596 - accuracy: 0.896 - ETA: 58s - loss: 0.2595 - accuracy: 0.896 - ETA: 58s - loss: 0.2597 - accuracy: 0.896 - ETA: 58s - loss: 0.2595 - accuracy: 0.896 - ETA: 58s - loss: 0.2598 - accuracy: 0.896 - ETA: 58s - loss: 0.2598 - accuracy: 0.896 - ETA: 58s - loss: 0.2596 - accuracy: 0.896 - ETA: 58s - loss: 0.2595 - accuracy: 0.896 - ETA: 58s - loss: 0.2592 - accuracy: 0.896 - ETA: 58s - loss: 0.2596 - accuracy: 0.896 - ETA: 58s - loss: 0.2595 - accuracy: 0.896 - ETA: 58s - loss: 0.2594 - accuracy: 0.896 - ETA: 57s - loss: 0.2596 - accuracy: 0.896 - ETA: 57s - loss: 0.2593 - accuracy: 0.896 - ETA: 57s - loss: 0.2588 - accuracy: 0.896 - ETA: 57s - loss: 0.2588 - accuracy: 0.896 - ETA: 57s - loss: 0.2585 - accuracy: 0.896 - ETA: 57s - loss: 0.2581 - accuracy: 0.896 - ETA: 57s - loss: 0.2584 - accuracy: 0.896 - ETA: 57s - loss: 0.2584 - accuracy: 0.896 - ETA: 57s - loss: 0.2583 - accuracy: 0.896 - ETA: 57s - loss: 0.2579 - accuracy: 0.896 - ETA: 56s - loss: 0.2579 - accuracy: 0.896 - ETA: 56s - loss: 0.2575 - accuracy: 0.896 - ETA: 56s - loss: 0.2570 - accuracy: 0.897 - ETA: 56s - loss: 0.2568 - accuracy: 0.897 - ETA: 56s - loss: 0.2568 - accuracy: 0.897 - ETA: 56s - loss: 0.2570 - accuracy: 0.897 - ETA: 56s - loss: 0.2568 - accuracy: 0.897 - ETA: 56s - loss: 0.2566 - accuracy: 0.897 - ETA: 56s - loss: 0.2566 - accuracy: 0.897 - ETA: 55s - loss: 0.2566 - accuracy: 0.897 - ETA: 55s - loss: 0.2564 - accuracy: 0.897 - ETA: 55s - loss: 0.2565 - accuracy: 0.897 - ETA: 55s - loss: 0.2562 - accuracy: 0.897 - ETA: 55s - loss: 0.2562 - accuracy: 0.897 - ETA: 55s - loss: 0.2561 - accuracy: 0.897 - ETA: 55s - loss: 0.2557 - accuracy: 0.897 - ETA: 55s - loss: 0.2555 - accuracy: 0.898 - ETA: 54s - loss: 0.2556 - accuracy: 0.898 - ETA: 54s - loss: 0.2555 - accuracy: 0.898 - ETA: 54s - loss: 0.2552 - accuracy: 0.898 - ETA: 54s - loss: 0.2552 - accuracy: 0.898 - ETA: 54s - loss: 0.2552 - accuracy: 0.898 - ETA: 54s - loss: 0.2558 - accuracy: 0.897 - ETA: 54s - loss: 0.2558 - accuracy: 0.898 - ETA: 54s - loss: 0.2556 - accuracy: 0.898 - ETA: 53s - loss: 0.2553 - accuracy: 0.898 - ETA: 53s - loss: 0.2555 - accuracy: 0.898 - ETA: 53s - loss: 0.2550 - accuracy: 0.898 - ETA: 53s - loss: 0.2550 - accuracy: 0.898 - ETA: 53s - loss: 0.2551 - accuracy: 0.898 - ETA: 53s - loss: 0.2552 - accuracy: 0.898 - ETA: 53s - loss: 0.2556 - accuracy: 0.898 - ETA: 52s - loss: 0.2556 - accuracy: 0.898 - ETA: 52s - loss: 0.2553 - accuracy: 0.898 - ETA: 52s - loss: 0.2551 - accuracy: 0.898 - ETA: 52s - loss: 0.2550 - accuracy: 0.898 - ETA: 52s - loss: 0.2548 - accuracy: 0.898 - ETA: 52s - loss: 0.2549 - accuracy: 0.898 - ETA: 52s - loss: 0.2545 - accuracy: 0.8990"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/782 [====================>.........] - ETA: 52s - loss: 0.2543 - accuracy: 0.899 - ETA: 51s - loss: 0.2540 - accuracy: 0.899 - ETA: 51s - loss: 0.2538 - accuracy: 0.899 - ETA: 51s - loss: 0.2536 - accuracy: 0.899 - ETA: 51s - loss: 0.2533 - accuracy: 0.899 - ETA: 51s - loss: 0.2528 - accuracy: 0.899 - ETA: 51s - loss: 0.2524 - accuracy: 0.899 - ETA: 51s - loss: 0.2524 - accuracy: 0.899 - ETA: 51s - loss: 0.2525 - accuracy: 0.899 - ETA: 50s - loss: 0.2523 - accuracy: 0.899 - ETA: 50s - loss: 0.2520 - accuracy: 0.900 - ETA: 50s - loss: 0.2520 - accuracy: 0.900 - ETA: 50s - loss: 0.2518 - accuracy: 0.900 - ETA: 50s - loss: 0.2516 - accuracy: 0.900 - ETA: 50s - loss: 0.2516 - accuracy: 0.900 - ETA: 50s - loss: 0.2513 - accuracy: 0.900 - ETA: 50s - loss: 0.2512 - accuracy: 0.900 - ETA: 49s - loss: 0.2513 - accuracy: 0.900 - ETA: 49s - loss: 0.2513 - accuracy: 0.900 - ETA: 49s - loss: 0.2513 - accuracy: 0.900 - ETA: 49s - loss: 0.2511 - accuracy: 0.900 - ETA: 49s - loss: 0.2514 - accuracy: 0.900 - ETA: 49s - loss: 0.2510 - accuracy: 0.900 - ETA: 49s - loss: 0.2508 - accuracy: 0.900 - ETA: 48s - loss: 0.2515 - accuracy: 0.900 - ETA: 48s - loss: 0.2514 - accuracy: 0.900 - ETA: 48s - loss: 0.2514 - accuracy: 0.900 - ETA: 48s - loss: 0.2509 - accuracy: 0.900 - ETA: 48s - loss: 0.2509 - accuracy: 0.900 - ETA: 48s - loss: 0.2507 - accuracy: 0.900 - ETA: 48s - loss: 0.2506 - accuracy: 0.901 - ETA: 48s - loss: 0.2503 - accuracy: 0.901 - ETA: 47s - loss: 0.2503 - accuracy: 0.901 - ETA: 47s - loss: 0.2501 - accuracy: 0.901 - ETA: 47s - loss: 0.2497 - accuracy: 0.901 - ETA: 47s - loss: 0.2495 - accuracy: 0.901 - ETA: 47s - loss: 0.2492 - accuracy: 0.901 - ETA: 47s - loss: 0.2491 - accuracy: 0.901 - ETA: 47s - loss: 0.2487 - accuracy: 0.901 - ETA: 47s - loss: 0.2488 - accuracy: 0.901 - ETA: 46s - loss: 0.2486 - accuracy: 0.901 - ETA: 46s - loss: 0.2483 - accuracy: 0.901 - ETA: 46s - loss: 0.2481 - accuracy: 0.901 - ETA: 46s - loss: 0.2478 - accuracy: 0.902 - ETA: 46s - loss: 0.2474 - accuracy: 0.902 - ETA: 46s - loss: 0.2474 - accuracy: 0.902 - ETA: 46s - loss: 0.2475 - accuracy: 0.902 - ETA: 46s - loss: 0.2475 - accuracy: 0.902 - ETA: 45s - loss: 0.2473 - accuracy: 0.902 - ETA: 45s - loss: 0.2470 - accuracy: 0.902 - ETA: 45s - loss: 0.2466 - accuracy: 0.902 - ETA: 45s - loss: 0.2463 - accuracy: 0.902 - ETA: 45s - loss: 0.2459 - accuracy: 0.903 - ETA: 45s - loss: 0.2455 - accuracy: 0.903 - ETA: 45s - loss: 0.2460 - accuracy: 0.903 - ETA: 45s - loss: 0.2456 - accuracy: 0.903 - ETA: 44s - loss: 0.2453 - accuracy: 0.903 - ETA: 44s - loss: 0.2451 - accuracy: 0.903 - ETA: 44s - loss: 0.2448 - accuracy: 0.903 - ETA: 44s - loss: 0.2447 - accuracy: 0.903 - ETA: 44s - loss: 0.2449 - accuracy: 0.903 - ETA: 44s - loss: 0.2448 - accuracy: 0.903 - ETA: 44s - loss: 0.2445 - accuracy: 0.904 - ETA: 43s - loss: 0.2442 - accuracy: 0.904 - ETA: 43s - loss: 0.2443 - accuracy: 0.904 - ETA: 43s - loss: 0.2442 - accuracy: 0.904 - ETA: 43s - loss: 0.2441 - accuracy: 0.904 - ETA: 43s - loss: 0.2442 - accuracy: 0.904 - ETA: 43s - loss: 0.2443 - accuracy: 0.903 - ETA: 43s - loss: 0.2439 - accuracy: 0.904 - ETA: 43s - loss: 0.2441 - accuracy: 0.903 - ETA: 42s - loss: 0.2441 - accuracy: 0.903 - ETA: 42s - loss: 0.2441 - accuracy: 0.903 - ETA: 42s - loss: 0.2442 - accuracy: 0.904 - ETA: 42s - loss: 0.2437 - accuracy: 0.904 - ETA: 42s - loss: 0.2433 - accuracy: 0.904 - ETA: 42s - loss: 0.2430 - accuracy: 0.904 - ETA: 42s - loss: 0.2433 - accuracy: 0.904 - ETA: 41s - loss: 0.2433 - accuracy: 0.904 - ETA: 41s - loss: 0.2431 - accuracy: 0.904 - ETA: 41s - loss: 0.2429 - accuracy: 0.904 - ETA: 41s - loss: 0.2429 - accuracy: 0.904 - ETA: 41s - loss: 0.2427 - accuracy: 0.904 - ETA: 41s - loss: 0.2424 - accuracy: 0.904 - ETA: 41s - loss: 0.2424 - accuracy: 0.905 - ETA: 40s - loss: 0.2424 - accuracy: 0.905 - ETA: 40s - loss: 0.2422 - accuracy: 0.905 - ETA: 40s - loss: 0.2419 - accuracy: 0.905 - ETA: 40s - loss: 0.2417 - accuracy: 0.905 - ETA: 40s - loss: 0.2413 - accuracy: 0.905 - ETA: 40s - loss: 0.2413 - accuracy: 0.905 - ETA: 40s - loss: 0.2412 - accuracy: 0.905 - ETA: 40s - loss: 0.2409 - accuracy: 0.905 - ETA: 39s - loss: 0.2410 - accuracy: 0.905 - ETA: 39s - loss: 0.2410 - accuracy: 0.905 - ETA: 39s - loss: 0.2407 - accuracy: 0.905 - ETA: 39s - loss: 0.2406 - accuracy: 0.905 - ETA: 39s - loss: 0.2407 - accuracy: 0.905 - ETA: 39s - loss: 0.2405 - accuracy: 0.905 - ETA: 39s - loss: 0.2404 - accuracy: 0.905 - ETA: 38s - loss: 0.2401 - accuracy: 0.905 - ETA: 38s - loss: 0.2404 - accuracy: 0.905 - ETA: 38s - loss: 0.2401 - accuracy: 0.906 - ETA: 38s - loss: 0.2396 - accuracy: 0.906 - ETA: 38s - loss: 0.2396 - accuracy: 0.906 - ETA: 38s - loss: 0.2398 - accuracy: 0.906 - ETA: 38s - loss: 0.2396 - accuracy: 0.906 - ETA: 38s - loss: 0.2395 - accuracy: 0.906 - ETA: 38s - loss: 0.2392 - accuracy: 0.906 - ETA: 37s - loss: 0.2389 - accuracy: 0.906 - ETA: 37s - loss: 0.2386 - accuracy: 0.906 - ETA: 37s - loss: 0.2383 - accuracy: 0.907 - ETA: 37s - loss: 0.2382 - accuracy: 0.907 - ETA: 37s - loss: 0.2381 - accuracy: 0.907 - ETA: 37s - loss: 0.2378 - accuracy: 0.907 - ETA: 37s - loss: 0.2377 - accuracy: 0.907 - ETA: 37s - loss: 0.2378 - accuracy: 0.907 - ETA: 36s - loss: 0.2377 - accuracy: 0.907 - ETA: 36s - loss: 0.2374 - accuracy: 0.907 - ETA: 36s - loss: 0.2374 - accuracy: 0.907 - ETA: 36s - loss: 0.2372 - accuracy: 0.907 - ETA: 36s - loss: 0.2369 - accuracy: 0.907 - ETA: 36s - loss: 0.2368 - accuracy: 0.907 - ETA: 36s - loss: 0.2368 - accuracy: 0.907 - ETA: 36s - loss: 0.2366 - accuracy: 0.907 - ETA: 35s - loss: 0.2363 - accuracy: 0.907 - ETA: 35s - loss: 0.2363 - accuracy: 0.907 - ETA: 35s - loss: 0.2365 - accuracy: 0.907 - ETA: 35s - loss: 0.2363 - accuracy: 0.907 - ETA: 35s - loss: 0.2362 - accuracy: 0.907 - ETA: 35s - loss: 0.2358 - accuracy: 0.907 - ETA: 35s - loss: 0.2355 - accuracy: 0.907 - ETA: 35s - loss: 0.2353 - accuracy: 0.907 - ETA: 34s - loss: 0.2353 - accuracy: 0.907 - ETA: 34s - loss: 0.2351 - accuracy: 0.907 - ETA: 34s - loss: 0.2351 - accuracy: 0.907 - ETA: 34s - loss: 0.2348 - accuracy: 0.907 - ETA: 34s - loss: 0.2345 - accuracy: 0.908 - ETA: 34s - loss: 0.2346 - accuracy: 0.908 - ETA: 34s - loss: 0.2343 - accuracy: 0.908 - ETA: 33s - loss: 0.2343 - accuracy: 0.908 - ETA: 33s - loss: 0.2346 - accuracy: 0.908 - ETA: 33s - loss: 0.2343 - accuracy: 0.908 - ETA: 33s - loss: 0.2344 - accuracy: 0.908 - ETA: 33s - loss: 0.2341 - accuracy: 0.908 - ETA: 33s - loss: 0.2340 - accuracy: 0.908 - ETA: 33s - loss: 0.2337 - accuracy: 0.908 - ETA: 33s - loss: 0.2333 - accuracy: 0.908 - ETA: 32s - loss: 0.2331 - accuracy: 0.908 - ETA: 32s - loss: 0.2328 - accuracy: 0.909 - ETA: 32s - loss: 0.2326 - accuracy: 0.909 - ETA: 32s - loss: 0.2325 - accuracy: 0.909 - ETA: 32s - loss: 0.2327 - accuracy: 0.908 - ETA: 32s - loss: 0.2325 - accuracy: 0.909 - ETA: 32s - loss: 0.2324 - accuracy: 0.909 - ETA: 31s - loss: 0.2323 - accuracy: 0.909 - ETA: 31s - loss: 0.2322 - accuracy: 0.909 - ETA: 31s - loss: 0.2321 - accuracy: 0.909 - ETA: 31s - loss: 0.2320 - accuracy: 0.909 - ETA: 31s - loss: 0.2319 - accuracy: 0.909 - ETA: 31s - loss: 0.2316 - accuracy: 0.909 - ETA: 31s - loss: 0.2313 - accuracy: 0.909 - ETA: 31s - loss: 0.2310 - accuracy: 0.909 - ETA: 30s - loss: 0.2308 - accuracy: 0.909 - ETA: 30s - loss: 0.2307 - accuracy: 0.909 - ETA: 30s - loss: 0.2309 - accuracy: 0.909 - ETA: 30s - loss: 0.2306 - accuracy: 0.909 - ETA: 30s - loss: 0.2303 - accuracy: 0.909 - ETA: 30s - loss: 0.2303 - accuracy: 0.909 - ETA: 30s - loss: 0.2302 - accuracy: 0.909 - ETA: 29s - loss: 0.2301 - accuracy: 0.909 - ETA: 29s - loss: 0.2300 - accuracy: 0.909 - ETA: 29s - loss: 0.2302 - accuracy: 0.909 - ETA: 29s - loss: 0.2300 - accuracy: 0.909 - ETA: 29s - loss: 0.2299 - accuracy: 0.909 - ETA: 29s - loss: 0.2302 - accuracy: 0.909 - ETA: 29s - loss: 0.2301 - accuracy: 0.909 - ETA: 29s - loss: 0.2298 - accuracy: 0.909 - ETA: 28s - loss: 0.2297 - accuracy: 0.909 - ETA: 28s - loss: 0.2295 - accuracy: 0.909 - ETA: 28s - loss: 0.2295 - accuracy: 0.909 - ETA: 28s - loss: 0.2293 - accuracy: 0.909 - ETA: 28s - loss: 0.2292 - accuracy: 0.909 - ETA: 28s - loss: 0.2289 - accuracy: 0.909 - ETA: 28s - loss: 0.2287 - accuracy: 0.910 - ETA: 28s - loss: 0.2285 - accuracy: 0.9101"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/782 [===========================>..] - ETA: 27s - loss: 0.2283 - accuracy: 0.910 - ETA: 27s - loss: 0.2281 - accuracy: 0.910 - ETA: 27s - loss: 0.2279 - accuracy: 0.910 - ETA: 27s - loss: 0.2278 - accuracy: 0.910 - ETA: 27s - loss: 0.2280 - accuracy: 0.910 - ETA: 27s - loss: 0.2280 - accuracy: 0.910 - ETA: 27s - loss: 0.2277 - accuracy: 0.910 - ETA: 26s - loss: 0.2274 - accuracy: 0.910 - ETA: 26s - loss: 0.2272 - accuracy: 0.910 - ETA: 26s - loss: 0.2269 - accuracy: 0.910 - ETA: 26s - loss: 0.2270 - accuracy: 0.910 - ETA: 26s - loss: 0.2267 - accuracy: 0.910 - ETA: 26s - loss: 0.2267 - accuracy: 0.910 - ETA: 26s - loss: 0.2266 - accuracy: 0.910 - ETA: 26s - loss: 0.2266 - accuracy: 0.910 - ETA: 25s - loss: 0.2262 - accuracy: 0.910 - ETA: 25s - loss: 0.2260 - accuracy: 0.911 - ETA: 25s - loss: 0.2259 - accuracy: 0.911 - ETA: 25s - loss: 0.2258 - accuracy: 0.911 - ETA: 25s - loss: 0.2255 - accuracy: 0.911 - ETA: 25s - loss: 0.2254 - accuracy: 0.911 - ETA: 25s - loss: 0.2252 - accuracy: 0.911 - ETA: 25s - loss: 0.2251 - accuracy: 0.911 - ETA: 24s - loss: 0.2252 - accuracy: 0.911 - ETA: 24s - loss: 0.2251 - accuracy: 0.911 - ETA: 24s - loss: 0.2250 - accuracy: 0.911 - ETA: 24s - loss: 0.2250 - accuracy: 0.911 - ETA: 24s - loss: 0.2249 - accuracy: 0.911 - ETA: 24s - loss: 0.2247 - accuracy: 0.911 - ETA: 24s - loss: 0.2245 - accuracy: 0.911 - ETA: 24s - loss: 0.2245 - accuracy: 0.911 - ETA: 23s - loss: 0.2246 - accuracy: 0.911 - ETA: 23s - loss: 0.2246 - accuracy: 0.911 - ETA: 23s - loss: 0.2246 - accuracy: 0.911 - ETA: 23s - loss: 0.2245 - accuracy: 0.911 - ETA: 23s - loss: 0.2243 - accuracy: 0.911 - ETA: 23s - loss: 0.2243 - accuracy: 0.911 - ETA: 23s - loss: 0.2242 - accuracy: 0.911 - ETA: 23s - loss: 0.2240 - accuracy: 0.911 - ETA: 22s - loss: 0.2240 - accuracy: 0.911 - ETA: 22s - loss: 0.2238 - accuracy: 0.912 - ETA: 22s - loss: 0.2237 - accuracy: 0.912 - ETA: 22s - loss: 0.2239 - accuracy: 0.912 - ETA: 22s - loss: 0.2238 - accuracy: 0.912 - ETA: 22s - loss: 0.2237 - accuracy: 0.912 - ETA: 22s - loss: 0.2236 - accuracy: 0.912 - ETA: 21s - loss: 0.2234 - accuracy: 0.912 - ETA: 21s - loss: 0.2234 - accuracy: 0.912 - ETA: 21s - loss: 0.2236 - accuracy: 0.912 - ETA: 21s - loss: 0.2234 - accuracy: 0.912 - ETA: 21s - loss: 0.2233 - accuracy: 0.912 - ETA: 21s - loss: 0.2232 - accuracy: 0.912 - ETA: 21s - loss: 0.2230 - accuracy: 0.912 - ETA: 21s - loss: 0.2227 - accuracy: 0.912 - ETA: 20s - loss: 0.2226 - accuracy: 0.912 - ETA: 20s - loss: 0.2225 - accuracy: 0.912 - ETA: 20s - loss: 0.2223 - accuracy: 0.912 - ETA: 20s - loss: 0.2220 - accuracy: 0.912 - ETA: 20s - loss: 0.2221 - accuracy: 0.912 - ETA: 20s - loss: 0.2220 - accuracy: 0.912 - ETA: 20s - loss: 0.2218 - accuracy: 0.912 - ETA: 20s - loss: 0.2216 - accuracy: 0.912 - ETA: 19s - loss: 0.2215 - accuracy: 0.912 - ETA: 19s - loss: 0.2216 - accuracy: 0.912 - ETA: 19s - loss: 0.2216 - accuracy: 0.912 - ETA: 19s - loss: 0.2215 - accuracy: 0.912 - ETA: 19s - loss: 0.2212 - accuracy: 0.912 - ETA: 19s - loss: 0.2211 - accuracy: 0.912 - ETA: 19s - loss: 0.2213 - accuracy: 0.912 - ETA: 19s - loss: 0.2211 - accuracy: 0.912 - ETA: 18s - loss: 0.2209 - accuracy: 0.913 - ETA: 18s - loss: 0.2207 - accuracy: 0.913 - ETA: 18s - loss: 0.2205 - accuracy: 0.913 - ETA: 18s - loss: 0.2203 - accuracy: 0.913 - ETA: 18s - loss: 0.2203 - accuracy: 0.913 - ETA: 18s - loss: 0.2200 - accuracy: 0.913 - ETA: 18s - loss: 0.2198 - accuracy: 0.913 - ETA: 18s - loss: 0.2199 - accuracy: 0.913 - ETA: 17s - loss: 0.2197 - accuracy: 0.913 - ETA: 17s - loss: 0.2195 - accuracy: 0.913 - ETA: 17s - loss: 0.2194 - accuracy: 0.913 - ETA: 17s - loss: 0.2192 - accuracy: 0.913 - ETA: 17s - loss: 0.2190 - accuracy: 0.914 - ETA: 17s - loss: 0.2188 - accuracy: 0.914 - ETA: 17s - loss: 0.2191 - accuracy: 0.914 - ETA: 17s - loss: 0.2194 - accuracy: 0.913 - ETA: 17s - loss: 0.2192 - accuracy: 0.914 - ETA: 16s - loss: 0.2192 - accuracy: 0.914 - ETA: 16s - loss: 0.2191 - accuracy: 0.914 - ETA: 16s - loss: 0.2189 - accuracy: 0.914 - ETA: 16s - loss: 0.2193 - accuracy: 0.914 - ETA: 16s - loss: 0.2191 - accuracy: 0.914 - ETA: 16s - loss: 0.2194 - accuracy: 0.914 - ETA: 16s - loss: 0.2193 - accuracy: 0.914 - ETA: 16s - loss: 0.2192 - accuracy: 0.914 - ETA: 15s - loss: 0.2190 - accuracy: 0.914 - ETA: 15s - loss: 0.2187 - accuracy: 0.914 - ETA: 15s - loss: 0.2186 - accuracy: 0.914 - ETA: 15s - loss: 0.2184 - accuracy: 0.914 - ETA: 15s - loss: 0.2183 - accuracy: 0.914 - ETA: 15s - loss: 0.2180 - accuracy: 0.914 - ETA: 15s - loss: 0.2179 - accuracy: 0.914 - ETA: 15s - loss: 0.2176 - accuracy: 0.914 - ETA: 14s - loss: 0.2175 - accuracy: 0.914 - ETA: 14s - loss: 0.2172 - accuracy: 0.915 - ETA: 14s - loss: 0.2172 - accuracy: 0.915 - ETA: 14s - loss: 0.2170 - accuracy: 0.915 - ETA: 14s - loss: 0.2171 - accuracy: 0.915 - ETA: 14s - loss: 0.2172 - accuracy: 0.915 - ETA: 14s - loss: 0.2171 - accuracy: 0.915 - ETA: 14s - loss: 0.2170 - accuracy: 0.915 - ETA: 13s - loss: 0.2168 - accuracy: 0.915 - ETA: 13s - loss: 0.2168 - accuracy: 0.915 - ETA: 13s - loss: 0.2167 - accuracy: 0.915 - ETA: 13s - loss: 0.2167 - accuracy: 0.915 - ETA: 13s - loss: 0.2165 - accuracy: 0.915 - ETA: 13s - loss: 0.2163 - accuracy: 0.915 - ETA: 13s - loss: 0.2161 - accuracy: 0.915 - ETA: 13s - loss: 0.2159 - accuracy: 0.915 - ETA: 12s - loss: 0.2158 - accuracy: 0.915 - ETA: 12s - loss: 0.2157 - accuracy: 0.915 - ETA: 12s - loss: 0.2155 - accuracy: 0.915 - ETA: 12s - loss: 0.2154 - accuracy: 0.915 - ETA: 12s - loss: 0.2152 - accuracy: 0.915 - ETA: 12s - loss: 0.2154 - accuracy: 0.915 - ETA: 12s - loss: 0.2153 - accuracy: 0.916 - ETA: 12s - loss: 0.2155 - accuracy: 0.915 - ETA: 11s - loss: 0.2154 - accuracy: 0.916 - ETA: 11s - loss: 0.2154 - accuracy: 0.916 - ETA: 11s - loss: 0.2152 - accuracy: 0.916 - ETA: 11s - loss: 0.2150 - accuracy: 0.916 - ETA: 11s - loss: 0.2150 - accuracy: 0.916 - ETA: 11s - loss: 0.2148 - accuracy: 0.916 - ETA: 11s - loss: 0.2146 - accuracy: 0.916 - ETA: 11s - loss: 0.2143 - accuracy: 0.916 - ETA: 10s - loss: 0.2142 - accuracy: 0.916 - ETA: 10s - loss: 0.2142 - accuracy: 0.916 - ETA: 10s - loss: 0.2140 - accuracy: 0.916 - ETA: 10s - loss: 0.2140 - accuracy: 0.916 - ETA: 10s - loss: 0.2138 - accuracy: 0.916 - ETA: 10s - loss: 0.2138 - accuracy: 0.916 - ETA: 10s - loss: 0.2137 - accuracy: 0.916 - ETA: 10s - loss: 0.2138 - accuracy: 0.916 - ETA: 9s - loss: 0.2136 - accuracy: 0.917 - ETA: 9s - loss: 0.2137 - accuracy: 0.91 - ETA: 9s - loss: 0.2135 - accuracy: 0.91 - ETA: 9s - loss: 0.2136 - accuracy: 0.91 - ETA: 9s - loss: 0.2134 - accuracy: 0.91 - ETA: 9s - loss: 0.2133 - accuracy: 0.91 - ETA: 9s - loss: 0.2131 - accuracy: 0.91 - ETA: 9s - loss: 0.2130 - accuracy: 0.91 - ETA: 8s - loss: 0.2129 - accuracy: 0.91 - ETA: 8s - loss: 0.2128 - accuracy: 0.91 - ETA: 8s - loss: 0.2127 - accuracy: 0.91 - ETA: 8s - loss: 0.2125 - accuracy: 0.91 - ETA: 8s - loss: 0.2123 - accuracy: 0.91 - ETA: 8s - loss: 0.2121 - accuracy: 0.91 - ETA: 8s - loss: 0.2122 - accuracy: 0.91 - ETA: 8s - loss: 0.2120 - accuracy: 0.91 - ETA: 7s - loss: 0.2118 - accuracy: 0.91 - ETA: 7s - loss: 0.2118 - accuracy: 0.91 - ETA: 7s - loss: 0.2118 - accuracy: 0.91 - ETA: 7s - loss: 0.2116 - accuracy: 0.91 - ETA: 7s - loss: 0.2116 - accuracy: 0.91 - ETA: 7s - loss: 0.2113 - accuracy: 0.91 - ETA: 7s - loss: 0.2112 - accuracy: 0.91 - ETA: 7s - loss: 0.2111 - accuracy: 0.91 - ETA: 6s - loss: 0.2109 - accuracy: 0.91 - ETA: 6s - loss: 0.2110 - accuracy: 0.91 - ETA: 6s - loss: 0.2111 - accuracy: 0.91 - ETA: 6s - loss: 0.2109 - accuracy: 0.91 - ETA: 6s - loss: 0.2111 - accuracy: 0.91 - ETA: 6s - loss: 0.2109 - accuracy: 0.91 - ETA: 6s - loss: 0.2107 - accuracy: 0.91 - ETA: 6s - loss: 0.2106 - accuracy: 0.91 - ETA: 5s - loss: 0.2105 - accuracy: 0.91 - ETA: 5s - loss: 0.2105 - accuracy: 0.91 - ETA: 5s - loss: 0.2104 - accuracy: 0.91 - ETA: 5s - loss: 0.2104 - accuracy: 0.91 - ETA: 5s - loss: 0.2105 - accuracy: 0.91 - ETA: 5s - loss: 0.2104 - accuracy: 0.91 - ETA: 5s - loss: 0.2104 - accuracy: 0.91 - ETA: 5s - loss: 0.2102 - accuracy: 0.91 - ETA: 4s - loss: 0.2102 - accuracy: 0.91 - ETA: 4s - loss: 0.2102 - accuracy: 0.91 - ETA: 4s - loss: 0.2100 - accuracy: 0.91 - ETA: 4s - loss: 0.2098 - accuracy: 0.91 - ETA: 4s - loss: 0.2102 - accuracy: 0.9184"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 4s - loss: 0.2101 - accuracy: 0.91 - ETA: 4s - loss: 0.2102 - accuracy: 0.91 - ETA: 4s - loss: 0.2100 - accuracy: 0.91 - ETA: 3s - loss: 0.2100 - accuracy: 0.91 - ETA: 3s - loss: 0.2098 - accuracy: 0.91 - ETA: 3s - loss: 0.2098 - accuracy: 0.91 - ETA: 3s - loss: 0.2096 - accuracy: 0.91 - ETA: 3s - loss: 0.2095 - accuracy: 0.91 - ETA: 3s - loss: 0.2093 - accuracy: 0.91 - ETA: 3s - loss: 0.2092 - accuracy: 0.91 - ETA: 3s - loss: 0.2091 - accuracy: 0.91 - ETA: 2s - loss: 0.2091 - accuracy: 0.91 - ETA: 2s - loss: 0.2091 - accuracy: 0.91 - ETA: 2s - loss: 0.2089 - accuracy: 0.91 - ETA: 2s - loss: 0.2089 - accuracy: 0.91 - ETA: 2s - loss: 0.2089 - accuracy: 0.91 - ETA: 2s - loss: 0.2091 - accuracy: 0.91 - ETA: 2s - loss: 0.2089 - accuracy: 0.91 - ETA: 2s - loss: 0.2091 - accuracy: 0.91 - ETA: 1s - loss: 0.2090 - accuracy: 0.91 - ETA: 1s - loss: 0.2089 - accuracy: 0.91 - ETA: 1s - loss: 0.2092 - accuracy: 0.91 - ETA: 1s - loss: 0.2092 - accuracy: 0.91 - ETA: 1s - loss: 0.2090 - accuracy: 0.91 - ETA: 1s - loss: 0.2090 - accuracy: 0.91 - ETA: 1s - loss: 0.2089 - accuracy: 0.91 - ETA: 1s - loss: 0.2087 - accuracy: 0.91 - ETA: 0s - loss: 0.2085 - accuracy: 0.91 - ETA: 0s - loss: 0.2084 - accuracy: 0.91 - ETA: 0s - loss: 0.2086 - accuracy: 0.91 - ETA: 0s - loss: 0.2086 - accuracy: 0.91 - ETA: 0s - loss: 0.2087 - accuracy: 0.91 - ETA: 0s - loss: 0.2085 - accuracy: 0.91 - ETA: 0s - loss: 0.2086 - accuracy: 0.91 - ETA: 0s - loss: 0.2084 - accuracy: 0.91 - 100s 128ms/step - loss: 0.2082 - accuracy: 0.9192 - val_loss: 0.0545 - val_accuracy: 0.9882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/782 [=============>................] - ETA: 1:42 - loss: 0.4086 - accuracy: 0.84 - ETA: 47s - loss: 0.2343 - accuracy: 0.9167 - ETA: 36s - loss: 0.2883 - accuracy: 0.868 - ETA: 31s - loss: 0.2460 - accuracy: 0.888 - ETA: 27s - loss: 0.2587 - accuracy: 0.890 - ETA: 26s - loss: 0.2815 - accuracy: 0.885 - ETA: 25s - loss: 0.2775 - accuracy: 0.883 - ETA: 24s - loss: 0.2823 - accuracy: 0.886 - ETA: 24s - loss: 0.2885 - accuracy: 0.881 - ETA: 23s - loss: 0.2997 - accuracy: 0.879 - ETA: 23s - loss: 0.2889 - accuracy: 0.882 - ETA: 23s - loss: 0.3001 - accuracy: 0.877 - ETA: 23s - loss: 0.2913 - accuracy: 0.882 - ETA: 22s - loss: 0.2930 - accuracy: 0.879 - ETA: 22s - loss: 0.2911 - accuracy: 0.879 - ETA: 22s - loss: 0.3034 - accuracy: 0.876 - ETA: 22s - loss: 0.3017 - accuracy: 0.876 - ETA: 22s - loss: 0.2973 - accuracy: 0.877 - ETA: 22s - loss: 0.3072 - accuracy: 0.874 - ETA: 22s - loss: 0.3088 - accuracy: 0.873 - ETA: 22s - loss: 0.3089 - accuracy: 0.873 - ETA: 22s - loss: 0.3070 - accuracy: 0.874 - ETA: 22s - loss: 0.3035 - accuracy: 0.874 - ETA: 22s - loss: 0.2967 - accuracy: 0.877 - ETA: 21s - loss: 0.2965 - accuracy: 0.877 - ETA: 21s - loss: 0.2920 - accuracy: 0.879 - ETA: 21s - loss: 0.3009 - accuracy: 0.876 - ETA: 21s - loss: 0.3049 - accuracy: 0.875 - ETA: 21s - loss: 0.3010 - accuracy: 0.876 - ETA: 21s - loss: 0.3007 - accuracy: 0.876 - ETA: 21s - loss: 0.3050 - accuracy: 0.875 - ETA: 21s - loss: 0.2998 - accuracy: 0.877 - ETA: 21s - loss: 0.2981 - accuracy: 0.878 - ETA: 21s - loss: 0.3015 - accuracy: 0.877 - ETA: 20s - loss: 0.3042 - accuracy: 0.876 - ETA: 20s - loss: 0.3004 - accuracy: 0.877 - ETA: 20s - loss: 0.2987 - accuracy: 0.878 - ETA: 20s - loss: 0.2986 - accuracy: 0.879 - ETA: 20s - loss: 0.2957 - accuracy: 0.879 - ETA: 20s - loss: 0.3023 - accuracy: 0.878 - ETA: 20s - loss: 0.3040 - accuracy: 0.878 - ETA: 20s - loss: 0.3042 - accuracy: 0.878 - ETA: 20s - loss: 0.3066 - accuracy: 0.876 - ETA: 20s - loss: 0.3060 - accuracy: 0.877 - ETA: 20s - loss: 0.3042 - accuracy: 0.877 - ETA: 20s - loss: 0.3067 - accuracy: 0.875 - ETA: 19s - loss: 0.3058 - accuracy: 0.875 - ETA: 19s - loss: 0.3036 - accuracy: 0.876 - ETA: 19s - loss: 0.3071 - accuracy: 0.875 - ETA: 19s - loss: 0.3104 - accuracy: 0.874 - ETA: 19s - loss: 0.3099 - accuracy: 0.875 - ETA: 19s - loss: 0.3087 - accuracy: 0.875 - ETA: 19s - loss: 0.3051 - accuracy: 0.877 - ETA: 19s - loss: 0.3061 - accuracy: 0.876 - ETA: 19s - loss: 0.3072 - accuracy: 0.876 - ETA: 19s - loss: 0.3067 - accuracy: 0.877 - ETA: 19s - loss: 0.3098 - accuracy: 0.875 - ETA: 19s - loss: 0.3100 - accuracy: 0.875 - ETA: 19s - loss: 0.3097 - accuracy: 0.876 - ETA: 19s - loss: 0.3063 - accuracy: 0.878 - ETA: 19s - loss: 0.3046 - accuracy: 0.879 - ETA: 19s - loss: 0.3081 - accuracy: 0.877 - ETA: 18s - loss: 0.3075 - accuracy: 0.878 - ETA: 18s - loss: 0.3084 - accuracy: 0.877 - ETA: 18s - loss: 0.3083 - accuracy: 0.878 - ETA: 18s - loss: 0.3099 - accuracy: 0.877 - ETA: 18s - loss: 0.3098 - accuracy: 0.877 - ETA: 18s - loss: 0.3084 - accuracy: 0.877 - ETA: 18s - loss: 0.3107 - accuracy: 0.877 - ETA: 18s - loss: 0.3124 - accuracy: 0.877 - ETA: 18s - loss: 0.3122 - accuracy: 0.877 - ETA: 18s - loss: 0.3119 - accuracy: 0.877 - ETA: 18s - loss: 0.3112 - accuracy: 0.877 - ETA: 18s - loss: 0.3122 - accuracy: 0.876 - ETA: 18s - loss: 0.3132 - accuracy: 0.876 - ETA: 18s - loss: 0.3115 - accuracy: 0.877 - ETA: 18s - loss: 0.3114 - accuracy: 0.876 - ETA: 17s - loss: 0.3105 - accuracy: 0.876 - ETA: 17s - loss: 0.3109 - accuracy: 0.876 - ETA: 17s - loss: 0.3112 - accuracy: 0.877 - ETA: 17s - loss: 0.3105 - accuracy: 0.877 - ETA: 17s - loss: 0.3112 - accuracy: 0.877 - ETA: 17s - loss: 0.3105 - accuracy: 0.877 - ETA: 17s - loss: 0.3091 - accuracy: 0.878 - ETA: 17s - loss: 0.3085 - accuracy: 0.878 - ETA: 17s - loss: 0.3061 - accuracy: 0.879 - ETA: 17s - loss: 0.3054 - accuracy: 0.879 - ETA: 17s - loss: 0.3068 - accuracy: 0.879 - ETA: 17s - loss: 0.3074 - accuracy: 0.878 - ETA: 17s - loss: 0.3070 - accuracy: 0.879 - ETA: 17s - loss: 0.3071 - accuracy: 0.878 - ETA: 17s - loss: 0.3058 - accuracy: 0.879 - ETA: 17s - loss: 0.3051 - accuracy: 0.880 - ETA: 16s - loss: 0.3053 - accuracy: 0.879 - ETA: 16s - loss: 0.3039 - accuracy: 0.879 - ETA: 16s - loss: 0.3058 - accuracy: 0.879 - ETA: 16s - loss: 0.3067 - accuracy: 0.879 - ETA: 16s - loss: 0.3065 - accuracy: 0.879 - ETA: 16s - loss: 0.3059 - accuracy: 0.879 - ETA: 16s - loss: 0.3043 - accuracy: 0.880 - ETA: 16s - loss: 0.3032 - accuracy: 0.881 - ETA: 16s - loss: 0.3026 - accuracy: 0.881 - ETA: 16s - loss: 0.3037 - accuracy: 0.880 - ETA: 16s - loss: 0.3025 - accuracy: 0.880 - ETA: 16s - loss: 0.3025 - accuracy: 0.881 - ETA: 16s - loss: 0.3027 - accuracy: 0.880 - ETA: 16s - loss: 0.3026 - accuracy: 0.880 - ETA: 16s - loss: 0.3021 - accuracy: 0.880 - ETA: 16s - loss: 0.3001 - accuracy: 0.881 - ETA: 16s - loss: 0.2998 - accuracy: 0.882 - ETA: 15s - loss: 0.3015 - accuracy: 0.881 - ETA: 15s - loss: 0.3009 - accuracy: 0.881 - ETA: 15s - loss: 0.3009 - accuracy: 0.881 - ETA: 15s - loss: 0.3009 - accuracy: 0.881 - ETA: 15s - loss: 0.3002 - accuracy: 0.881 - ETA: 15s - loss: 0.2990 - accuracy: 0.882 - ETA: 15s - loss: 0.2992 - accuracy: 0.882 - ETA: 15s - loss: 0.2999 - accuracy: 0.882 - ETA: 15s - loss: 0.2992 - accuracy: 0.882 - ETA: 15s - loss: 0.2996 - accuracy: 0.881 - ETA: 15s - loss: 0.2996 - accuracy: 0.881 - ETA: 15s - loss: 0.2998 - accuracy: 0.881 - ETA: 15s - loss: 0.3002 - accuracy: 0.881 - ETA: 15s - loss: 0.2999 - accuracy: 0.881 - ETA: 15s - loss: 0.2989 - accuracy: 0.882 - ETA: 15s - loss: 0.2991 - accuracy: 0.881 - ETA: 14s - loss: 0.2976 - accuracy: 0.882 - ETA: 14s - loss: 0.2991 - accuracy: 0.881 - ETA: 14s - loss: 0.2992 - accuracy: 0.881 - ETA: 14s - loss: 0.2990 - accuracy: 0.881 - ETA: 14s - loss: 0.2988 - accuracy: 0.881 - ETA: 14s - loss: 0.2981 - accuracy: 0.881 - ETA: 14s - loss: 0.2988 - accuracy: 0.881 - ETA: 14s - loss: 0.2988 - accuracy: 0.882 - ETA: 14s - loss: 0.2983 - accuracy: 0.882 - ETA: 14s - loss: 0.2982 - accuracy: 0.882 - ETA: 14s - loss: 0.2981 - accuracy: 0.882 - ETA: 14s - loss: 0.2974 - accuracy: 0.882 - ETA: 14s - loss: 0.2974 - accuracy: 0.882 - ETA: 14s - loss: 0.2971 - accuracy: 0.882 - ETA: 14s - loss: 0.2968 - accuracy: 0.883 - ETA: 14s - loss: 0.2965 - accuracy: 0.883 - ETA: 14s - loss: 0.2987 - accuracy: 0.882 - ETA: 13s - loss: 0.2985 - accuracy: 0.882 - ETA: 13s - loss: 0.2986 - accuracy: 0.882 - ETA: 13s - loss: 0.2993 - accuracy: 0.882 - ETA: 13s - loss: 0.2984 - accuracy: 0.882 - ETA: 13s - loss: 0.2991 - accuracy: 0.882 - ETA: 13s - loss: 0.2990 - accuracy: 0.882 - ETA: 13s - loss: 0.2986 - accuracy: 0.882 - ETA: 13s - loss: 0.2979 - accuracy: 0.882 - ETA: 13s - loss: 0.2988 - accuracy: 0.882 - ETA: 13s - loss: 0.2991 - accuracy: 0.882 - ETA: 13s - loss: 0.2995 - accuracy: 0.881 - ETA: 13s - loss: 0.2985 - accuracy: 0.882 - ETA: 13s - loss: 0.2981 - accuracy: 0.882 - ETA: 13s - loss: 0.2979 - accuracy: 0.882 - ETA: 13s - loss: 0.2982 - accuracy: 0.882 - ETA: 13s - loss: 0.2983 - accuracy: 0.882 - ETA: 13s - loss: 0.2976 - accuracy: 0.882 - ETA: 13s - loss: 0.2981 - accuracy: 0.882 - ETA: 13s - loss: 0.2982 - accuracy: 0.882 - ETA: 13s - loss: 0.2984 - accuracy: 0.882 - ETA: 13s - loss: 0.2994 - accuracy: 0.881 - ETA: 13s - loss: 0.2994 - accuracy: 0.881 - ETA: 12s - loss: 0.2992 - accuracy: 0.881 - ETA: 12s - loss: 0.3001 - accuracy: 0.881 - ETA: 12s - loss: 0.3005 - accuracy: 0.881 - ETA: 12s - loss: 0.3001 - accuracy: 0.881 - ETA: 12s - loss: 0.2998 - accuracy: 0.881 - ETA: 12s - loss: 0.3003 - accuracy: 0.880 - ETA: 12s - loss: 0.2999 - accuracy: 0.880 - ETA: 12s - loss: 0.2999 - accuracy: 0.880 - ETA: 12s - loss: 0.2997 - accuracy: 0.880 - ETA: 12s - loss: 0.2993 - accuracy: 0.881 - ETA: 12s - loss: 0.2994 - accuracy: 0.881 - ETA: 12s - loss: 0.3000 - accuracy: 0.881 - ETA: 12s - loss: 0.2991 - accuracy: 0.881 - ETA: 12s - loss: 0.2988 - accuracy: 0.881 - ETA: 12s - loss: 0.2997 - accuracy: 0.881 - ETA: 12s - loss: 0.3003 - accuracy: 0.881 - ETA: 12s - loss: 0.2995 - accuracy: 0.881 - ETA: 11s - loss: 0.2991 - accuracy: 0.882 - ETA: 11s - loss: 0.2995 - accuracy: 0.881 - ETA: 11s - loss: 0.2998 - accuracy: 0.881 - ETA: 11s - loss: 0.2998 - accuracy: 0.8818"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756/782 [============================>.] - ETA: 11s - loss: 0.3006 - accuracy: 0.881 - ETA: 11s - loss: 0.3008 - accuracy: 0.881 - ETA: 11s - loss: 0.3015 - accuracy: 0.881 - ETA: 11s - loss: 0.3011 - accuracy: 0.881 - ETA: 11s - loss: 0.3012 - accuracy: 0.881 - ETA: 11s - loss: 0.3009 - accuracy: 0.881 - ETA: 11s - loss: 0.3003 - accuracy: 0.881 - ETA: 11s - loss: 0.3009 - accuracy: 0.881 - ETA: 11s - loss: 0.3014 - accuracy: 0.881 - ETA: 11s - loss: 0.3016 - accuracy: 0.881 - ETA: 11s - loss: 0.3014 - accuracy: 0.881 - ETA: 11s - loss: 0.3019 - accuracy: 0.881 - ETA: 11s - loss: 0.3029 - accuracy: 0.880 - ETA: 10s - loss: 0.3028 - accuracy: 0.880 - ETA: 10s - loss: 0.3025 - accuracy: 0.880 - ETA: 10s - loss: 0.3027 - accuracy: 0.880 - ETA: 10s - loss: 0.3020 - accuracy: 0.881 - ETA: 10s - loss: 0.3014 - accuracy: 0.881 - ETA: 10s - loss: 0.3014 - accuracy: 0.881 - ETA: 10s - loss: 0.3010 - accuracy: 0.881 - ETA: 10s - loss: 0.3012 - accuracy: 0.881 - ETA: 10s - loss: 0.3007 - accuracy: 0.881 - ETA: 10s - loss: 0.3011 - accuracy: 0.881 - ETA: 10s - loss: 0.3005 - accuracy: 0.881 - ETA: 10s - loss: 0.2997 - accuracy: 0.881 - ETA: 10s - loss: 0.2993 - accuracy: 0.881 - ETA: 10s - loss: 0.2997 - accuracy: 0.881 - ETA: 10s - loss: 0.2995 - accuracy: 0.881 - ETA: 10s - loss: 0.2994 - accuracy: 0.881 - ETA: 10s - loss: 0.2997 - accuracy: 0.881 - ETA: 9s - loss: 0.3001 - accuracy: 0.881 - ETA: 9s - loss: 0.3001 - accuracy: 0.88 - ETA: 9s - loss: 0.3000 - accuracy: 0.88 - ETA: 9s - loss: 0.3005 - accuracy: 0.88 - ETA: 9s - loss: 0.3001 - accuracy: 0.88 - ETA: 9s - loss: 0.3006 - accuracy: 0.88 - ETA: 9s - loss: 0.3001 - accuracy: 0.88 - ETA: 9s - loss: 0.2998 - accuracy: 0.88 - ETA: 9s - loss: 0.2992 - accuracy: 0.88 - ETA: 9s - loss: 0.2994 - accuracy: 0.88 - ETA: 9s - loss: 0.2997 - accuracy: 0.88 - ETA: 9s - loss: 0.2997 - accuracy: 0.88 - ETA: 9s - loss: 0.2993 - accuracy: 0.88 - ETA: 9s - loss: 0.2989 - accuracy: 0.88 - ETA: 9s - loss: 0.2986 - accuracy: 0.88 - ETA: 9s - loss: 0.2981 - accuracy: 0.88 - ETA: 9s - loss: 0.2980 - accuracy: 0.88 - ETA: 9s - loss: 0.2977 - accuracy: 0.88 - ETA: 8s - loss: 0.2974 - accuracy: 0.88 - ETA: 8s - loss: 0.2972 - accuracy: 0.88 - ETA: 8s - loss: 0.2975 - accuracy: 0.88 - ETA: 8s - loss: 0.2978 - accuracy: 0.88 - ETA: 8s - loss: 0.2979 - accuracy: 0.88 - ETA: 8s - loss: 0.2976 - accuracy: 0.88 - ETA: 8s - loss: 0.2974 - accuracy: 0.88 - ETA: 8s - loss: 0.2976 - accuracy: 0.88 - ETA: 8s - loss: 0.2977 - accuracy: 0.88 - ETA: 8s - loss: 0.2983 - accuracy: 0.88 - ETA: 8s - loss: 0.2985 - accuracy: 0.88 - ETA: 8s - loss: 0.2981 - accuracy: 0.88 - ETA: 8s - loss: 0.2990 - accuracy: 0.88 - ETA: 8s - loss: 0.3001 - accuracy: 0.88 - ETA: 8s - loss: 0.2998 - accuracy: 0.88 - ETA: 8s - loss: 0.2998 - accuracy: 0.88 - ETA: 8s - loss: 0.2994 - accuracy: 0.88 - ETA: 7s - loss: 0.2995 - accuracy: 0.88 - ETA: 7s - loss: 0.2999 - accuracy: 0.88 - ETA: 7s - loss: 0.2998 - accuracy: 0.88 - ETA: 7s - loss: 0.3000 - accuracy: 0.88 - ETA: 7s - loss: 0.2996 - accuracy: 0.88 - ETA: 7s - loss: 0.3005 - accuracy: 0.88 - ETA: 7s - loss: 0.3003 - accuracy: 0.88 - ETA: 7s - loss: 0.2996 - accuracy: 0.88 - ETA: 7s - loss: 0.3001 - accuracy: 0.88 - ETA: 7s - loss: 0.3000 - accuracy: 0.88 - ETA: 7s - loss: 0.2997 - accuracy: 0.88 - ETA: 7s - loss: 0.2993 - accuracy: 0.88 - ETA: 7s - loss: 0.2989 - accuracy: 0.88 - ETA: 7s - loss: 0.2985 - accuracy: 0.88 - ETA: 7s - loss: 0.2985 - accuracy: 0.88 - ETA: 7s - loss: 0.2988 - accuracy: 0.88 - ETA: 7s - loss: 0.2984 - accuracy: 0.88 - ETA: 6s - loss: 0.2987 - accuracy: 0.88 - ETA: 6s - loss: 0.2986 - accuracy: 0.88 - ETA: 6s - loss: 0.2983 - accuracy: 0.88 - ETA: 6s - loss: 0.2980 - accuracy: 0.88 - ETA: 6s - loss: 0.2977 - accuracy: 0.88 - ETA: 6s - loss: 0.2977 - accuracy: 0.88 - ETA: 6s - loss: 0.2978 - accuracy: 0.88 - ETA: 6s - loss: 0.2985 - accuracy: 0.88 - ETA: 6s - loss: 0.2985 - accuracy: 0.88 - ETA: 6s - loss: 0.2997 - accuracy: 0.88 - ETA: 6s - loss: 0.2991 - accuracy: 0.88 - ETA: 6s - loss: 0.2990 - accuracy: 0.88 - ETA: 6s - loss: 0.2988 - accuracy: 0.88 - ETA: 6s - loss: 0.2982 - accuracy: 0.88 - ETA: 6s - loss: 0.2978 - accuracy: 0.88 - ETA: 6s - loss: 0.2972 - accuracy: 0.88 - ETA: 6s - loss: 0.2972 - accuracy: 0.88 - ETA: 6s - loss: 0.2967 - accuracy: 0.88 - ETA: 5s - loss: 0.2965 - accuracy: 0.88 - ETA: 5s - loss: 0.2960 - accuracy: 0.88 - ETA: 5s - loss: 0.2958 - accuracy: 0.88 - ETA: 5s - loss: 0.2954 - accuracy: 0.88 - ETA: 5s - loss: 0.2951 - accuracy: 0.88 - ETA: 5s - loss: 0.2951 - accuracy: 0.88 - ETA: 5s - loss: 0.2953 - accuracy: 0.88 - ETA: 5s - loss: 0.2950 - accuracy: 0.88 - ETA: 5s - loss: 0.2947 - accuracy: 0.88 - ETA: 5s - loss: 0.2948 - accuracy: 0.88 - ETA: 5s - loss: 0.2944 - accuracy: 0.88 - ETA: 5s - loss: 0.2943 - accuracy: 0.88 - ETA: 5s - loss: 0.2939 - accuracy: 0.88 - ETA: 5s - loss: 0.2948 - accuracy: 0.88 - ETA: 5s - loss: 0.2949 - accuracy: 0.88 - ETA: 5s - loss: 0.2944 - accuracy: 0.88 - ETA: 5s - loss: 0.2943 - accuracy: 0.88 - ETA: 4s - loss: 0.2941 - accuracy: 0.88 - ETA: 4s - loss: 0.2943 - accuracy: 0.88 - ETA: 4s - loss: 0.2938 - accuracy: 0.88 - ETA: 4s - loss: 0.2940 - accuracy: 0.88 - ETA: 4s - loss: 0.2940 - accuracy: 0.88 - ETA: 4s - loss: 0.2939 - accuracy: 0.88 - ETA: 4s - loss: 0.2941 - accuracy: 0.88 - ETA: 4s - loss: 0.2943 - accuracy: 0.88 - ETA: 4s - loss: 0.2945 - accuracy: 0.88 - ETA: 4s - loss: 0.2941 - accuracy: 0.88 - ETA: 4s - loss: 0.2939 - accuracy: 0.88 - ETA: 4s - loss: 0.2941 - accuracy: 0.88 - ETA: 4s - loss: 0.2938 - accuracy: 0.88 - ETA: 4s - loss: 0.2938 - accuracy: 0.88 - ETA: 4s - loss: 0.2937 - accuracy: 0.88 - ETA: 4s - loss: 0.2938 - accuracy: 0.88 - ETA: 4s - loss: 0.2937 - accuracy: 0.88 - ETA: 4s - loss: 0.2940 - accuracy: 0.88 - ETA: 3s - loss: 0.2941 - accuracy: 0.88 - ETA: 3s - loss: 0.2939 - accuracy: 0.88 - ETA: 3s - loss: 0.2937 - accuracy: 0.88 - ETA: 3s - loss: 0.2938 - accuracy: 0.88 - ETA: 3s - loss: 0.2939 - accuracy: 0.88 - ETA: 3s - loss: 0.2945 - accuracy: 0.88 - ETA: 3s - loss: 0.2942 - accuracy: 0.88 - ETA: 3s - loss: 0.2942 - accuracy: 0.88 - ETA: 3s - loss: 0.2937 - accuracy: 0.88 - ETA: 3s - loss: 0.2937 - accuracy: 0.88 - ETA: 3s - loss: 0.2935 - accuracy: 0.88 - ETA: 3s - loss: 0.2931 - accuracy: 0.88 - ETA: 3s - loss: 0.2938 - accuracy: 0.88 - ETA: 3s - loss: 0.2939 - accuracy: 0.88 - ETA: 3s - loss: 0.2940 - accuracy: 0.88 - ETA: 3s - loss: 0.2938 - accuracy: 0.88 - ETA: 3s - loss: 0.2935 - accuracy: 0.88 - ETA: 3s - loss: 0.2932 - accuracy: 0.88 - ETA: 2s - loss: 0.2930 - accuracy: 0.88 - ETA: 2s - loss: 0.2928 - accuracy: 0.88 - ETA: 2s - loss: 0.2931 - accuracy: 0.88 - ETA: 2s - loss: 0.2934 - accuracy: 0.88 - ETA: 2s - loss: 0.2937 - accuracy: 0.88 - ETA: 2s - loss: 0.2937 - accuracy: 0.88 - ETA: 2s - loss: 0.2938 - accuracy: 0.88 - ETA: 2s - loss: 0.2942 - accuracy: 0.88 - ETA: 2s - loss: 0.2945 - accuracy: 0.88 - ETA: 2s - loss: 0.2942 - accuracy: 0.88 - ETA: 2s - loss: 0.2938 - accuracy: 0.88 - ETA: 2s - loss: 0.2937 - accuracy: 0.88 - ETA: 2s - loss: 0.2936 - accuracy: 0.88 - ETA: 2s - loss: 0.2933 - accuracy: 0.88 - ETA: 2s - loss: 0.2936 - accuracy: 0.88 - ETA: 2s - loss: 0.2930 - accuracy: 0.88 - ETA: 2s - loss: 0.2933 - accuracy: 0.88 - ETA: 2s - loss: 0.2930 - accuracy: 0.88 - ETA: 1s - loss: 0.2927 - accuracy: 0.88 - ETA: 1s - loss: 0.2926 - accuracy: 0.88 - ETA: 1s - loss: 0.2925 - accuracy: 0.88 - ETA: 1s - loss: 0.2922 - accuracy: 0.88 - ETA: 1s - loss: 0.2921 - accuracy: 0.88 - ETA: 1s - loss: 0.2917 - accuracy: 0.88 - ETA: 1s - loss: 0.2924 - accuracy: 0.88 - ETA: 1s - loss: 0.2923 - accuracy: 0.88 - ETA: 1s - loss: 0.2929 - accuracy: 0.88 - ETA: 1s - loss: 0.2926 - accuracy: 0.88 - ETA: 1s - loss: 0.2925 - accuracy: 0.88 - ETA: 1s - loss: 0.2927 - accuracy: 0.88 - ETA: 1s - loss: 0.2928 - accuracy: 0.88 - ETA: 1s - loss: 0.2928 - accuracy: 0.88 - ETA: 1s - loss: 0.2925 - accuracy: 0.88 - ETA: 1s - loss: 0.2924 - accuracy: 0.88 - ETA: 1s - loss: 0.2925 - accuracy: 0.88 - ETA: 0s - loss: 0.2928 - accuracy: 0.88 - ETA: 0s - loss: 0.2927 - accuracy: 0.88 - ETA: 0s - loss: 0.2924 - accuracy: 0.88 - ETA: 0s - loss: 0.2921 - accuracy: 0.88 - ETA: 0s - loss: 0.2922 - accuracy: 0.8843"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.88 - ETA: 0s - loss: 0.2926 - accuracy: 0.88 - ETA: 0s - loss: 0.2925 - accuracy: 0.88 - ETA: 0s - loss: 0.2920 - accuracy: 0.88 - ETA: 0s - loss: 0.2918 - accuracy: 0.88 - ETA: 0s - loss: 0.2922 - accuracy: 0.88 - ETA: 0s - loss: 0.2922 - accuracy: 0.88 - ETA: 0s - loss: 0.2924 - accuracy: 0.88 - ETA: 0s - loss: 0.2922 - accuracy: 0.88 - ETA: 0s - loss: 0.2927 - accuracy: 0.88 - ETA: 0s - loss: 0.2926 - accuracy: 0.88 - ETA: 0s - loss: 0.2921 - accuracy: 0.88 - 23s 29ms/step - loss: 0.2919 - accuracy: 0.8843\n",
      "Accuracy: [0.29194511187350963, 0.88432]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import autokeras as ak\n",
    "\n",
    "\n",
    "def imdb_raw():\n",
    "    max_features = 20000\n",
    "    index_offset = 3  # word index offset\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(\n",
    "        num_words=max_features,\n",
    "        index_from=index_offset)\n",
    "    x_train = x_train\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    x_test = x_test\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    word_to_id = tf.keras.datasets.imdb.get_word_index()\n",
    "    word_to_id = {k: (v + index_offset) for k, v in word_to_id.items()}\n",
    "    word_to_id[\"<PAD>\"] = 0\n",
    "    word_to_id[\"<START>\"] = 1\n",
    "    word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "    id_to_word = {value: key for key, value in word_to_id.items()}\n",
    "    x_train = list(map(lambda sentence: ' '.join(\n",
    "        id_to_word[i] for i in sentence), x_train))\n",
    "    x_test = list(map(lambda sentence: ' '.join(\n",
    "        id_to_word[i] for i in sentence), x_test))\n",
    "    x_train = np.array(x_train, dtype=np.str)\n",
    "    x_test = np.array(x_test, dtype=np.str)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "# Prepare the data.\n",
    "(x_train, y_train), (x_test, y_test) = imdb_raw()\n",
    "print(x_train.shape)  # (25000,)\n",
    "print(y_train.shape)  # (25000, 1)\n",
    "print(x_train[0][:50])  # <START> this film was just brilliant casting <UNK>\n",
    "\n",
    "# Initialize the TextClassifier\n",
    "clf = ak.TextClassifier(max_trials=3)\n",
    "# Search for the best model.\n",
    "clf.fit(x_train, y_train, epochs=2)\n",
    "# Evaluate on the testing data.\n",
    "print('Accuracy: {accuracy}'.format(accuracy=clf.evaluate(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=x_train[1:150]\n",
    "a=clf.predict(X)\n",
    "b=y_train[1:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24f010fbe10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.plot(a, color='red')\n",
    "plt.plot(b, color='blue')\n",
    "plt.grid()\n",
    "plt.title('MOVIE SELECTION CRITERION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "loss, acc = clf.evaluate(x_train, y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09436042731999399"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
